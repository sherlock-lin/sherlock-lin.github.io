[{"content":"简析 距离初次写笔记/博客已经差不多十年了，这其中换了不少平台，每次换平台都少不了一顿折腾，导致有段时间都不怎么喜欢写博客了，更喜欢以笔记的方式记录下，现在在基于github搭建完博客后，终于有种安心的感觉了，不禁思考起，承载博客的最终形式应该是什么样子的，首先先简单回顾这些年用过的博客网站吧。\nV1(CSDN) 时间：15～18年\n15年时候开始想输出技术文章，在平时查阅资料以及周围同学交流时，觉得CSDN很火，于是就在CSDN上注册了号并且持续输出文章，当时接触了很多新技术，但是写的大部分内容实际上都是一些常识类的东西，很少有自己深入挖掘。当时选择CSDN还有一些其他因素，总结来说就是入门门槛低、引流好，对中文友好，相比之下Github、自建网站等来说对小白来说不是很友好，因此就这样用了几年的CSDN。\nV2(segmentfault/简书/github) 时间：18～19\n在查看技术时，被简书的简约、漂亮的界面吸引住了，相比CSDN天花乱坠的广告以及充斥着不少重复内容的情况，简书的吸引力简直太大了，于是开始在上面进行内容的输出，但是没有持续多久，发现这上面的引流做得不是很好，认真写了不少文章基本没啥流量；后来转战segmentfault，也是类似的理由。之后也在github写过一段时间，github好在可以永久的给你保证数据不会丢而且这个平台基本不会倒，但是因为UI以及没有什么好的反馈逐渐放弃。\nV3(博客园/知乎) 时间：19～21\n在经历过segmentfault/简书后，愈发觉得不应该过度在乎界面，更应该注重内容的质量，同时为了不再折腾，想选一个老牌稳重点网站，于是把目光瞄准了博客园，整体来说博客园应该是做得对开发者很友好的平台，虽然UI比较简陋，但是支持作者自定义UI呀，通过css和js一样能自定义出优美、酷炫的界面，同时它的后台管理功能也是做得比较好的，除此之外还在知乎并行的写文章，但不得不说，知乎的markdown支持真的不行，更适合写一些对格式要求没那么强的内容。\nV4(hexo自建网站) 时间：21～22\n虽然很喜欢博客园，但是有不少需要自己动手做的地方了，作为一个非前端要花不少时间去调css和js其实挺恼火的，后来想了想既然反正都花了这么多时间，为什么不直接自己搭建个网站呢，于是基于 hexo+github 搭建了一个，虽然也折腾了不少，但好歹不花钱弄了一个稳定的、属于自己的博客网站，但后来有几次hexo报错并且工作 忙了起来，就扔在那里了；再后来电脑重装系统导致本地文件丢失，由于当时只是将编译好的博客数据部署到github，因此github也没有保持原来的数据，基于这个原因就不想再继续弄了\nV5(CSDN/公众号) 时间：23～24\n思考之后，觉得作为已经工作多年的人并且对技术还有热情的人，首先当下重中之重是保持输出技术文章，平台是其次，只要能够保持高质量输出文章内容，自己的水平也会不断进步，平台只是个工具而已，并且随着在CSDN输出文章增多以及粉丝增多，CSDN也逐渐给我开放了不少酷炫的主题，而且用CSDN的话也能降低写博客的成本，于是这一年在CSDN贡献了不少的博客，同时觉得公众号可以打造自己的IP并且也挺酷炫的，因此有些觉得质量不错的文章也会在公众号再发一次。但是随着博客数量的增加，写博客的附加成本在逐渐上升，首先是CSDN不支持导入markdown文件的同时导入图片，因此每次要在CSDN上发布文章，还需要手动的在编辑页面上一张一张 的上传图片，这个方式现在回想都觉得挫；同理，公众号也是一样，相当于每发一次文章同样的事情需要做两遍，我陷入了沉思～\n在通过摸索后，发现其实可以通过图床的方式例如PicGo来解决，就是在typera写文章时，图片会自动上传到网上例如gitee、github上，然后本地直接引用网络连接，这样就完美解决上诉问题，这样本地、CSDN、公众号的都通过网络连接访问gitee上的图片资源，从而避免了每次发布编辑图片，但是这个时候CSDN网站变得很卡， 想翻阅历史的博客能加载几个小时，以及编辑一些历史文章再保存时也会卡很久或者直接失败～\n至于公众号，更适合发一些权威或者说改动不大的内容，如果有编辑过自己公众号文章的朋友应该也比较清楚，基于这个原因我也放弃了公众号。\nV6(hugo自建网站) 时间：现在\n回顾过去这些年的经历，再结合自己的情况，需求逐渐清晰了起来。\n背景：我是要用一辈子去参与编程的，因此输出博客是长期存在的需求(因为编程是脑力活动，需要深度思考，输出高质量技术博客可以push自己持续吸收高质量技术)\n以下需求按优先级排序：\n稳定的平台\n每次迁移平台都意味着有一堆适配的杂活要做，这些事情本质上就是没有意义的事情，对个人没有任何的成长而言；不需要过多参与到平台的维护工作中，例如自己购买服务器部署之类的，例如有些时间比较忙服务崩了都不知道，我期望的是这些文章我一旦发布后，即便我很多年不去维护它，它也能持续很好的工作～\n免费\n一方面不希望花钱，因为也没打算靠写博客赚钱，另一方面，也希望我认真写的文章不要依赖某一个个体，例如我很喜欢的左耳朵耗子，他的文章是购买海外服务器部署的，而在他逝去后，如果服务器被回收了，那真的是一大损失。虽然我的文章质量并不能相提并论，但是也是认真思考过的东西，如果可以我也希望即使我离开这个世界，它也能帮到后来有需要的学徒，就像现在的我依然在看左耳朵耗子的文章一样，即便作者已不在这个世界，但有时候仿佛在跟作者沟通、辩论一样，思想的东西就是这样，因此有一个能够免费并且长期承载这些思想的东西是非常重要的\n支持自定义\n正如教员所说的“枪杠子里出政权”，一些关键的东西一定要把控在手上。例如主题的选择、交互的控制、响应性能的优化等等，这样在未来有任何变动，我都能通过自己自定义去进行处理\n维护人工成本低/写文章成本低\n从长期的角度来看，不需要人维护，并且发布新文章的成本要很低，像手动一张张上传图片的操作绝不可取，其他适配的工作也是能少就少\n基于以上需求，我最终的方案也有雏型了，随着不断的完善，以下是我的最终形态\n通过本地电脑的typora编写Blog内容，这些Blog都是通过hugo创建并且管理的，同时这个目录也是由git管理的，这个时候写完文章也可以通过hugo启动本地博客网站进行展示以及调整 通过git命令将数据push到github服务端持久化起来，此时相当于数据已经持久化备份起来了，之后即便本地电脑坏了对博客内容都不会有丝毫的影响 通过配置workflows文件，在仓库1感应到有新的资源被push来时，会出发action，将仓库1最新的数据通过hugo编译部署在仓库2上，由仓库2对外提供web服务。 在有用户在博客评论时，评论信息会自动持久化到仓库3，以issue的形式持久化并且正常展示到博客网站上，这里我使用的是utterances工具来做的持久化操作 在博客搭建好之后，我们需要做的只有1、2两步，第3和第4步咱们可以永远不用去管它，如果有人像我一样觉得第二步操作输入几条指令太麻烦，可以将起封装成一件执行的shell脚本，这样就之需要专注Blog内容的编写，编写完后点一个按钮，数据会自动上传到仓库1，之后就可以通过访问博客网站正常使用了。\n总结 如果将这个整个博客系统看作一个软件的话，那么分层如下\n再聊回咱们的标题，你觉得理想情况下，blog的归处是什么样子的？或者说博客文章应该放在哪里是最好的？\n有人会觉得，有必要这么大费周张的思考这个吗，但我觉得这是很有必要的，任何事情你如果想把它做好，就一定要有闭环的思维，如果你认真写了几篇高质量的文章，由于像我上面一样，通过多次平台的迁移导致丢失了不少，这难道不是一种损失吗。这就像是工作上的失误导致公司的业务造成损失，这个损失也许是可以接受的(例如博客文章内容质量不高)，但万一哪一天公司业务起来了呢，也就是你文章质量逐渐上来或者是你开始把写博客也当作事业一样来对待时，如何给自己的博客文章提供稳定性保障，这就需要好好思考了也就是标题的问题。\n如果有其他更好的设计，欢迎在底下评论。补充说明下，上面提到的所有平台不排除作者打开方式不对，仅供读者参考，这个解决方案也是，仅供参考，希望能让有同样需求的同学少走一点弯路，这就是我写本篇文章的初衷\n","date":"2024-09-21T10:53:25+08:00","image":"https://sherlock-lin.github.io/p/blog%E5%BD%92%E5%A4%84/image-20240921101717625_hu1519644137074903956.png","permalink":"https://sherlock-lin.github.io/p/blog%E5%BD%92%E5%A4%84/","title":"Blog归处"},{"content":"简析 Broker的启动流程框架基本如下\n触发启动 初始化 读取配置、检测、赋值 启动 Bookie启动 Broker启动 启动Netty 启动后台监控任务 何时、如何触发启动 Broker的启动基本都是靠维护人员主动触发的，入口是Broker提供的脚本 bin/pulsar、bin/pulsar-daemon。常见的启动指令有 bin/pulsar standalone、 bin/pulsar broker、bin/pulsar-daemon start broker等，今天就从bin/pulsar broker流程进行探讨。先来看看bin/pulsar的脚本逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 pulsar_help() { cat \u0026lt;\u0026lt;EOF //在这里可以看到pulsar支持的操作，当然也可以通过bin/pulsar help 指令进行查看 Usage: pulsar \u0026lt;command\u0026gt; where command is one of: //启动Broker服务 broker Run a broker server //启动bookie服务 bookie Run a bookie server zookeeper Run a zookeeper server configuration-store Run a configuration-store server discovery Run a discovery server proxy Run a pulsar proxy websocket Run a web socket proxy server functions-worker Run a functions worker server sql-worker Run a sql worker server sql Run sql CLI standalone Run a broker server with local bookies and local zookeeper autorecovery Run an autorecovery service .... } //如果执行的是bin/pulsar broker则会走到这里，可以清楚的看到最终会调用PulsarBrokerStarter类进行启动 if [ $COMMAND == \u0026#34;broker\u0026#34; ]; then PULSAR_LOG_FILE=${PULSAR_LOG_FILE:-\u0026#34;pulsar-broker.log\u0026#34;} exec $JAVA $LOG4J2_SHUTDOWN_HOOK_DISABLED $OPTS -Dpulsar.log.file=$PULSAR_LOG_FILE org.apache.pulsar.PulsarBrokerStarter --broker-conf $PULSAR_BROKER_CONF $@ elif [ $COMMAND == \u0026#34;bookie\u0026#34; ]; then PULSAR_LOG_FILE=${PULSAR_LOG_FILE:-\u0026#34;bookkeeper.log\u0026#34;} exec $JAVA $OPTS -Dpulsar.log.file=$PULSAR_LOG_FILE org.apache.bookkeeper.server.Main --conf $PULSAR_BOOKKEEPER_CONF $@ Broker启动流程 通过脚本能够看到是通过PulsarBrokerStarter进行启动，因此现在就直接从它的main方法进行跟踪吧\n这里的初始化和启动两条链路都值得看，首先跟踪下初始化Broker的链路\n可以看到初始化的过程中分别做了 配置加载、初始化Broker、初始化Bookkeeper以及AutoRecoveryMain服务等。接下来就就看服务启动链路。\n可以看到启动入口很简洁，就是启动上面初始化好的Broker、Bookkeeper、AutoRecoveryMain，这里先看Broker的启动流程也就是276行\n可以看到这个方法非常大，里面内容非常丰富，一起来详细看看\n简单总结下这个方法，它主要创建了以下几个对象\nCoordinationServiceImpl对象，用于协调Broker选主\nBrokerService对象，这个是启动Broker对象的核心\nLoadManager对象，用于管理Broker对象的负载均衡\nSchemaStorage对象，负责处理读写schema的请求\nOffloadPoliciesImpl，负责分层存储操作\n并启动WebService服务，负责对外提供http服务\nWorkerService服务，负责处理function计算操作\n这里面的BrokerService是最核心的，在这里进去看下它创建的逻辑\n此方法主要做了下面几件事\n创建Netty服务端，用于处理生产者/消费者/代理的TCP请求 创建定期检测服务 不活跃的检测 消息过期检测 压缩检测 消费者检测 初始化五个Map容器 维护Topic对象 维护集群副本复制的客户端 维护连接当前Broker的管理流 维护Topic归属信息 维护多层级的Topic信息？ 启动DelayedDeliveryTrackerLoader跟踪延迟消息 启动Broker拦截器BrokerEntryMetadataInterceptors 启动限额管理对象BundlesQuotas 启动Netty服务端(此时Pulsar服务具备处理所有客户端请求能力) 启动定期检测服务 不活跃的检测 消息过期检测 压缩检测 消费者检测 消息积压检测 总结 PulsarService是Pulsar服务启动的核心类，其内置了七大重要的对象如下图\nBrokerService: 核心是启动Netty，处理客户端的TCP连接，同时通过多个Map容器维护例如Topic信息、Topic归属信息等等，除此之外还启动一批定时线程定期检测(消息过期、压缩、客户端活跃等) LoadManager: 负责处理Broker服务的负载均衡 WebService: 对外提供HTTP服务，例如管理流的操作(元数据)等 CoordinationService: 给Broker提供协调服务，例如Broker选主操作 SchemaStorage: 提供schema相关的一切服务，常见的就是schema的读写 OffloadPolicies: 提供分层存储，冷数据自动迁移到外部服务中 WorkerService: 管理Worker实例，用来执行Function计算任务 以上就是Pulsar启动流程所做的事情，其中Bookkeeper的启动以及其余的功能例如CoordinationService、SchemaStorage等等都值得单独新开一篇文章进行讲解，这里就不混在一起讲了。\n","date":"2024-09-18T10:05:57+08:00","image":"https://sherlock-lin.github.io/p/%E5%90%AF%E7%A8%8Bpulsar%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90%E9%AB%98%E9%80%9F%E5%90%AF%E5%8A%A8%E5%BC%95%E6%93%8E%E6%8F%AD%E7%A7%98%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%B7%A8%E5%85%BD%E7%9A%84%E8%AF%9E%E7%94%9F/image-20240913141630196_hu5121917752973153749.png","permalink":"https://sherlock-lin.github.io/p/%E5%90%AF%E7%A8%8Bpulsar%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90%E9%AB%98%E9%80%9F%E5%90%AF%E5%8A%A8%E5%BC%95%E6%93%8E%E6%8F%AD%E7%A7%98%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%B7%A8%E5%85%BD%E7%9A%84%E8%AF%9E%E7%94%9F/","title":"启程Pulsar：深入剖析高速启动引擎，揭秘消息中间件巨兽的诞生"},{"content":"一、引言 关于Pulsar Schema，咱们要想想以下几个问题\nPulsar 中的 Schema 是什么？ Pulsar Schema Registry的作用是什么？ 怎么使用？ 原理是什么？ 二、Schema 是什么 Schema是定义结构化数据和二进制字节数组之间转换的逻辑，Pulsar的消息是以非结构化的二进制数组进行存储的，Schema只有在读写时才会被应用于数据上，因此生产者和消费者需要对Schema达成一致。Pulsar通过Schema Registry作为一个中央仓库存储Schema信息，它可以协调生产者和消费者保证相同的Schema，它可以存储多个版本的Schema，支持不同的兼容性配置以及根据兼容性的要求进行Schema的演进。Pulsar将Schema存储在Bookie上，Schema的写入、读取都通过Broker和Bookie交互，这个逻辑跟消息的读写操作是一只的，因此不需要额外考虑Schema的可用性和可靠性问题，因此整体看Pulsar实现Schema Registry的方式非常优雅\n类型安全在所有数据应用中都非常重要，生产者和消费者需要某种机制协调数据类型来避免各种潜在的问题，比如序列化和反序列化方式不一致。数据安全通常有两种处理方式client-side和service-side，本质上就是客户端用时决定和服务端提前保证\nclient-side：将一切交给用户，客户端自行负责消息的序列化和反序列化并且保证生产消费时消息的类型安全，这种方式的最大问题就是类型是通过约定的，一旦生产者写入非约定的数据，下游的消费者将没有办法解析数据\nserver-side：数据安全由服务端保证，生产者和消费者都需要跟服务端提前确定数据类型。这种方式真正意义上保证了数据的类型安全，避免了生产者写入非法数据的问题\n两种差异如下图\n三、怎么使用 1. client-side 生产者代码逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //schema在第一次写入的时候就已经决定好了，后续用其他的schema消息类型会写入失败 public static void customSchemaProducer() { try { String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); Producer\u0026lt;byte[]\u0026gt; producer = pulsarClient.newProducer() .topic(\u0026#34;persistent://sherlock-api-tenant-1/sherlock-namespace-1/topic_8\u0026#34;) .create(); User user = new User(); user.setName(\u0026#34;老六\u0026#34;); user.setAge(21); user.setAddress(\u0026#34;海南\u0026#34;); //由用户自行做序列化逻辑 producer.send(JSON.toJSONString(user).getBytes()); producer.close(); pulsarClient.close(); } catch (Exception e) { } } 消费者逻辑代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public static void customSchemaConsumer() { try { String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); Consumer\u0026lt;byte[]\u0026gt; consumer = pulsarClient.newConsumer() .topic(\u0026#34;persistent://sherlock-api-tenant-1/sherlock-namespace-1/topic_8\u0026#34;) .subscriptionName(\u0026#34;sub_03\u0026#34;) .subscribe(); while(true) { Message\u0026lt;byte[]\u0026gt; message = consumer.receive(); //由用户自行做序列化逻辑 byte[] user = message.getValue(); System.out.println(\u0026#34;消息数据为：\u0026#34;+JSON.parseObject(user, User.class).toString()); consumer.acknowledge(message); //consumer.negativeAcknowledge(message); } } catch (Exception e) { } } 执行效果如下\n1 消息数据为：User{name=\u0026#39;老六\u0026#39;, age=21, address=\u0026#39;海南\u0026#39;} 2. server-side 生产者代码逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 //schema在第一次写入的时候就已经决定好了，后续用其他的schema消息类型会写入失败 public static void customSchemaProducer() { try { String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); //由Pulsar做序列化逻辑 Producer\u0026lt;User\u0026gt; producer = pulsarClient.newProducer(AvroSchema.of(User.class)) .topic(\u0026#34;persistent://sherlock-api-tenant-1/sherlock-namespace-1/topic_7\u0026#34;) .create(); User user = new User(); user.setName(\u0026#34;王武\u0026#34;); user.setAge(36); user.setAddress(\u0026#34;海南\u0026#34;); producer.send(user); producer.close(); pulsarClient.close(); } catch (Exception e) { } } 消费者逻辑代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public static void customSchemaConsumer() { try { String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); //由Pulsar做序列化逻辑 Consumer\u0026lt;User\u0026gt; consumer = pulsarClient.newConsumer(AvroSchema.of(User.class)) .topic(\u0026#34;persistent://sherlock-api-tenant-1/sherlock-namespace-1/topic_7\u0026#34;) .subscriptionName(\u0026#34;sub_03\u0026#34;) .subscribe(); while(true) { Message\u0026lt;User\u0026gt; message = consumer.receive(); User user = message.getValue(); System.out.println(\u0026#34;消息数据为：\u0026#34;+user); consumer.acknowledge(message); //consumer.negativeAcknowledge(message); } } catch (Exception e) { } } 执行效果如下\n1 消息数据为：User{name=\u0026#39;王武\u0026#39;, age=36, address=\u0026#39;海南\u0026#39;} 3. 小结 分别查看两个Topic的Schema信息如下图\n通过查询client-side的Schema信息，会发现Pulsar服务端其实并没有进行存储，相当于不指定Schema的话Pulsar默认都用byte数组\n再来看看server-side的Schema信息，可以看到打印如下，namespace是pojo类的包路径，name是pojo类名，然后fields就是pojo类的各个字段的属性(像不像mysql里面的表结构，不少场景Topic就是当作表来用的)，然后type是AVRO是由于咱们是用的avro进行序列化的。\n除了在读写数据时指定Schema，Pulsar还支持通过admin管理流提前指定好，具体指令在这里。如果是用Pulsar来作为实时数仓场景，强烈建议提前通过admin管理流进行指定好，配置isSchemaValidationEnforced可以考虑开启。如果条件允许可以考虑做成服务化，例如通过Web页面提供新建Schema、修改Schema操作并接入公司内部的审批流等\n1 2 3 pulsar-admin schemas upload --filename POST /admin/v2/schemas/:tenant/:namespace/:topic/schema pulsar-admin schemas get sherlock-api-tenant-1/sherlock-namespace-1/partition_partition_topic_3 四、原理解析 Schema相关的流程咱们需要关注以下几个\n注册Schema流程 生产者端侧 消费者端侧 指定服务器 Schema生效流程 更新Schema流程 1. 注册Schema流程 生产者端侧\n生产者实例会在内部构造schema实例，生产者会通过它对数据进行转换 生产者会请求连接Broker，并传递schema信息 SchemaInfo Broker会在schema registry中查找这个schema是否被注册，如果已经注册了就将注册的schema版本返回给生产者 Broker检查是否支持自动更新schema，如果配置不允许自动更新，则这个schema不能被注册并且拒绝生产者 Broker进行schema兼容性检查，如果通过检查则将此schema存储在schema registry并返回版本给生产者，生产者所有消息以这个schema格式进行发送；若是检查没通过则拒绝生产者 消费者端\n消费者实例会在内部构造schema实例 消费者请求连接Broker，并传递schema信息 SchemaInfo Broker检查这个Topic是否已经在使用，有的话跳到第五步，否则跳到第四步 Broker检查是否支持自动更新schema，如果支持则注册这个schema，否则拒绝客户端 Broker进行schema兼容性检查，通过则连接否则拒绝客户端 五、源码解析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public static void customSchemaProducer() { try { String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); Producer\u0026lt;User\u0026gt; producer = pulsarClient.newProducer(AvroSchema.of(User.class)) .topic(\u0026#34;persistent://sherlock-api-tenant-1/sherlock-namespace-1/topic_7\u0026#34;) .create(); User user = new User(); user.setName(\u0026#34;王武\u0026#34;); user.setAge(36); user.setAddress(\u0026#34;海南\u0026#34;); producer.send(user); producer.close(); pulsarClient.close(); } catch (Exception e) { } } 文献 Pulsar：Schema Registry介绍 官方文档 深度解读 Pulsar Schema ","date":"2024-09-13T10:34:56+08:00","image":"https://sherlock-lin.github.io/p/schema%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/image-20240308104136110_hu13493609005795593452.png","permalink":"https://sherlock-lin.github.io/p/schema%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/","title":"Schema深度解析"},{"content":"一、简析 schema是pulsar重要的功能之一，现在就一起从源码的视角看下管理流创建schema时客户端和服务端的表现\n客户端 客户端主要经历以下四个步骤\n创建Schema实例\n根据数据类型创建相对应的实例，例如Avro创建AvroSchema、JSON创建JSONSchema等\n获取处理Schema的对象\n管理流PulsarAdmin对象获取SchemasImpl对象，这个对象是专门处理所有schema相关的操作。除此之外PulsarAdmin对象还维护着Clusters、Brokers、Tenants等等管理维护集群的重要对象，通过这些对象可以很好的管理维护Pulsar集群\n构造SchemaInfo\n通过Schema实例创建其对应的SchemaInfo信息，里面就包括这个schema的名字、schema的结构化信息、schema类型等等，最后SchemaInfo这个对象会转成字符串发到服务端\n发送HTTP请求\n通过post请求将数据发到服务端，这里是通过Java Rest库javax.ws.rs-api进行处理的\n服务端 服务端主要经历以下四个步骤\n参数格式校验\n校验租户、命名空间的是否有效(判空、是否有特殊字符) 从缓存中根据Topic获取其对应的TopicName对象 权限校验\n判断是否是Topic的owner 判断当前用户是否有操作当前Topic的权限 SchemaRegistry注册schema\nSchemaRegistryService是服务端处理所有schema相关的对象，而schema相关的读写操作是依赖它的成员SchemaStorage进行处理的，SchemaStorage的最终是通过Bookkeeper客户端对象发送写请求\n写Bookkeeper\n通过LedgerHandle对象向Bookkeeper服务端发送写请求\n小结 schame新建流程概括起来就是，客户端构造schema信息，服务端负责schema校验，bookkeeper负责schema的存储\n二、客户端源码解析 源码跟踪 下面是通过管理流创建schema的样例代码，核心就是通过PulsarAdmin.schemas获取schema对象，这个schema对象负责所有客户端跟schema相关的操作，包括schema的增删改查等。通过方法的第二个参数可以看到是通过Schema接口提供的静态方法AVRO来构造Avro格式的schema对象，除此之外Schema接口还提供了诸如JSON、KeyValue、PROTOBUF等静态方法提供对应数据格式的schema对象，这里如果将这块构造schema对象逻辑抽成简单工厂模式可能会更合适些\n接下来就进入createSchema方法，顾名思义可以知道这个方法就是用于创建schema的，第一个参数是topic，第二个参数是SchemaInfo对象，这个对象包含了所有要新建的schema信息，这里会将它转换为PostSchemaPayload对象传递给下一个方法。PostSchemaPayload是用来请求到服务端的参数\n这个方法并不会有返回值，sync方法是处理异步结果对象，它在正常写成功情况下不会做任何操作，但如果有什么错误会往外抛出异常。这里核心逻辑是在createSchemaAsync方法\n可以看到这个方法的返回值是个异步对象，146行这里会获取当前topic对应的TopicName对象，并通过schemaPath方法构造WebTarget对象，这个对象中就包含着要请求的HTTP地址，主要是根据当前Topic的版本来决定请求服务端哪个版本的处理方法。除此之外还可以看到有通过Entity.json方法将PostSchemaPayload对象转换为HTTP请求的参数对象，转换逻辑是javax.ws.rs-api这个网络库封装的，就不进行跟踪了\n这里就是客户端最后发送的地方，request方法中还会发送前的安全相关检查，async方法基本上就说明本次HTTP请求是异步的，而post方法也能看得出，这是一个POST类型的HTTP请求，再往后就是将请求发送出去了\n不知是否有人好奇参数WebTarget长什么样子，通过通过调试可以看到值为\n/admin/v2/schemas/public/test-namespace-jytixthzgatgirem/test-multi-version-schema-one/schema\n此值仅供学习参考，具体这个值的构造逻辑如下\n小结 简单归纳如下\n通过Schema接口构造对应数据格式的schema对象，由此对象可得到schema相关的元信息SchemaInfo 构造请求目标的HTTP地址 通过javax.ws.rs-api提供的库发送异步HTTP请求到服务端 三、服务端源码解析 源码跟踪 服务端的接收逻辑在SchemasResource类，这个类在org.apache.pulsar.broker.admin包下，这个包下全是处理管理流相关的操作，如果有做pulsar平台化需求的，这个包下的相关逻辑值得一读。\n再来看看postSchema方法，首先是validateTopicName方法，这个方法就是对入参进行判空、是否有特殊字符做检查；接下来就是核心方法postSchemaAsync，通过方法名可以推断出这是个异步处理schema写请求的方法\npostSchemaAsync方法看似复杂，实际上核心的就是133行，其余的方法大概说一下，validateOwnershipAndOperationAsync方法主要检查当前用户是否有新建schema的操作权限，getSchemaCompatibilityStrategyAsyncWithoutAuth方法相对复杂一些，放到后面详细讲解。那么再看回133行，其中getSchemaRegistryService方法获取的是SchemaRegistryServiceImpl对象，顾名思义可以知道Pulsar的SchemaResistry相关的功能都是由它进行处理，现在先看它的putSchemaIfAbsent方法\nSchemaStorage对象是SchemaRegistryServiceImpl的核心成员，负责schema存储相关的操作。在新建schema时会调用它的put方法进行创建；这里有个trimDeletedSchemaAndGetList方法，如果put方法在创建schema时有任何异常，则此方法会去删除该新建的schema，避免写\u0026quot;一半\u0026quot;的情况发生，某种意义上这也是一种回滚的设计。\n这里的getAll方法很重要，会根据schema的id来查询是否已经存在当前schema，有的话则将版本号加1。处理完之后就调用put方法\n这里没什么逻辑，继续往下跟踪\ngetSchemaLocator方法会构造LocatorEntry对象，调用putSchema\n由于是初次创建schema，因此直接走到337行；如果这个topic已经创建过schema则会读取之前的schema信息再新增，同时把版本号自增\n在这里可以看得到构造IndexEntry对象，这是消息的索引对象，后续用来加速查询schema\n这个方法的内容就很眼熟了(bookkeeper相关内容)，createLedger方法会先创建这个Ledger\n在576行可以看到最终调用bookkeeper创建这个Ledger\n再来看看addEntry方法，这里核心也是调用bookkeeper的ledgerHandle进行数据写入\n这个方法是属于Bookkeeper客户端的逻辑了，通过方法注释可以看到，这个方法负责将数据异步写入到一个打开的Ledger。Bookkeeper相关的逻辑后续在单独写post进行讲解\n小结 简单归纳如下\n参数格式校验、操作权限校验 查询当前Topic是否已经创建过schema，有则以插入时版本号自增 如果是初次创建Schema，则调用bookkeeper创建Ledger 往这个Schema对应的Ledger内插入schema元数据信息 四、其他 序列化对象创建流程 现在再专门来看看序列化对象的创建过程，回到开头管理流创建schema的地方，Schema.AVRO方法是咱们本次要看的\n通过注释可以看到，此静态方法是创建一个Avro类型的schema对象，getDefaultImplementation方法是获取实现类(饿汉单例设计模式)，而newAvroSchema方法才是本次要看的\n继续往下跟踪\n获取对应处理的类加载器，并通过对应的类加载器创建AvroSchema实例\n54行是核心，其他的都是赋值操作\nsuper调用父类构造函数做赋值操作，还是继续看\n继续跟踪parse逻辑\nFACTORY.createParser方法是jackson的方法，用于创建JsonParser对象的；因此继续跟踪parse方法\n1471行可以看到返回了我们想要的Schema对象，那么Schema.parse方法就是重中之重\n这个方法是核心，本身会递归的进行解析赋值给schema对象\n相信读者读到这里也好奇schema长什么样，因此提供下图让读者感受下，能大概推测得出来这里已经涵盖了schema的结构信息了\ngetSchemaCompatibilityStrategyAsyncWithoutAuth方法 AdminResource#getSchemaCompatibilityStrategyAsyncWithoutAuth方法是在服务端处理schema创建请求阶段会调用的方法，现在就一起跟踪看看\n731行和739行分别是获取Topic级别和Namespace级别的schema兼容策略，如果没有定义则默认自动更新。例如Topic A之前已经创建过schema1，那么如果此时再发起schema2创建请求，则服务端会继续保存并且生效schema2，只不过它的版本号会进行累加，当然，也可以配置为不支持schema策略不支持更新，一旦确定了后就不允许再变更\n五、总结 相信大家对schema创建的流程已经很清楚了，再次简单归纳下\n客户端根据用户定义的结构信息创建对应的Schema对象，并将结构信息以HTTP请求发给服务端 服务端检测并根据Schema兼容策略做相对应的处理，一般情况下会调用Bookkeeper创建Ledger以及Entry Bookkeeper将此Schema数据持久化到磁盘，相当于Schema信息会被Bookkeeper当作一条消息进行存储 这基本上就是全部内容，当然细节感兴趣的小伙伴可以自行跟踪代码，相信你会有更多收获～\n","date":"2024-08-01T10:02:55+08:00","image":"https://sherlock-lin.github.io/p/%E7%AE%A1%E7%90%86%E6%B5%81%E5%88%9B%E5%BB%BAschema%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20240801111546500_hu11517481045871944850.png","permalink":"https://sherlock-lin.github.io/p/%E7%AE%A1%E7%90%86%E6%B5%81%E5%88%9B%E5%BB%BAschema%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","title":"管理流创建schema流程源码解析"},{"content":"一、Pulsar客户端简析 pulsar服务是经典的C/S架构，由客户端和服务端构成。服务端提供处理读写请求服务，客户端负责发起读写请求。pulsar将客户端按照读写分成了生产者和消费者，但是无论怎么分，它们本质上都是Pulsar客户端并有很多相同的地方，本篇就针对客户端进行分析。\n下图是客户端的组成部分\nConnectionPool连接池(值得深挖)\n连接池是客户端的核心，维护着跟服务端的TCP连接，客户端的读写(生产者/消费者)都强依赖网络连接，因为最后数据还是要通过底层的网络进行通信\nLookupService\n具有路有属性的客户端角色，负责查找Topic归属的Broker节点\n线程池\n事件线程池\n外部线程池\n内部线程池\n二、创建客户端对象 1、创建流程 先看看下面一段代码\n这是通过生产者写数据到Pulsar服务端的case，相信大家不会感到陌生，其中34行就是创建客户端的逻辑，因此就从这里进行跟踪\n通过跟踪PulsarClient.builder方法可以看到这是一个静态方法，可以看到返回值是ClientBuilder对象，具体实现逻辑咱们先不关心，咱们只需要知道这个方法会创建一个ClientBuilder就够了，结合之前的创建的逻辑可以知道最终会走到ClientBuilder#build方法\nbuild方法中核心就是50行的通过PulsarClientImpl构造函数创建客户端对象，其他的都是一些配置校验工作。下面就直接进入PulsarClientImpl的构造函数进行分析\n这个构造方法虽然逻辑不少，但实际上重要的就是201行的初始化\n三、创建网络连接池 1. 初始化 这里的ClientCnx对象非常重要，后面再细讲。现在先继续跟踪构造函数的逻辑\n这里初始化了Netty客户端，在跟外部创建网络连接时直接通过Netty客户端进行即可。客户端初始化阶段，网络连接池基本上就做了这些事，那么它是怎么工作的呢，让我们来往下看\n2. 工作流程 在创建生产者对象时，会走到PulsarClientImpl#getConnection这个方法，从这里开始进行分析\n此方法第一行是通过Lookup服务查找Topic归属的Broker节点信息，Lookup相关的感兴趣的可以看 Apache Pulsar源码解析之Lookup机制 这篇文章，在969行会将Lookup查到的Broker地址进行创建网络连接\n可以看到获取网络连接方法最终会调用ConnectionPool类的方法进行获取\n这里会根据参数randomKey(Broker IP地址)进行网络连接的复用，如果还没创建的话则进行创建，同时检查清理不可用的网络连接进行释放\n调用createConnection方法进行连接创建，同时也在通道创建通道成功后绑定监听器，在通道被关闭时一起关闭当前的网络连接。\n将unresolvedPhysicalAddress解析出正确的地址，现在还不太清楚已经有了logicalAddress(目标Broker地址)，还解析这个的用途是什么\n调用connectToAddress方法创建网络连接，如果出现异常时，如果服务端在Lookup阶段返回不止一个地址，那么就尝试跟下一个地址创建网络连接\n这里应该就很熟悉了，就是通过Netty客户端创建跟目标Broker节点的TCP连接。\n3. 小结 连接池是一个ConcurrentHashMap，key是IP+端口，value是ClientCnx来缓存这些连接。ClientCnx除了管理连接还管理所有的业务命令，例如发送消息是Send命令，服务端会对应一个handleSend方法来处理这个命令。\n连接池是客户端最重要的内容，无论是生产者还是消费者在创建的时候，都会去连接池获取/创建跟Broker的网络连接，后续的数据读写本质上都是通过Netty的channel进行的，因此可见它是相当重要的。连接池的设计将网络连接跟其他读写功能剥离开来达到职责分离的效果，同时通过池化概念，在多个生产者/消费者情况下不仅节约了网络连接的创建，同时还提升网络连接创建的性能(复用思路)。\n四、其他功能 1. LookupService Lookup机制工作逻辑在 Apache Pulsar源码解析之Lookup机制 这篇文章已经说明了，这里主要一起看看它的创建逻辑。在PulsarClientImpl构造函数中，我们能看到以下代码\nPulsar支持两种Lookup实现，一种是通过http协议去跟服务端通信，另一种是通过二进制方式查询(性能更好)。本次就跟着比较常见的http方式进行分析\n通过构造函数可以看到是通过创建HttpClient对象进行的，这里我一开始以为是用的开源的HttpClient就没继续跟，后来在调试的时候跟进去才发现，这是Pulsar 自定义对象\n跟踪进去看，其他都是赋值、安全检查的工作，核心在161行的httpClient创建。 这里可以看到是创建的AsyncHttpClient对象，这是一个封装Netty的async-http-client-2.12.1.jar的外部包，这是支持异步处理的高性能HTTP工具包\n2. MemoryLimitController 由于MemoryLimitController的内容不多，就看看它的创建以及工作流程\n在PulsarClientImpl的构造函数中可以看到会调用MemoryLimitController构造函数进行创造，从这里进去分析\n构造逻辑很简单，就只有赋值操作，到这里就成功创建MemoryLimitController对象了，那就再看看它是怎么工作的吧。MemoryLimitController的核心工作逻辑是checkTrigger方法\n这里会调用trigger的run方法，这个trigger的逻辑其实就是创建MemoryLimitController的构造方法第三个参数，也就是上面的reduceConsumerReceiverQueueSize方法，那么继续跟踪\n循环调用所有的消费者的reduceCurrentReceiverQueueSize方法，也就是说MemoryLimitController目前只能限制消费者的内存。\n这里的限制逻辑相当于将所有消费者的接收队列的容量减半，避免队列中的数据占用过多内存。由此可见MemoryLimitController目前做的还是比较小范围的内存控制，并且整体逻辑并不复杂。\n3. 线程池 客户端对象初始化时候，会创建三个线程池，现在就来分析下它们的用途\n首先是externalExecutorProvider线程池通过查看调用的方法，可以看到是被消费者使用，里面的工作线程主要是用于消费服务端的消息\n再来看看internalExecutorProvider线程池，可以看到是用来是一些跟偏向Pulsar系统层面的工作\n至于scheduledExecutorProvider相信就更简单了，顾名思义都是处理一些周期性的任务，例如下面的周期性的同步Topic分区信息到客户端\n五、总结 PulsarClient中的EventLoopGroup负责创建TCP连接，ConnectionPool对象负责管理连接，在创建ConnectionPool对象时会通过EventLoopGroup创建连接。 PulsarClient使用Netty来创建TCP连接，并管理一个连接池和两个线程池，所有Producer和Consumer都会复用PulsarClient的连接池和线程池，这样可以避免客户端创建过多的连接和线程。因此通常一个进程中只创建一个PulsarClient，每个Topic可以自己单独创建Producer和Consumer。 由于Broker使用了Reactor模型，单线程只负责转发事件，而数据的读取、解码、处理等都是在工作线程中完成的，也就是服务端所有请求都是异步完成的；客户端Producer/Consumer都是异步的，因此不存在单连接的性能问题。 PulsarClient默认只会与每个Broker建立一个连接，如果觉得不够可以通过配置来调大。 ClientCnx非常重要，这是netty的入队处理逻辑类。后续会专门针对这个类进行解析 ","date":"2024-07-17T10:34:21+08:00","image":"https://sherlock-lin.github.io/p/pulsarclient%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20240715212010651_hu12175125588812162081.png","permalink":"https://sherlock-lin.github.io/p/pulsarclient%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","title":"PulsarClient源码解析"},{"content":"引言 知乎上有一个热门的问题，什么是人生的顶级享受？ 看到这个问题我回想到了多年前，那个炎热的午后，我在学校的图书馆里，一边参照书籍，一边用着一部破旧的thinkpad敲着一行行Java代码，写一会执行调试一下，或皱眉，或喜笑颜开，这是在外人的视角；而内心世界里，我仿佛就是一个无所不能的魔法师🧙‍♀️，一挥动魔法棒🪄，高楼大厦拔地而起，再念一段咒语，山川河流、各个形态的动物都随我所想的模样出现，最后大喝一声，“启动～”，这个“世界”就仿佛被赋予了生命力一样活了过来，河流唱着歌从高山流下来，经过嬉闹的丛林，丛林里小鹿在跟蝴蝶🦋嬉闹，此时池边蛰伏已久的鳄鱼🐊正准备扑向小鹿，只听我大喝一声，“停～”，整个世界就像按下了暂停键，所有东西都停止在那一刻，于是乎我敲着键盘重新编码鳄鱼的行为，鳄鱼不需要捕食其他动物也能存活，只需要通过呼吸和喝水也能获得足够能量。有人说，你这不胡扯吗，这怎么可能？但这就是可以的，因为这是属于我的世界，这就是编程的世界。\n编程的本质 编程的本质是什么，过去我经验尚浅不敢写这种内容，现如今工作久了脸皮厚了，尝试写一下吧。编程跟其他所有脑力密集型行业一样，本质工作都是设计。政治家的设计，是解决如何让一个国家变得更加富强；建筑师的设计，是解决如何让大楼可以同时兼顾稳定、优雅美观；飞机建造者的设计，是解决如何低成本建造出性能优越的飞机等等，而编程也是一样，程序员也就是coder解决的是，如何用软件解决真实世界的各个业务场景的问题，同时在性能和成本方面都要有一定的要求。但有别于其他行业，编程可以让设计者快速、低成本的验证自己的想法，设计飞机的人，要是下一秒就能看到自己亲手设计的飞机翱翔在天空中的姿态，设计社会框架例如理想国的人，要是下一秒就能看到自己设计的国度等等，那会是多么幸福的一件事情，而编程恰恰就可以！在大部分场景，只需要在编译器中执行一下，自己的想法立马就能得到验证。因此，虽然编程发展了几十年，相关的编程语言数不胜数，涉及的领域从最开始的破译军事机密、到原子弹研究逐步到现在的互联网商业，再到元宇宙、GPT等等，但万物不离其宗，本质都是通过设计来解决特定场景的问题。因此，程序员的核心竞争力应该是思维或者是设计能力，而远远不是具体的某一门编程语言，某一项技术，更不应该是某个职称。因此笔者认为，如果热爱编程，应该更看重如何提升自己设计能力以及解决问题能力，切勿因为一些非重要的事情乱了道心。\n工作与编程 大概是从12年左右开始，国内互联网行业迎来了大爆发，由于行业红利，大批人转到互联网行业来，相关的培训机构也如雨后春笋增长了起来，大幅降低了程序员的门槛。因此互联网行业鱼龙混杂，有特别特别牛的大佬，同时也有很多不具备所谓编程思维的程序员，而目前互联网行业的公司，大部分的工作内容基本都是CURD，更有甚者基本都不编程，每天开不完的会以及拉通对齐。在这里并不是要批判什么，而是想跟热爱编程的伙伴说，即便工作很忙以及工作上很少用到编程，但也请别放弃对编程的热爱。过去我认为对于程序员来说，工作等同于编程，工作需要什么就去学什么以及使用什么，而因为种种因素，最终逐渐丧失对编程的热爱。而现在，我跟喜欢将工作与编程分开，就像两个进程一样互相资源隔离，但又偶尔保持联系。一方面在将工作做好的同时也提升自己的沟通表达、拆解抽象问题的能力，这个过程中学到的东西是有助于咱们去学编程；另一方面，在学习编程时，提升对技术的深广度理解，又能更好的作用于日常的工作，而脱离了工作的限制，咱们可以大幅发挥自己的热爱，内心真心想学什么就大胆去学，不用考虑具体的技术是否能应用到当前的工作，尽可能的深挖，因为技术都是自相似的，任何东西学到一定的深度要考虑的问题以及解决方式都是相似的，但区别就在于需要你静下心来去思考沉淀。千万不要因为社会上的一些焦虑言论止步探索的那颗心，编程跟其他技能爱好一样，需要大量的时间沉淀磨练，相对应的，它也会给你很丰厚的反馈；因此，好好享受编程吧～\n编程的未来 现如今，随着GPT、人工智能的爆火，也逐步出现自动写代码的程序，也许未来真的可以取代人类进行编程。针对这个情况，我也分享下我的看法\n思维 如果编程水平一直停留在入门级别，那确实很容易被取代，即便不是人工智能，也同样会有很多其他比你厉害的人取代你，因此我们需要不断提升自己的技术能力以及业务能力，如果你能对业务很了解并且能用对应的技术实现业务并解决业务的痛点，那么恭喜你，基本上不用担心被人工智能取代，而是应该抱着积极的心态，因为人工智能说白了也是工具，需要人去驾驭，而你通过驾驭它可以比别人更好的完成业务，这是一件值得兴奋的事情 自我修行 退一步来说，即使在未来人工智能已彻底取代人类编程的工作，我们真的就要放弃编程吗？同理放在其他场景，现在人工智能击败了柯洁，那么人类就不用围棋了吗？如果有一天人工智能也能拉出很好听的小提琴曲子，人类就彻底放弃小提琴了吗？ 因此这个问题其实是有点荒谬的，说到底，其实像这些技能本质上是 道-术-器中的器，是要通过器来习得术和道，这个过程只能自己来，没有人能替我们走，人工智能更不行。因此现在能看到，即便机器臂已经能发挥比人类很大的力量，依然有很多人在锻炼自己的身体肌肉，即便人工智能不停的在各个领域打破一些人的记录，但一样有无数的在在这个领域继续自我突破。说白了，这不是人跟人工智能的较量，而是一场人跟自己的较量，因此无论人工智能发展到何种程度，人类依然不会停止修行突破，那么多行业都如此，编程怎会例外 最后，我非常庆幸能成为一名coder，我周围所看到的程序员伙伴都是比较单纯、朴素、和对生活充满热爱的一群人，跟大家伙一样，我们也在用自己的方式给这个世界添砖加瓦，发光发热～\n","date":"2024-04-28T15:09:13+08:00","image":"https://sherlock-lin.github.io/p/%E7%BC%96%E7%A8%8B%E6%9C%AC%E6%BA%90/image-20240920151110972_hu12095366861263762317.png","permalink":"https://sherlock-lin.github.io/p/%E7%BC%96%E7%A8%8B%E6%9C%AC%E6%BA%90/","title":"编程本源"},{"content":"引言 你是否遇到以下问题\n时间过得很快，不知道过去在忙什么 事情很多很杂，感觉一直都很忙但是好像也没啥收获 生活、工作中不顺心的事情很多，心里比较烦躁压抑 那么可以尝试参考《奇特的一生》中的男主一样，尝试将每天重要的事情、思考记录下来，通过每天输出记录来促进自己反思，同时文字还有疗伤的功效，很多气愤恼怒的问题，在你用文字输出后情绪能能得到不少的缓解。有人可能会觉得每天都很忙了哪有时间来进行记录，其实不然，每天只需要花不到十分钟的时间记录核心的一件事情、分析原因以及改进措施就够了，所带来的好处我总结了下大概有以下三点\n节省生命 提升感知细节的能力 正视痛苦 节省生命 我们平时会是不是冒出一些想法💡、灵感，如果不记录下来很快就会遗忘从而导致浪费生命，例如本人之前在处理一个问题时最后所探索出来的解决方式之前就有思考🤔过，但是由于没记录下来又白白浪费这次的时间。因为灵感虽然是一瞬间冒出来的，但是背后却是一段生活经历的积累。如果不记录下来后面可能还是会不断的出现导致生命变得低效。 另一方面，我们每天要面对的事情非常的多，大致可以分为重要紧急、重要不紧急、不重要紧急，不重要不紧急。有时候我们可能会陷入里面不那么重要的事情，导致影响了重要紧急的事情，这是由于当局者迷，而记录的方式可以帮助我们以第三人称的视角的审视，进而调整自己的工作安排，更加有的放矢。\n感知细节的能力 在不反思的情况下，我们的生活会变得很“粗糙”从而导致虽然做了很多事但是也没有感觉，而通过记录就可以从很多微小的时间从捕捉感触合馆来呢，一个动作、一句话、一个场景、一个选择、一种情绪等都会让人产生感悟，甚至每天心中都会去反思这件事，这回让我们对生活的觉知有很大的提升。通过每天定期记录，我们自己也会下意识的去思考，现在在做的这件事是什么？为什么要去做？怎么样可以做得更好等等，从而偏向于做更重要的事情并且放更多的精力在这件事情上，由于思考投入比较多，我们对这件事的细节流程也会格外的印象深刻。\n正视痛苦 人生在世，难免会遇到很多耿耿于怀、气愤、悲伤的事情，此时大多数人会选择逃避，沉浸在负面情绪中。而反思天然就有正视痛苦的力量，通过反思，通过记录，你就会以第三人称的视角，像是看别人的故事一般客观的去分析思考这件事情，通过客观的思考分析就能将情绪和事件抽离开来，针对事件中自己需要改进的点记录下来避免下次再犯，进而得到提升以及成长。这才是痛苦促进人进步的核心，因此即便遇到再难过的事情都可以尝试记录下来分析，久而久之再遇到痛苦悲伤的事情 我们也不会那么害怕，因为换个视角这又是一次提升自我的机会。\n总结 最后，我祝愿大家身体健康、万事顺心，如果不行的话那就祝愿大家都有面对、解决痛苦的能力，以及过上高效、快意的人生～\n","date":"2024-04-19T15:09:14+08:00","image":"https://sherlock-lin.github.io/p/%E8%AE%B0%E5%BD%95%E6%96%B9%E5%BC%8F%E9%87%8D%E6%96%B0%E6%89%93%E5%BC%80%E4%BA%BA%E7%94%9F/f6bca0216ea5e504d6fd85e06d61631d_hu17895883417847532878.png","permalink":"https://sherlock-lin.github.io/p/%E8%AE%B0%E5%BD%95%E6%96%B9%E5%BC%8F%E9%87%8D%E6%96%B0%E6%89%93%E5%BC%80%E4%BA%BA%E7%94%9F/","title":"记录方式重新打开人生"},{"content":"一、介绍 在软件设计中，为了方便能够应对不同的场景，一般在一些容易有差异的环节会考虑允许用户自定义逻辑，拦截器就是其中的一种实现方式，像Spring、Kafka、Pulsar等都支持这种方式。流程简化起来就如下图，客户端跟服务端的写消息请求和接收请求都要先通过一遍拦截器，因此用户都过自定义拦截器逻辑就能以一种无侵入、规范化的方式来改动消息发送以及处理响应的行为。\n二、使用 1. ProducerInterceptor接口 ProducerInterceptor是Pulsar提供的接口，通过实现该接口用户可以在消息发送和发送成功阶段注入自定义的逻辑来扩展Pulsar客户端的能力，进而优雅的解决某些场景的问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @InterfaceAudience.Public @InterfaceStability.Stable public interface ProducerInterceptor extends AutoCloseable { void close(); boolean eligible(Message message); Message beforeSend(Producer producer, Message message); void onSendAcknowledgement( Producer producer, Message message, MessageId msgId, Throwable exception); default void onPartitionsChange(String topicName, int partitions) { } } 这里针对这五个方法大概介绍下\nclose：由于该接口实现了AutoCloseable，因此也要定义生产者关闭时要释放的资源，如果没有就空着 eligible：判断拦截器针对那些消息生效，默认false不生效。这个相当于Java8 Stream里的filter，属于职责分离的设计 beforeSend：在每条消息要发送时会调用此方法，因此如果在发送前想做点什么可以考虑在这里实现 onSendAcknowledgement：在每条消息消息发送服务端响应后(无论成功失败)会调用此方法 onPartitionsChange：在分区数有变动的时候会调用这里的逻辑。这是3.2版本新加的逻辑，2.8以及之前的版本没有此接口 2. 实现之统计 这里对生产者累计发送的消息条数进行统计，实现逻辑如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class SherlockCountProducerInterceptor implements ProducerInterceptor { private AtomicLong count = new AtomicLong(1); @Override public void close() { } @Override public boolean eligible(Message message) { return true; } @Override public Message beforeSend(Producer producer, Message message) { System.out.println(\u0026#34;累计发送消息条数：\u0026#34;+count.getAndIncrement()); return message; } @Override public void onSendAcknowledgement(Producer producer, Message message, MessageId msgId, Throwable exception) { } } 逻辑比较简单，其实就是通过一个计数器在每次发送时进行加1即可，并且在eligible中返回true也就是对所有发送的消息都生效，每条消息在发送前都会调用一次beforeSend方法进行自增操作并打印出来。\n现在拦截器的逻辑已经定义好了，接下来怎么使用呢，请继续往下看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public static void customInterceptorProducer() throws Exception { String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); Producer\u0026lt;String\u0026gt; producer = pulsarClient.newProducer(Schema.STRING) .topic(\u0026#34;sherlock-api-tenant-1/sherlock-namespace-1/partition_partition_topic_3\u0026#34;) .intercept(new SherlockCountProducerInterceptor())\t//拦截器生效逻辑 .create(); for (int i = 0; i \u0026lt; 200; i++) { producer.send(\u0026#34;hello java API pulsar:\u0026#34;+i+\u0026#34;, 当前时间为：\u0026#34;+new Date()); } producer.close(); pulsarClient.close(); } 上述就是使用拦截器的case，通过这种方式就能轻松的定义所需要注入的逻辑。上述代码执行后输出如下\n可以看到我们通过拦截器完成了消息发送的统计功能，可以发散设想一想，像根据不同key进行分组统计、统计某个时间段消息发送失败的条数等功能也同样可以通过拦截器实现。\n3. 实现之二次处理 实现统计感觉还不得劲，再折腾一个。假设咱们的生产者中会发送很多地区的消息，这些消息有些是中国的，有些是新加坡的，有些是巴西的，这个时候它们的时间就有歧义了，因为不同时区的时间是有差异的，那咱们尝试用拦截器来实现一下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public class SherlockAdapterTimeProducerInterceptor implements ProducerInterceptor { @Override public void close() { } @Override public boolean eligible(Message message) { // if (\u0026#34;V3\u0026#34;.equals(String.valueOf(message.getSchemaVersion()))) { // return true; // } if (\u0026#34;Singapore\u0026#34;.equals(message.getKey())) { System.out.println(\u0026#34;这条消息是新加坡地区的，进行处理！\u0026#34;); return true; } System.out.println(\u0026#34;这条消息是中国地区的，不进行处理！\u0026#34;); return false; } @Override public Message beforeSend(Producer producer, Message message) { System.out.println(\u0026#34;拦截到一条新加坡地区的消息，现在进行处理，消息内容为：\u0026#34;+message.getValue()); return message; } @Override public void onSendAcknowledgement(Producer producer, Message message, MessageId msgId, Throwable exception) { } } 上面就是demo，继续将这个拦截器应用于生产者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public static void customInterceptorProducer() throws Exception { String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); Producer\u0026lt;String\u0026gt; producer = pulsarClient.newProducer(Schema.STRING) .topic(\u0026#34;sherlock-api-tenant-1/sherlock-namespace-1/partition_partition_topic_3\u0026#34;) .intercept(new SherlockAdapterTimeProducerInterceptor()) .create(); producer.newMessage().key(\u0026#34;China\u0026#34;).value(\u0026#34;下单动作\u0026#34;).send(); producer.newMessage().key(\u0026#34;Singapore\u0026#34;).value(\u0026#34;收藏动作\u0026#34;).send(); producer.newMessage().key(\u0026#34;China\u0026#34;).value(\u0026#34;取消动作\u0026#34;).send(); producer.newMessage().key(\u0026#34;Singapore\u0026#34;).value(\u0026#34;订阅动作\u0026#34;).send(); producer.close(); pulsarClient.close(); } 执行可以看到下面的输出\n通过输出的结果可以分析出来eligible的逻辑是生效的，针对新加坡地区的消息会进行处理，而中国的消息保持不变，所有地区的时间通过此拦截器来统一成东八区的时间。\n4. 小结 通过上述例子可以看到我们可以通过拦截器实现任意的逻辑，但是这里需要注意的是，拦截器里面尽量不要放过多的逻辑，因为这可能会影响生产者发送消息的速度，并且也容易造成处理逻辑的分散。拦截器最好是做一些校验、适配、状态记录等一些需要前置完成并且轻量级的操作。\n三、实现原理 1. 初始化流程 通过使用我们可以看到在创建生产者对象是只要通过.intercept方法传入拦截器对象即可生效，那么我们就先通过这个方法来看看实现逻辑\n1 2 3 4 5 6 7 8 9 10 ProducerBuilder\u0026lt;T\u0026gt; intercept(org.apache.pulsar.client.api.interceptor.ProducerInterceptor... interceptors); public ProducerBuilder\u0026lt;T\u0026gt; intercept(ProducerInterceptor... interceptors) { if (this.interceptorList == null) { this.interceptorList = new ArrayList(); } this.interceptorList.addAll(Arrays.asList(interceptors)); return this; } 通过代码跟踪可以看到ProducerBuilderImpl方法中会先将拦截器对象集合赋值给自己的成员变量，也就是它先保存一份在后面使用。在最终调用create方法来创建Producer时，最终会走到该类的createAsync方法，核心逻辑如下\n1 2 3 4 5 public CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; createAsync() { .... return this.interceptorList != null \u0026amp;\u0026amp; this.interceptorList.size() != 0 ? this.client.createProducerAsync(this.conf, this.schema, new ProducerInterceptors(this.interceptorList)) : this.client.createProducerAsync(this.conf, this.schema, (ProducerInterceptors)null); } } 如果用户通过.intercept方法传入了自定义的拦截器，则会调用PulsarClientImpl带有拦截器对象的构造方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public \u0026lt;T\u0026gt; CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; createProducerAsync(ProducerConfigurationData conf, Schema\u0026lt;T\u0026gt; schema, ProducerInterceptors interceptors) { .... //这个方法的核心逻辑就这一行，继续往下跟踪 return this.createProducerAsync(topic, conf, schema, interceptors); } private \u0026lt;T\u0026gt; CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; createProducerAsync(String topic, ProducerConfigurationData conf, Schema\u0026lt;T\u0026gt; schema, ProducerInterceptors interceptors) { .... //同理，核心逻辑就这一行 producer = this.newProducerImpl(topic, -1, conf, schema, interceptors, producerCreatedFuture); } protected \u0026lt;T\u0026gt; ProducerImpl\u0026lt;T\u0026gt; newProducerImpl(....) { return new ProducerImpl(this, topic, conf, producerCreatedFuture, partitionIndex, schema, interceptors); } public ProducerImpl(PulsarClientImpl client, String topic, ProducerConfigurationData conf, CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; producerCreatedFuture, int partitionIndex, Schema\u0026lt;T\u0026gt; schema, ProducerInterceptors interceptors) { //只有这里有用到，继续跟踪 super(client, topic, conf, producerCreatedFuture, schema, interceptors); .... } protected ProducerBase(PulsarClientImpl client, String topic, ProducerConfigurationData conf, CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; producerCreatedFuture, Schema\u0026lt;T\u0026gt; schema, ProducerInterceptors interceptors) { .... //对父类的成员变量进行赋值 this.interceptors = interceptors; } 通过上面的代码跟踪我们可以知道，当我们通过拦截器创建的Producer对象，它是有在内部维护一个ProducerInterceptors对象来存储我们所指定的拦截器集合的逻辑\n那么我们来看看ProducerInterceptors的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 public class ProducerInterceptors implements Closeable { .... private final List\u0026lt;ProducerInterceptor\u0026gt; interceptors;\t//存储拦截器集合逻辑 .... //在消息发送前进行触发 public Message beforeSend(Producer producer, Message message) { Message interceptorMessage = message; for (ProducerInterceptor interceptor : interceptors) { //调用拦截器的eligible方法来判断是否要对当前这条消息进行拦截处理，这个就是咱们上面实现的eligible接口 if (!interceptor.eligible(message)) { continue; } try { //循环调用拦截器集合里的每个拦截器对这条消息进行处理 interceptorMessage = interceptor.beforeSend(producer, interceptorMessage); } catch (Throwable e) { .... } } return interceptorMessage; } //逻辑跟beforeSend基本一致 public void onSendAcknowledgement(Producer producer, Message message, MessageId msgId, Throwable exception) { for (ProducerInterceptor interceptor : interceptors) { if (!interceptor.eligible(message)) { continue; } try { interceptor.onSendAcknowledgement(producer, message, msgId, exception); } catch (Throwable e) { log.warn(\u0026#34;Error executing interceptor onSendAcknowledgement callback \u0026#34;, e); } } } public void onPartitionsChange(String topicName, int partitions) { for (ProducerInterceptor interceptor : interceptors) { try { interceptor.onPartitionsChange(topicName, partitions); } catch (Throwable e) { log.warn(\u0026#34;Error executing interceptor onPartitionsChange callback \u0026#34;, e); } } } @Override public void close() throws IOException { for (ProducerInterceptor interceptor : interceptors) { try { interceptor.close(); } catch (Throwable e) { log.error(\u0026#34;Fail to close producer interceptor \u0026#34;, e); } } } } 通过上述逻辑可以看到ProducerInterceptors本质上就是个批量管理对象，符合高内聚低耦合的设计，解耦了业务逻辑循环处理的逻辑，将这些循环处理的逻辑都封装在ProducerInterceptors类里面，然后ProducerInterceptors仅对外提供触发某几个动作的api，业务只需要在哪个阶段调用这些api即可。\n2. 生效流程 在生产者消息发送阶段，最终都会走到ProducerImpl类的internalSendAsync方法，可以看到这里会调用拦截器进行处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 CompletableFuture\u0026lt;MessageId\u0026gt; internalSendAsync(Message\u0026lt;?\u0026gt; message) { //核心方法，跟踪进去 MessageImpl\u0026lt;?\u0026gt; interceptorMessage = (MessageImpl) beforeSend(message); .... } protected Message\u0026lt;?\u0026gt; beforeSend(Message\u0026lt;?\u0026gt; message) { if (interceptors != null) { //如果配置了拦截器则调用ProducerInterceptors类的beforeSend方法 return interceptors.beforeSend(this, message); } else { //如果没有配置拦截器则直接返回原消息 return message; } } 这是消息发送的处理逻辑，那如果是再消息发送结束后触发呢？一起来跟踪看下吧，首先还是从ProducerImp类的internalSendAsync方法开始看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Override CompletableFuture\u0026lt;MessageId\u0026gt; internalSendAsync(Message\u0026lt;?\u0026gt; message) { sendAsync(interceptorMessage, new SendCallback() { .... @Override public void sendComplete(Exception e) { try { if (e != null) { stats.incrementSendFailed(); //从这里跟踪进去看看 onSendAcknowledgement(interceptorMessage, null, e); future.completeExceptionally(e); } else { onSendAcknowledgement(interceptorMessage, interceptorMessage.getMessageId(), null); future.complete(interceptorMessage.getMessageId()); stats.incrementNumAcksReceived(System.nanoTime() - createdAt); } } finally { interceptorMessage.getDataBuffer().release(); } } protected void onSendAcknowledgement(Message\u0026lt;?\u0026gt; message, MessageId msgId, Throwable exception) { if (interceptors != null) { //可以看到最终也是调用的ProducerInterceptors类的onSendAcknowledgement方法 interceptors.onSendAcknowledgement(this, message, msgId, exception); } } 这里的设计是异步回调的方式，将调用拦截器处理逻辑封装成参数传给下一层，在消息发送完成后再调用参数里指定的回调逻辑。那么什么时候触发呢，由于Pulsar客户端跟服务端是通过Netty的TCP通信的，因此直接看看PulsarDecoder的channelRead方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { .... switch (cmd.getType()) { .... case PRODUCER_SUCCESS: //写入消息被Broker处理后会忘生产者客户端通过TCP发送一条PRODUCER_SUCCESS类型的消息也就是这里，跟踪进去看看处理逻辑 checkArgument(cmd.hasProducerSuccess()); handleProducerSuccess(cmd.getProducerSuccess()); break; } } protected void handleProducerSuccess(CommandProducerSuccess success) { .... //生产者会在队列维护每条未被ack的写入请求消息，在Broker ack时会从这个队列中移除并获取回调处理逻辑 CompletableFuture\u0026lt;ProducerResponse\u0026gt; requestFuture = (CompletableFuture\u0026lt;ProducerResponse\u0026gt;) pendingRequests.remove(requestId); if (requestFuture != null) { ProducerResponse pr = new ProducerResponse(success.getProducerName(), success.getLastSequenceId(), success.getSchemaVersion(), success.hasTopicEpoch() ? Optional.of(success.getTopicEpoch()) : Optional.empty()); //调用回调逻辑 requestFuture.complete(pr); } else { .... } } 四、总结 通过使用和跟踪原理，我们对Pulsar生产者拦截器有了进一步的认识，除了生产者拦截器，Pulsar还支持Broker侧以及Bookkeeper侧的拦截器，这些放到后面再跟大家一起学习。\n","date":"2024-04-19T11:54:03+08:00","image":"https://sherlock-lin.github.io/p/%E6%B7%B1%E5%85%A5%E6%8E%A2%E7%B4%A2%E7%94%9F%E4%BA%A7%E8%80%85%E6%8B%A6%E6%88%AA%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E4%BB%A5%E5%8F%8A%E6%BA%90%E7%A0%81%E8%AE%BE%E8%AE%A1/image-20240419110502648_hu11315331606035570821.png","permalink":"https://sherlock-lin.github.io/p/%E6%B7%B1%E5%85%A5%E6%8E%A2%E7%B4%A2%E7%94%9F%E4%BA%A7%E8%80%85%E6%8B%A6%E6%88%AA%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E4%BB%A5%E5%8F%8A%E6%BA%90%E7%A0%81%E8%AE%BE%E8%AE%A1/","title":"深入探索生产者拦截器的使用以及源码设计"},{"content":"一、正文 Namespace下的Topic是分Bundle进行管理的，每个Namespace都是一个哈希环，而Bundle负责管理环上某个范围上的Topic。通过这种方式可以更好的进行Topic的管理。当某个Bundle上负责的Topic越来越多时，会导致负责该Bundle的Broker节点压力变大。因此Pulsar还提供了Bundle分裂的机制，这个机制支持自动触发以及手动触发，今天这篇文章就从源码的角度分析手动触发Bundle分裂时服务端会发生什么\n主动触发Bundle分裂操作方式\n1 2 3 4 5 6 7 8 9 10 bin/pulsar-admin namespaces bundles public/default //输出如下 { \u0026#34;boundaries\u0026#34; : [ \u0026#34;0x00000000\u0026#34;, \u0026#34;0x08000000\u0026#34;, \u0026#34;0x10000000\u0026#34;, \u0026#34;0x20000000\u0026#34;, \u0026#34;0x30000000\u0026#34;, \u0026#34;0x40000000\u0026#34;, \u0026#34;0x50000000\u0026#34;, \u0026#34;0x60000000\u0026#34;, \u0026#34;0x70000000\u0026#34;, \u0026#34;0x80000000\u0026#34;, \u0026#34;0x90000000\u0026#34;, \u0026#34;0xa0000000\u0026#34;, \u0026#34;0xb0000000\u0026#34;, \u0026#34;0xc0000000\u0026#34;, \u0026#34;0xd0000000\u0026#34;, \u0026#34;0xe0000000\u0026#34;, \u0026#34;0xf0000000\u0026#34;, \u0026#34;0xffffffff\u0026#34; ], \u0026#34;numBundles\u0026#34; : 17 } //指定某个bundle进行分裂 bin/pulsar-admin namespaces split-bundle --bundle 0x00000000_0x10000000 public/default 二、源码解析 Pulsar管理流相关的操作都是通过HTTP的方式，因为需要支持多种客户端类型(http、client、cli)。服务端处理这些操作都在admin模块下，如下图，本次要聊的bundle分裂就在Namespaces方法中\n首先从Namespaces的splitNamespaceBundle进行跟踪\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void splitNamespaceBundle( .... @QueryParam(\u0026#34;splitAlgorithmName\u0026#34;) String splitAlgorithmName, //指定bundle分裂算法 @ApiParam(\u0026#34;splitBoundaries\u0026#34;) List\u0026lt;Long\u0026gt; splitBoundaries) { //校验参数格式以及是否存在对应的namespace validateNamespaceName(tenant, namespace); //异步进行分裂操作 internalSplitNamespaceBundleAsync(bundleRange, authoritative, unload, splitAlgorithmName, splitBoundaries) .thenAccept(__ -\u0026gt; { .... }) .exceptionally(ex -\u0026gt; { .... }); } 可以看到最外层只是做些参数校验，那么就继续跟踪internalSplitNamespaceBundleAsync方法，如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 protected CompletableFuture\u0026lt;Void\u0026gt; internalSplitNamespaceBundleAsync(String bundleName, boolean authoritative, boolean unload, String splitAlgorithmName, List\u0026lt;Long\u0026gt; splitBoundaries) { return validateSuperUserAccessAsync() //权限校验 .thenAccept(__ -\u0026gt; { checkNotNull(bundleName, \u0026#34;BundleRange should not be null\u0026#34;); log.info(\u0026#34;[{}] Split namespace bundle {}/{}\u0026#34;, clientAppId(), namespaceName, bundleName); //获取当前集群所支持的bundle分裂算法，这里是硬编码的固定四种 List\u0026lt;String\u0026gt; supportedNamespaceBundleSplitAlgorithms = pulsar().getConfig().getSupportedNamespaceBundleSplitAlgorithms(); //此处省去参数检查逻辑 .... } }) .thenCompose(__ -\u0026gt; { //此处省去参数检查逻辑 .... }) .thenCompose(__ -\u0026gt; validatePoliciesReadOnlyAccessAsync()) //权限校验 .thenCompose(__ -\u0026gt; getBundleRangeAsync(bundleName)) //获取要分裂的bundle的范围 .thenCompose(bundleRange -\u0026gt; { return getNamespacePoliciesAsync(namespaceName) .thenCompose(policies -\u0026gt; //1. 校验Bundle的范围是否有效 //2.判断当前Broker节点是否负责这个bundle的管理，如果不是则重定向 validateNamespaceBundleOwnershipAsync(namespaceName, policies.bundles, bundleRange,authoritative, false)) //核心方法就是这里的 NamespaceService.splitAndOwnBundle .thenCompose(nsBundle -\u0026gt; pulsar().getNamespaceService().splitAndOwnBundle(nsBundle, unload, pulsar().getNamespaceService() .getNamespaceBundleSplitAlgorithmByName(splitAlgorithmName), splitBoundaries)); }); } 接下来就是进入NamespaceService类的splitAndOwnBundle方法，NamespaceService也是Pulsar比较重要的一个类，这里先继续跟踪分割bundle的逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 public CompletableFuture\u0026lt;Void\u0026gt; splitAndOwnBundle(NamespaceBundle bundle, boolean unload, NamespaceBundleSplitAlgorithm splitAlgorithm, List\u0026lt;Long\u0026gt; boundaries) { //如果实现了自定义的分割逻辑则使用自定义的 if (ExtensibleLoadManagerImpl.isLoadManagerExtensionEnabled(config)) { return ExtensibleLoadManagerImpl.get(loadManager.get()) .splitNamespaceBundleAsync(bundle, splitAlgorithm, boundaries); } final CompletableFuture\u0026lt;Void\u0026gt; unloadFuture = new CompletableFuture\u0026lt;\u0026gt;(); final AtomicInteger counter = new AtomicInteger(BUNDLE_SPLIT_RETRY_LIMIT); //核心流程流程 splitAndOwnBundleOnceAndRetry(bundle, unload, counter, unloadFuture, splitAlgorithm, boundaries); return unloadFuture; } void splitAndOwnBundleOnceAndRetry(NamespaceBundle bundle, boolean unload, AtomicInteger counter, CompletableFuture\u0026lt;Void\u0026gt; completionFuture, NamespaceBundleSplitAlgorithm splitAlgorithm, List\u0026lt;Long\u0026gt; boundaries) { //获取bundle分割配置 BundleSplitOption bundleSplitOption = getBundleSplitOption(bundle, boundaries, config); //根据配置来选择对应的分割算法进行分割 splitAlgorithm.getSplitBoundary(bundleSplitOption).whenComplete((splitBoundaries, ex) -\u0026gt; { CompletableFuture\u0026lt;List\u0026lt;NamespaceBundle\u0026gt;\u0026gt; updateFuture = new CompletableFuture\u0026lt;\u0026gt;(); if (ex == null) { .... try { //进行bundle分割操作 bundleFactory.splitBundles(bundle, splitBoundaries.size() + 1, splitBoundaries) .thenAccept(splitBundles -\u0026gt; { .... Objects.requireNonNull(splitBundles.getLeft()); Objects.requireNonNull(splitBundles.getRight()); checkArgument(splitBundles.getRight().size() == splitBoundaries.size() + 1, \u0026#34;bundle has to be split in \u0026#34; + (splitBoundaries.size() + 1) + \u0026#34; bundles\u0026#34;); NamespaceName nsname = bundle.getNamespaceObject(); .... try { // 检查确保每个Bundle都有对应的Broker负责 for (NamespaceBundle sBundle : splitBundles.getRight()) { Objects.requireNonNull(ownershipCache.tryAcquiringOwnership(sBundle)); } //更新Bundle信息，毕竟Bundle已经分裂好了，相关的一些元数据要同步更新 updateNamespaceBundles(nsname, splitBundles.getLeft()).thenCompose(__ -\u0026gt; updateNamespaceBundlesForPolicies(nsname, splitBundles.getLeft())) .thenRun(() -\u0026gt; { bundleFactory.invalidateBundleCache(bundle.getNamespaceObject()); updateFuture.complete(splitBundles.getRight()); }).exceptionally(ex1 -\u0026gt; { .... }); } catch (Exception e) { .... } }); } catch (Exception e) { .... } } else { updateFuture.completeExceptionally(ex); } updateFuture.whenCompleteAsync((r, t)-\u0026gt; { if (t != null) { // 失败则重试几次 if ((t.getCause() instanceof MetadataStoreException.BadVersionException) \u0026amp;\u0026amp; (counter.decrementAndGet() \u0026gt;= 0)) { pulsar.getExecutor().schedule(() -\u0026gt; pulsar.getOrderedExecutor() .execute(() -\u0026gt; splitAndOwnBundleOnceAndRetry( bundle, unload, counter, completionFuture, splitAlgorithm, boundaries)), 100, MILLISECONDS); } else if (t instanceof IllegalArgumentException) { completionFuture.completeExceptionally(t); } else { // Retry enough, or meet other exception String msg2 = format(\u0026#34; %s not success update nsBundles, counter %d, reason %s\u0026#34;, bundle.toString(), counter.get(), t.getMessage()); LOG.warn(msg2); completionFuture.completeExceptionally(new ServiceUnitNotReadyException(msg2)); } return; } //更新bundle的状态 getOwnershipCache().updateBundleState(bundle, false) .thenRun(() -\u0026gt; { // update bundled_topic cache for load-report-generation pulsar.getBrokerService().refreshTopicToStatsMaps(bundle); loadManager.get().setLoadReportForceUpdateFlag(); // release old bundle from ownership cache pulsar.getNamespaceService().getOwnershipCache().removeOwnership(bundle); completionFuture.complete(null); if (unload) { // Unload new split bundles, in background. This will not // affect the split operation which is already safely completed r.forEach(this::unloadNamespaceBundle); } onNamespaceBundleSplit(bundle); }) .exceptionally(e -\u0026gt; { .... }); }, pulsar.getOrderedExecutor()); }); } 上面这个方法的逻辑比较丰富，但核心的分割流程实际上是调用的NamespaceBundleFactory的splitBundles进行的，这里就继续跟踪NamespaceBundleFactory的逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 public CompletableFuture\u0026lt;Pair\u0026lt;NamespaceBundles, List\u0026lt;NamespaceBundle\u0026gt;\u0026gt;\u0026gt; splitBundles( NamespaceBundle targetBundle, int argNumBundles, List\u0026lt;Long\u0026gt; splitBoundaries) { //判断当前bundle是否支持分裂 checkArgument(canSplitBundle(targetBundle), \u0026#34;%s bundle can\u0026#39;t be split further since range not larger than 1\u0026#34;, targetBundle); .... NamespaceName nsname = targetBundle.getNamespaceObject(); final int numBundles = argNumBundles; return bundlesCache.get(nsname).thenApply(sourceBundle -\u0026gt; { final int lastIndex = sourceBundle.partitions.length - 1; //重新创建数组保存哈希环的节点，因为bundle分裂后环上的节点会增多 final long[] partitions = new long[sourceBundle.partitions.length + (numBundles - 1)]; int pos = 0; int splitPartition = -1; final Range\u0026lt;Long\u0026gt; range = targetBundle.getKeyRange(); for (int i = 0; i \u0026lt; lastIndex; i++) { //遍历当前Namespace的所有Bundle来找到需要进行分裂的目标Bundle if (sourceBundle.partitions[i] == range.lowerEndpoint() \u0026amp;\u0026amp; (range.upperEndpoint() == sourceBundle.partitions[i + 1])) { splitPartition = i; long minVal = sourceBundle.partitions[i]; partitions[pos++] = minVal; if (splitBoundaries == null || splitBoundaries.size() == 0) { long maxVal = sourceBundle.partitions[i + 1]; //numBundles就是要分割成的份数，这里相当于将原先Bundle负责的范围平均分给多个新的Bundle long segSize = (maxVal - minVal) / numBundles; long curPartition = minVal + segSize; for (int j = 0; j \u0026lt; numBundles - 1; j++) { partitions[pos++] = curPartition; curPartition += segSize; } } else { for (long splitBoundary : splitBoundaries) { partitions[pos++] = splitBoundary; } } } else { partitions[pos++] = sourceBundle.partitions[i]; } } partitions[pos] = sourceBundle.partitions[lastIndex]; if (splitPartition != -1) { // keep version of sourceBundle //根据上面旧的Bundle范围划分来分裂出多个新的bundle NamespaceBundles splitNsBundles = new NamespaceBundles(nsname, this, sourceBundle.getLocalPolicies(), partitions); List\u0026lt;NamespaceBundle\u0026gt; splitBundles = splitNsBundles.getBundles().subList(splitPartition, (splitPartition + numBundles)); return new ImmutablePair\u0026lt;\u0026gt;(splitNsBundles, splitBundles); } return null; }); } 到这里基本就结束，这条链路主要是Broker将原先的哈希环中的某一个范围拆分成多个范围的逻辑，这里保留几个问题给读者思考\nBundle分裂后是否会涉及到数据的迁移？ Bundle分裂算法有四种，区别是什么？ 三、参考文献 官方文档 ","date":"2024-04-16T10:34:57+08:00","image":"https://sherlock-lin.github.io/p/%E4%B8%BB%E5%8A%A8%E8%A7%A6%E5%8F%91bundle%E5%88%86%E8%A3%82%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20240416181912380_hu8808141309202124509.png","permalink":"https://sherlock-lin.github.io/p/%E4%B8%BB%E5%8A%A8%E8%A7%A6%E5%8F%91bundle%E5%88%86%E8%A3%82%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","title":"主动触发Bundle分裂服务端流程源码解析"},{"content":"引言 承接 手写分布式存储系统v0.2版本 ，今天开始新的迭代开发。主要实现 服务发现 功能\n什么是服务发现 由于咱们的服务是分布式的，那从服务管理的角度来看肯定是要有一个机制来知道具体都有哪些实例可以提供服务。举个例子就是，张三家里在全国各地有不少火锅加盟店，那张三肯定要有一个方式知道这些火锅店加盟店的情况。例如上海又新开了一家加盟店，那么这家加盟店肯定要先通过某种方式联系张三，这样张三才能将配方以及食材供应给这家新的加盟店等等。\n疑问\n为什么不能通过域名映射的方式来做映射，客户端通过域名调用服务就好了为啥要专门做服务发现\n答：域名映射是对外提供服务时使用的，而我们的系统还有很多场景要做内部的服务管理，例如某个节点故障了，为了服务能够继续保证高可用，咱们的分布式存储系统就要将这个节点上所管理的数据分给其余的节点进行管理等，这个时候系统内部就需要明确知道各个分布式节点的信息。\n服务发现设计 目前服务发现设计主要有以下几种\n配置化：将所有节点的信息写在服务配置里，像ES等 使用能保证一致性的外部服务：如kafka、bookkeeper等，外部服务有zookeeper、etcd、consul等 主从架构里，所有从节点启动时自动向主服务注册自己的节点信息：如hdfs、yarn等 为了方便扩展，同时咱们的存储服务能够设计成无主架构，因此采用第二种采用外部服务zookeeper来进行实现。实现的大致流程如下图\n所有节点实例在启动时，都去zookeeper上创建属于自己的目录，在节点下线时就将自己对应的目录进行删除。这样只需要监听“服务发现目录”就能知道是否有节点上下线。同时为了避免服务故障时没能正确删除自己的目录，因此咱们采用zookeeper临时目录的功能，例如节点1启动并在zookeeper创建对应临时目录后，会每隔一小段时间向zookeeper发送请求也就是心跳，证明自己的服务还正常；如果zookeeper在等待一段时间后，没收到某个节点的心跳，就会默认这个服务已经挂了并将其对应的临时目录进行删除。\n代码实现 由于把全部代码贴上来不太现实且不易于阅读，就将开发时测试样例贴上来供大家伙参考\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 package com.sherlock; import org.apache.zookeeper.*; import org.apache.zookeeper.data.ACL; import org.apache.zookeeper.data.Stat; import java.io.File; import java.util.List; import java.util.concurrent.CountDownLatch; /** * author: shalock.lin * date: 2024/2/4 * describe: */ public class BaseZookeeper implements Watcher { private static ZooKeeper zookeeper; public static void main(String[] args) throws Exception { BaseZookeeper baseZookeeper = new BaseZookeeper(); baseZookeeper.connectZookeeper(\u0026#34;127.0.0.1:2181\u0026#34;); List\u0026lt;String\u0026gt; children = baseZookeeper.getChildren(\u0026#34;/\u0026#34;); System.out.println(children); AsyncCallback.StringCallback scb = new AsyncCallback.StringCallback() { @Override public void processResult(int rc, String path, Object ctx, String name) { System.out.println(rc); } }; asyncCreateFullPathOptimistic(zookeeper, \u0026#34;/distributed-storage-system/available/shalocklindeMacBook-Pro.local\u0026#34;, \u0026#34;testData\u0026#34;.getBytes() ,ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT,scb, null); Thread.sleep(5000); List\u0026lt;String\u0026gt; afterChildren = baseZookeeper.getChildren(\u0026#34;/\u0026#34;); System.out.println(afterChildren); } /** * 超时时间 */ private static final int SESSION_TIME_OUT = 2000; private CountDownLatch countDownLatch = new CountDownLatch(1); @Override public void process(WatchedEvent event) { if (event.getState() == Event.KeeperState.SyncConnected) { System.out.println(\u0026#34;Watch received event\u0026#34;); countDownLatch.countDown(); } } /**连接zookeeper * @param host * @throws Exception */ public void connectZookeeper(String host) throws Exception{ zookeeper = new ZooKeeper(host, SESSION_TIME_OUT, this); countDownLatch.await(); System.out.println(\u0026#34;zookeeper connection success\u0026#34;); } /** * 获取路径下所有子节点 * @param path * @return * @throws KeeperException * @throws InterruptedException */ public List\u0026lt;String\u0026gt; getChildren(String path) throws KeeperException, InterruptedException{ List\u0026lt;String\u0026gt; children = zookeeper.getChildren(path, false); return children; } /** * 获取节点上面的数据 * @param path 路径 * @return * @throws KeeperException * @throws InterruptedException */ public String getData(String path) throws KeeperException, InterruptedException{ byte[] data = zookeeper.getData(path, false, null); if (data == null) { return \u0026#34;\u0026#34;; } return new String(data); } /** * 设置节点信息 * @param path 路径 * @param data 数据 * @return * @throws KeeperException * @throws InterruptedException */ public Stat setData(String path, String data) throws KeeperException, InterruptedException{ Stat stat = zookeeper.setData(path, data.getBytes(), -1); return stat; } /** * 删除节点 * @param path * @throws InterruptedException * @throws KeeperException */ public void deleteNode(String path) throws InterruptedException, KeeperException{ zookeeper.delete(path, -1); } /** * 获取某个路径下孩子的数量 * @param path * @return * @throws KeeperException * @throws InterruptedException */ public Integer getChildrenNum(String path) throws KeeperException, InterruptedException{ int childenNum = zookeeper.getChildren(path, false).size(); return childenNum; } /** * 关闭连接 * @throws InterruptedException */ public void closeConnection() throws InterruptedException{ if (zookeeper != null) { zookeeper.close(); } } public static void asyncCreateFullPathOptimistic( final ZooKeeper zk, final String originalPath, final byte[] data, final List\u0026lt;ACL\u0026gt; acl, final CreateMode createMode, final AsyncCallback.StringCallback callback, final Object ctx) { zk.create(originalPath, data, acl, createMode, new AsyncCallback.StringCallback() { @Override public void processResult(int rc, String path, Object ctx, String name) { if (rc != KeeperException.Code.NONODE.intValue()) { callback.processResult(rc, path, ctx, name); return; } // Since I got a nonode, it means that my parents don\u0026#39;t exist // create mode is persistent since ephemeral nodes can\u0026#39;t be // parents String parent = new File(originalPath).getParent().replace(\u0026#34;\\\\\u0026#34;, \u0026#34;/\u0026#34;); asyncCreateFullPathOptimistic(zk, parent, new byte[0], acl, CreateMode.PERSISTENT, new StringCallback() { @Override public void processResult(int rc, String path, Object ctx, String name) { if (rc == KeeperException.Code.OK.intValue() || rc == KeeperException.Code.NODEEXISTS.intValue()) { // succeeded in creating the parent, now // create the original path asyncCreateFullPathOptimistic(zk, originalPath, data, acl, createMode, callback, ctx); } else { callback.processResult(rc, path, ctx, name); } } }, ctx); } }, ctx); } } 功能演示 整个功能验证逻辑如下\n服务启动前观测zookeeper对应目录下不存在数据\n启动服务，从控制台能看到服务正常启动\n再观测zookeeper对应目录下注册了服务的主机名\n通过打印输出，能看到存在该目录下的服务信息(当前存的是测试样例数据)\n停止服务，并持续观测一段时间，可以看到目录已被zookeeper删除\n总结 终于开发一点跟“分布式”相关的内容了，在使用zookeeper时踩了一点坑， 启动服务时报下述异常org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for，通过调试发现zookeeper服务端返回的信息非常有限无法得出有用的信息。结果网上的答案，排除了是防火墙、超时配置等问题后，最终发现是自己在调用zookeeper创建路径是直接传了完整的路径也就是多级目录 /distributed-storage-system/available/shalocklindeMacBook-Pro.local导致的报错，原因是zookeeper不支持递归创建多级目录，只能参考bookkeeper开发工具类从代码层面递归去zookeeper创建路径。惭愧的是，已经接触zookeeper多年，并且也翻过它的代码，却连这个基本的点都不知晓。因此进一步验证上一篇的想法，就是很多东西真的要自己去实现一遍，否则只沉浸理论容易陷入一种“什么都懂”、“什么都是理所当然”的幻觉并自我感觉良好，但这很有可能会令我们的技术止步不前\n","date":"2024-04-07T20:51:00+08:00","image":"https://sherlock-lin.github.io/p/%E6%89%8B%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9Fv0.3%E7%89%88%E6%9C%AC/image-20240923205148052_hu7109961498001971171.png","permalink":"https://sherlock-lin.github.io/p/%E6%89%8B%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9Fv0.3%E7%89%88%E6%9C%AC/","title":"手写分布式存储系统v0.3版本"},{"content":"引言 上回说到 手写分布式存储系统v0.1版本 ，已经实现了通过监听TCP端口并将数据写到本地磁盘的功能，今天咱们就继续往上面添砖加瓦\nv0.2版本大致做以下功能\n实现滚动写文件\n代码优化\n滚动写文件实现 由于咱们写文件是用的mmap进行文件写入，而mmap自身原因最多只能映射到不大于2G的文件。因此在一个磁盘文件写满后，咱们需要滚动写到一个新的文件中，基本上所有分布式存储系统都是这么实现的，如kakfa、pulsar、rocketmq等等。那咱们也自己尝试实现下，大致逻辑如下\n这个过程中有几个点需要考虑\n如何判断文件写满了 滚动前后文件名的变化规则 第一点可以考虑在内存中维护一个整型记录当前文件的大小，否则每次写数据时判断是否写满都要去查下linux会影响性能\n第二点文件名变化规则的设计方式有较多中，例如每次写新的文件名都用最新的等。参考几个系统的实现后决定采用写指定名字的文件例如 “file”，当这个文件写满1个G时，将“file”改名为“file”加当前时间如“file-20240202”，然后再新建一个名为“file”的文件进行写入。这样就能保证“file”这个文件永远都是当前正在写入的文件，核心代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 private boolean rollingFile() throws IOException { preFilepath = fileName+\u0026#34;-\u0026#34;+LocalDateTime.now().toString().replace(\u0026#34;:\u0026#34;,\u0026#34;-\u0026#34;).substring(0,19); File preFile = new File(preFilepath); boolean preFileExists = preFile.exists(); if (!preFileExists) { this.fileChannel.force(false); boolean rename = file.renameTo(preFile); if (rename) { this.fileChannel = new RandomAccessFile(new File(fileName), \u0026#34;rw\u0026#34;) .getChannel(); this.mappedByteBuffer = this.fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, fileSize); WROTE_POSITION_UPDATER.set(this, 0); return true; } else { LOG.error(\u0026#34;TieredIndexFile#rollingFile: rename current file failed\u0026#34;); return false; } } return false; } 代码优化 由于v0.1版本中实现的比较莽，因此现在需要进行一个简单的重构。重构后大致逻辑可以参考下面这张不规范的UML图，首先是抽象出一个LifecycleComponent接口，由于除了网络、持久化服务之外，未来咱们可能还会有其他的服务例如监控、插件服务等等，因此咱们需要对这些服务做一层统一的抽象，所有这些服务都要提供服务启动和服务停止的接口，这样设计之后再服务启动/停止时只需要对LifecycleComponent集合列表进行统一的启动/停止操作即可，代码维护起来也很舒服。\n网络方面是通过NetServiceImpl方法初始化并启动Netty引导类ServerBootstrap，ServerBootstrap启动后会监听Linux机器的网络端口，在监听到有请求时会交给ServerHandler 进行处理，在ServerHandler这里可以调用LocalDataStorageImpl方法进行数据持久化，LocalDataStorageImpl是数据持久化的统一入口，咱们针对mmap写入方式抽象并实现了DefaultMappedFile，提供了真正的mmap写磁盘操作。基本大致逻辑就是如此，尽量不做过度的设计，好的系统是演变过来的，等未来发展到一定阶段后再根据情形进行分析优化\n功能演示 开发完后，咱们就可以开始进行演示了，启动服务后当在控制台看到以下信息就知道服务已经正常启动，此时就可以发数据给服务端了 通过指令能看到已经在目录下创建好对应的文件，由于是通过mmap方式写的数据，因此虽然咱们还没写数据到文件内，但是可以看到文件大小已经是100Byte了，这也是mmap的特点 通过以下指令往8888端口发送数据 1 (echo \u0026#39;are you ok?\u0026#39;; sleep 2) | telnet 127.0.0.1 8888 通过控制台能够看到数据有写到磁盘，并且内存中维护的文件里存放数据的大小也在增加 重复多次第4步，可以看到日志显示已到达文件大小触发文件滚动动作 再看看linux文件系统可以看到，已经创建对应的文件 testWrite-2024-02-02T19-35-20 打印一下可以清晰的看到咱们刚刚请求的内容都被正确的持久化到磁盘中了 总结 上面基本上就是 v0.2 版本的内容了，不难但是你会发现使用一个分布式存储系统、看它的源码的体验，跟你自己实现一遍是完全不同的，一个现成的组件就像是一架飞机，你看得到它的机翼、发动机等等，你知道它是这样设计的；但，它为什么是这样设计的呢？那样不可以吗，这类问题恐怕会想的比较少或者虽然想了一下但是转头就忘了。但是当你自己设计去实现的过程中，你会遇到种种问题需要你去反复思考以及做取舍等等，这些都是你真正意义上成长的过程，甚至有时还会顿悟为什么那个东西人家要这样设计，这些都是无比令人振奋的事情，这不就是生命的意义吗\n","date":"2024-04-07T20:49:15+08:00","image":"https://sherlock-lin.github.io/p/%E6%89%8B%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9Fv0.2%E7%89%88%E6%9C%AC/image-20240202190044471-6871646_hu533876039371260404.png","permalink":"https://sherlock-lin.github.io/p/%E6%89%8B%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9Fv0.2%E7%89%88%E6%9C%AC/","title":"手写分布式存储系统v0.2版本"},{"content":"引言 这是手写分布式存储系统v0.1版本，只有一个目标就是支持通过tcp接收数据并落地到磁盘文件(单机模式)，那接下来就开始吧\n设计 实现一个系统，设计是最过瘾的过程没有之一，类似你搭积木前在脑海设计构建一副大致的“雏形”，只有有了这个东西之后才能够指导最终实现的方向以及确保不会偏离的太差。这里我对v0.1的预期是如下的，只要客户端能够通过tcp将数据请求到Linux机器的端口，咱们的v0.1版本就能够监听到并且将数据落地到磁盘，只需要实现这个功能就可以了。\n代码实现 这个功能中会跟网络和写磁盘打交道，那直接用Netty现成的包就好了，至于写磁盘的话用JDK原生自带的就够了。大致抽象出两个对应的接口以及实现，如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 public interface NetService { void start(); void stop(); } public class NetServiceImpl implements NetService{ private static final Logger LOG = LoggerFactory.getLogger(NetServiceImpl.class); private EventLoopGroup bossGroup = null; private EventLoopGroup workerGroup = null; public void start() { //bossGroup就是parentGroup，是负责处理TCP/IP连接的 EventLoopGroup bossGroup = new NioEventLoopGroup(1); //workerGroup就是childGroup,是负责处理Channel(通道) EventLoopGroup workerGroup = new NioEventLoopGroup(30); try { ServerBootstrap bootstrap = new ServerBootstrap() .group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) //初始化服务端可连接队列,指定了队列的大小128 .option(ChannelOption.SO_BACKLOG, 128) //通过NoDelay禁用Nagle,使消息立即发出去，不用等待到一定的数据量才发出去 .option(ChannelOption.TCP_NODELAY, true) //保持长连接 .childOption(ChannelOption.SO_KEEPALIVE, true) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ServerInitializer()); ChannelFuture future = bootstrap.bind(8888).sync(); future.channel().closeFuture().sync(); } catch (Exception e){ }finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public void stop() { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } 再写下数据存储相关的接口和类如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public interface DataStorage\u0026lt;T\u0026gt; { void save(T t) throws Exception; } public class LocalDataStorageImpl implements DataStorage\u0026lt;String\u0026gt;{ private static MappedByteBuffer mappedByteBuffer; private static Integer _1Gb = 1024*1024*1024; private static Integer _1MB = 1024*1024; public LocalDataStorageImpl() { try { FileChannel fileChannel = new RandomAccessFile(\u0026#34;./testWrite\u0026#34;, \u0026#34;rw\u0026#34;).getChannel(); mappedByteBuffer = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, _1MB); } catch (Exception e) { e.printStackTrace(); } } @Override public void save(String data) throws Exception{ System.out.println(\u0026#34;start writeDataToFile data is :\u0026#34;+data); mappedByteBuffer.put(data.getBytes()); System.out.println(\u0026#34;writeDataToFile end!\u0026#34;); } } 再实现Netty相关的逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 @ChannelHandler.Sharable public class ServerHandler extends SimpleChannelInboundHandler\u0026lt;String\u0026gt; { private static final Logger LOG = LoggerFactory.getLogger(ServerHandler.class); private DataStorage dataStorage = new LocalDataStorageImpl(); @Override public void channelActive(ChannelHandlerContext channelHandlerContext) throws Exception { channelHandlerContext.write(\u0026#34;Welcome to sherlock home!\u0026#34;); channelHandlerContext.write(\u0026#34;It is \u0026#34;+ new Date()+\u0026#34;\\n\u0026#34;); channelHandlerContext.flush(); } @Override public void channelRead0(ChannelHandlerContext ctx, String request) throws Exception { LOG.info(\u0026#34;========readdata, request is {}=========\u0026#34;, request); //异步通过专门的EventLoop线程池进行处理 dataStorage.save(request); String response; boolean close = false; if (request.isEmpty()) { response = \u0026#34;Please type something.\\r\\n\u0026#34;; } else if (\u0026#34;bye\u0026#34;.equals(request.toLowerCase())) { response = \u0026#34;Have a good day!\\r\\n\u0026#34;; close = true; } else { response = \u0026#34;Did you say \u0026#39;\u0026#34; + request + \u0026#34;\u0026#39;?\\r\\n\u0026#34;; } ChannelFuture future = ctx.write(response); if (close) { future.addListener(ChannelFutureListener.CLOSE); } } @Override public void channelReadComplete(ChannelHandlerContext ctx) { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close(); } } public class ServerInitializer extends ChannelInitializer\u0026lt;SocketChannel\u0026gt; { private static final Logger LOG = LoggerFactory.getLogger(ServerInitializer.class); private static final StringDecoder DECODER = new StringDecoder(); private static final StringEncoder ENCODER = new StringEncoder(); private static final ServerHandler SERVER_HANDLER = new ServerHandler(); @Override public void initChannel(SocketChannel socketChannel) throws Exception { ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new DelimiterBasedFrameDecoder(8192, Delimiters.lineDelimiter())); pipeline.addLast(DECODER); pipeline.addLast(ENCODER); pipeline.addLast(SERVER_HANDLER); } } 最后，咱们再来实现主函数逻辑\n1 2 3 4 5 6 public class Main { public static void main(String[] args) { NetService netService = new NetServiceImpl(); netService.start(); } } 基本上就差不多了，代码优化往后放放，现在嘛，能跑就行☺️\n运行调试 启动服务后，咱们通过下列指令往接口插入数据\n1 2 3 4 (echo \u0026#39;hello\u0026#39;; sleep 2) | telnet 127.0.0.1 8888 (echo \u0026#39;sherlock\u0026#39;; sleep 2) | telnet 127.0.0.1 8888 (echo \u0026#39;thanks\u0026#39;; sleep 2) | telnet 127.0.0.1 8888 (echo \u0026#39;are you ok?\u0026#39;; sleep 2) | telnet 127.0.0.1 8888 通过下面控制台的信息能够看到接收到完整的数据了，说明v0.1版本通过socket端口读取数据的链路是正常的\n再看看本地磁盘文件，通过打印出来能够看到数据是已经落到磁盘的\n小结 以上就是实现的整个过程，代码不可谓不粗糙，不过咱们讲究的就是一个莽，快速闭环看到效果才是最重要的，至于优化嘛，放到后面的版本慢慢优化~\n","date":"2024-04-07T20:46:11+08:00","image":"https://sherlock-lin.github.io/p/%E6%89%8B%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9Fv0.1%E7%89%88%E6%9C%AC/image-20240131185601251-6698564_hu7506803332195288085.png","permalink":"https://sherlock-lin.github.io/p/%E6%89%8B%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9Fv0.1%E7%89%88%E6%9C%AC/","title":"手写分布式存储系统v0.1版本"},{"content":"引言 一直想写一篇服务化相关的文章，那就别犹豫了现在就开始吧\n正文 作为大数据基础架构工程师，业界也笑称“运维Boy”，日常工作就是在各个机器上部署以及维护服务，例如部署Hadoop、Kafka、Pulsar这些等等，用于给公司业务提供数据导入、存储、分析服务。这些事情在经历了十多年已经演变出以下几个阶段，今天就以唠嗑的形式进行展开说说\n单一指令阶段 这是最原始的阶段，在机器/操作系统上的所有事情都要由大数据SRE通过一条条执行进行操作，举个简单的例子。当公司需要你新搭建数仓时，也就相当于要搭建以下三层\n存储层：搭建Hadoop、Hive、HBase集群等，这是用于将所有公司数据包括用户数据的存储 导入层：搭建FlinkCDC、Flume、Kafka/Pulsar等数据导入服务，这是用于将数据导入到存储层 分析层：搭建Doris、ClickHouse、Presto、SpringBoot等服务，这是用于将存储层的数据按照预期的想法进行计算出最终可直接用于分析的结果，例如庞大的公司昨天赚了多少钱？分别是各个城市赚了多少？相比上个月多了多少等等 换算到真正要做的事情，那大致流程就是，先申请机器(物理机或者云服务)、初始化环境例如搭建SSH等等，然后下载各个组件的安装包上传到对应的机器，针对对应的组件进行配置修改以及各个组件启动的前置动作，最后再根据具体的启动指令来挨个启动机器等等。如果机器只有几台，你不会觉得什么，但是如果有三四十台的时候，你会觉得手软以及抱怨。大致抱怨以下几点\n工作量大：要靠人工登陆每台机器重复执行那么多的步骤 容易出错：这类动作重复多次容易出现人工操作失误导致影响 体验差：这类事情做多了对于SRE来说是煎熬，并不会有太多技术上的成长，最后沦为只会执行这几个指令的“工具人” 脚本化阶段 人类历史发展本质上就是对资源的利用，为了更合理的利用资源因此衍生出了各种革命，例如第一次工业革命通过蒸汽替代人力，第二次工业革命通过各种能源燃料更大幅代替人力，第三次也就是最近几十年的互联网革命，本质上也是省资源避免大量的重复劳动。\n上面这段话想表达的是， 互联网行业可以说90%以上的重复劳动都是没啥意义的，就相当于在一辆豪华的汽车🚗内是有人在里面蹬三轮，这不是很滑稽吗。因此如果你发现自己的工作中还存在大量 单一指令阶段的事情，那么务必要想办法进行脚本化。脚本本质上就是一本操作指南，给“操作系统”看的，举个例子如果你是一个果园园主，你雇了30个人进行水果采摘，你肯定不会去给每一个人讲解如何识别水果、水果具体的采摘的流程是怎么样子的，要用手托住果子在用剪刀轻轻减哪个部位之类的话。因为这样不仅耽误大量你的时间，并且每年水果成熟时你都要重复一遍，因此更高效的方式是花上一天时间写一本“水果采摘指南”，后续的每一个采摘的人直接看下指南即可知道该怎么做，这个指南就是脚本。\n那么工作中也是一样，可以将下载组件包、解压包、更改配置、服务启动/重启等操作直接封装成脚本，然后将可能会变的东西作为参数传进来，这样的话无论是针对多少台机器进行操作，你只需要在这些机器上执行一下脚本即可。在这个基础上还能做二次优化，就是在所有机器配置SSH后，你只需要在执行脚本时传入要做变更机器的标识例如IP，执行的机器就会自动将这些“逻辑”分发到各个机器上进行执行，这样的操作方式是不是更加舒服？或者说这是不是才是一个相对成熟的流程？\n那么此时大家觉得这个流程是否还存在问题？可以思考🤔一会再继续往下看。其实也很简单，就是对开发人员的专业能力是比较高的，换成是上面的例子来解释就是，果园园主不想花时间去学习写“水果采摘指南”，或者说所有果园园主单独写指南从上帝视角看本质上就是资源的浪费，要怎么解决这个问题呢。也不复杂，直接让上帝提供几份“水果采摘指南”，各个果园园主只需要选择适合自己的直接用岂不美哉？那么就引出了用户界面操作阶段。\n用户界面操作阶段 在读这篇文章的你相信对网站操作也不陌生了，例如咱们不需要知道网络底层是怎么操作，代码是怎么编写的，就能完成多人跨网络、跨时空的沟通，这些本质上要归功于用户界面操作阶段, 因为这些东西已经包装成了几个按钮。大数据SRE的工作内容其实也是可以作成几个按钮来大幅提升效率的，例如要在某些服务上搭建数仓，那么只需要在Web页面上勾选要部署服务的机器标识例如IP，然后选择想要安装的服务，然后点击确定即可完成安装，然后安装完后在Web页面就有这个服务的专门管理页面，例如服务启动、配置更改、使用情况监控等等，是不是一下子觉得高级了起来？更重要的是，你发现甚至你都不用掌握过多的SRE的知识也能完成这份工作？并且即便后续在更大的场景例如要在几百台、几千台机器进行部署维护你也不怕了？这就是互联网的魅力，所以说互联网革命也是人类历史上对资源利用的一大进步，如果咱们深处互联网时代，甚至从事互联网工作，而不具备互联网思维，那岂不是一种倒退吗或者形象点就是一个远古人生活在21世纪还在钻木取火，这就挺奇怪的。\n在这个阶段是否还有能改进的地方，接下来是我的设想或者是YY时间也就是 大模型+AIOPS阶段\n大模型+AIOPS阶段 最近几年随着大模型的爆发，有不少企业以及个人已经用它来提升和改进自己的工作效率。那么以后是否还有这样的一种模式，就是我们只要跟机器人，或者说是一位“虚拟同事”发送 给我搭建一套数仓指令是否就可以了？它会自动接续这条自然语言的语意，咱们进行各个流程的操作，在一些关键流程我们人类只需要进行审批确认没问题即可，剩下的事情交给机器去做就够了。\n在这个基础上，运维人员也不用天天盯着监控告警了，我们可以将历史发生过的事故数据以及专业知识喂人工智能，并训练它针对具体事情该做出怎样的决策，举个简单的例子比如某台机器的CPU过高，那么自动排查问题并进行修复，最后再将排查的结果以及修复的流程发给人类即可，这岂不美哉？而人类过多的做这些事情本质上还是一种资源的浪费，因为存在过多过多重复劳动、过多没有太多价值的事情，如果一个人的一辈子都在做这种事情，那本质上我们还是几万年前那个吭哧吭哧钻木头🪵的原始人，一切的一切都从来没有变过。\n总结 以上是我对大数据服务化粗糙的认知，输出出来是希望能引发一些思考🤔，当然写的过程中也引发了我自己的不少思考。这个过程中虽然存在一点批判，但绝不是针对具体的个人，而是针对目前常见的一些流程设计，单纯觉得有些设计可以变得更“美”一些。如果对服务化感兴趣的伙伴可以去针对性的学习专业的知识来改善工作内容，本篇文章仅仅是唠嗑，存在很多瑕疵，但我始终相信，多人沟通讨论可以构建设计一个更加完美的设计，因此如果能引发其他人的共鸣或者不同想法💡其实都是好事。\n","date":"2024-04-04T20:41:34+08:00","image":"https://sherlock-lin.github.io/p/%E8%AE%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E5%8C%96%E5%8F%91%E5%B1%95%E5%8F%B2/image-20240404185440981_hu17668148412322371707.png","permalink":"https://sherlock-lin.github.io/p/%E8%AE%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E5%8C%96%E5%8F%91%E5%B1%95%E5%8F%B2/","title":"论大数据服务化发展史"},{"content":"引言 距离 莽，就完事啦！已经过去了两个月，这两个月也交出了自己的答卷，这个过程中也有些自己的心得体会，这篇就作为call back吧\n高效执行力 这两个月累计输出22篇文章，算下来差不多是三天一篇，这在过去是完全不敢想象的，在舍弃“完美”后，很多自己的想法、对技术的见解都可以发出来，虽然也有写得好的，但是也有不少自己觉得不满意的，这在以前我肯定希望能够在未来打造到完美再发出来，但如果真的是那样可能我的产量会严重下滑甚至可能会停止输出博客，并且如果不发出来我自己的一些问题也无法暴露出来并无法进行改进。因此请读者带着包容的心态来进行阅读，同时我也相信搜索引擎会自动过滤掉我的那些写得糟糕的文章，同时会将我写的还行的文章送到您的面前，如果能恰好帮助您解决某些问题或者解开某个疑惑，那是我的荣幸。\n从我这两个月的输出也能从某种程度说明完美和执行力是互斥的，或者说有时候不要想着一步到位，而是想做出来，然后再不断进行完善。就像Pulsar系列的文章，有些写得比较草率，但是即便如此在输出到现如今我对Pulsar的整体流程有个更加深入的理解，在脑海里逐渐有了一个“智慧模型”，这是非常重要的，在有个这个模型或者说整体框架后，我再去针对某个点进行啃透就相对轻松很多，并且也有的放矢，自己自己当前的进度在那里\n质量 如何将事情做得又快又好应该是大部分人都在思考的问题，如今的我觉得两者就像是道家的阴阳鱼此消彼长，我们要尽量做好平衡，有时候要侧重于执行，但是当发现质量下滑得厉害时，我们又要适当放慢速度来提升质量。这会是一个不断持续的过程，而这个过程磨练的也是个人的心智或者能力。除此之外，在不断执行的过程中，也要不断进行提炼，例如一篇好的文章框架应该是如何的，提炼出一套通用的框架后就按照这套框架进行文章输出，并且在输出的过程中继续完善框架，比如很经典的5W2H模型，这个东西是什么？为什么会需要这个东西？这个东西怎么用？怎么实现？等等。基本把这些问题回答了，那么你要讲的东西也讲清楚了\n待完善 在不断输出技术的过程中，也发现自己目前还存在的一些问题，在此一起记录下来方便自我完善也供大家参考\n表达也是有框架的，我在讲解某些东西的时候逻辑不够清晰，反复讲来讲去其实就是想表达一个意思，但是由于没有很好的提炼导致有点嘴碎的感觉 绘图能力待提升，应该看更多优秀的作品，同时将某些技术的关键点通过图给关联起来，并且目前绘制的图挺不规范，例如类和功能混合在一起等等，这些都待完善 表达应该也要有层次感，就像金字塔一样，下一层的知识是为了更好的支撑上一层，彼此是有联系并且层层递进的，而目前这块做得不够好，更像是顺着某条路一条路走完但是读者会很懵 总结 这是我最近两个月关于“莽”比较大的感悟，虽然文章质量有下滑，但我觉得有时候该抓一放一，对于此时的我来说坚持输出远胜于用很多时间打磨一两片文章。因此我会在“莽”的过程中尽量提升质量，读者如果有其他的建议也希望在评论中一起进行讨论\n","date":"2024-04-04T15:09:14+08:00","image":"https://sherlock-lin.github.io/p/%E8%8E%BD%E5%B0%B1%E5%AE%8C%E4%BA%8B%E4%BA%86%E7%AC%AC%E4%BA%8C%E5%BC%B9/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu6307248181568134095.jpg","permalink":"https://sherlock-lin.github.io/p/%E8%8E%BD%E5%B0%B1%E5%AE%8C%E4%BA%8B%E4%BA%86%E7%AC%AC%E4%BA%8C%E5%BC%B9/","title":"莽就完事了第二弹"},{"content":"引言 《认知觉醒》这本书太经典了，反复读了多次还是爱不释手，因此决定针对它写写读书笔记。今天主要针对这本书的三重大脑理论进行讲解\n三重大脑 作者认为人类的大脑分为三重分别是本能脑、情绪脑以及理智脑，三者的区别如下图(从书中拷贝的，侵权请联系删除)\n很多相关书籍都会将大脑分为这三种，但本人觉得对于读者来说其实可以简化，将情绪脑和本能脑进行合并简称“非理智脑”。理智脑和非理智脑各有优缺点，理智脑相比之下更加高级，但是弱小，而非理智脑虽然低级但是非常非常强大。因此从人类远古时期到如今已跨入互联网第三次工业革命中，大部分人的决策还是通过非理智脑。这里分别例举两者的特点做下比较\n理智脑特点\n富有远见、善于权衡 能立足未来延迟满足 对大脑控制力弱 非理智脑优点\n执行力强 避难趋易和急于求成 对大脑控制力强 通过这个比较相信大家能够明显的感觉到两者的差异，这里比较两者并不是想说理智脑更好，而是希望我们更加了解自己大脑这个“工具”。大脑是我们日常生活中最常用的“工具”，在我们的灵魂向大脑发送指令时，大脑会进行思考并做出对应决策，最终将决策的结果发送到身体的各个部位进行最终的“执行动作”。打个比方，如果每个人都是一个王国，那么灵魂就是国王，而理智脑是军师，非理智脑是将军，身体的各个部位分别是这个王国的子民。因此国王要做的是将国家发展战略相关的事情交给军师，将这个战略所依赖的各个事情交给将军，让将军带领部队、子民们去攻城拔寨从而壮大这个王国。\n通过上面这个例子大家应该就清楚，理智脑和非理智脑从来不是对立的，而是协作，如何协调好两者是我们每个人需要做好的事情。用书中的原话来说就是 理智脑不是直接干活的，干活是本能脑和情绪脑的事情，因为它们的“力气”大；上天赋予理智脑智慧，是让它驱动本能和情绪，而不是直接取代它们。\n生活例子 接下来结合以下几个例子来讲讲\n营销手法\n现如今很多营销手法本质上就是攻击每个人的“非理智脑”，例如不少主播带货，通过不停的喊倒计时来制造稀缺以及紧张的氛围，此时“非理智脑”就会本能的紧张以及在损失厌恶的心理下，“非理智脑”会以压倒性的形式远远战胜“理智脑”，即便“理智脑”能察觉到买这玩意可能没啥作用，但是没办法它对大脑的控制远远不如“理智脑”。这是聪明的商家屡试不爽的招数，除此之外的场景还有很多很多，例如当房价不停的疯狂上涨时，大部分人也会丧失理智跟风上车；当股价飕飕上涨时，也同样如此，这些趋利避害以及急于求成都是“非理智脑”的缺点，至少应该意识到这一点以及尽量避免因此遭到损失。\n学习技能\n在学习新技术/技能时，我们往往坚持不了太久，这是因为从学习曲线来说大部分前期都是比较容易，但是一旦过了前期之后，再进行努力都很难看到成效，此时很多人都会建议一定要自律之类的话，但是盲目的自律其实就是在让弱小的“理智脑”去对抗强大的“非理智脑”，结果失败都是非常正常的事。因此应该用“理智脑”去引导非理智脑，就拿学小提琴为例子，我们要做的不是强迫自己每天拉几个小时的小提琴，这只会变得痛苦以及更早的放弃。“理智脑”要做的应该是，要求自己去听几场音乐会，看小提琴家们在舞台上拉出悠扬的声音，这个画面会在未来的很长时间引导着“非理智脑”去充满热情练琴，其次就是选一些自己喜欢并且容易入门的曲子，在每天练完基本功后“奖励”自己拉一会自己的曲子，在曲子拉熟练后可以适当的在朋友们面前进行表演等。这只是以小提琴为例子，其他技能都是想通的，因此应该合理的应用好我们的“非理智脑”\n总结 这类文章可能读起来会有点觉得像是傲慢的说教之类的，如果有类似的感觉我感到很抱歉，这并不是我的本意，我从过去到现在即使是将来在这方面都有要不断完善的地方，写出来一方面是给大家分享我的见解，另一方面自己也会时常回头看看、反思这块相关的内容并指导我自己更好的前行。最后跟大家分享文章中我很喜欢的一句话 习惯之所以难以改变，就是因为它是自我巩固的——越用越强，越强越用。要想从既有的习惯中跳出来，最好的方法不是依靠自制力，而是依靠知识。\n","date":"2024-04-02T15:09:59+08:00","image":"https://sherlock-lin.github.io/p/%E8%AE%A4%E7%9F%A5%E8%A7%89%E9%86%92%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%A4%A7%E8%84%91%E4%B9%8B%E4%B8%80%E5%88%87%E9%97%AE%E9%A2%98%E7%9A%84%E8%B5%B7%E6%BA%90/image-20240401215532850_hu17024335535230597268.png","permalink":"https://sherlock-lin.github.io/p/%E8%AE%A4%E7%9F%A5%E8%A7%89%E9%86%92%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%A4%A7%E8%84%91%E4%B9%8B%E4%B8%80%E5%88%87%E9%97%AE%E9%A2%98%E7%9A%84%E8%B5%B7%E6%BA%90/","title":"认知觉醒读书笔记之大脑之一切问题的起源"},{"content":"引言 在看了 你真的了解Pulsar的消息保留、积压、TTL策略吗 后，相信有不少对技术充满热情的小伙伴会疑惑，Pulsar的TTL又是怎么去失信的呢？今天就让我们一起来看看吧\n在看下面的文章时我们要带着以下几个问题\nTTL是什么时候触发的 TTL机制被触发后会发生什么 过期的消息会立马被删除吗 整体流程 在跟踪源码前先看看这张图，每个Broker内部都会有一个周期定时线程任务，每隔一段时间都会触发TTL任务。TTL任务会轮询当前Broker所管理的所有Topic中的所有订阅者，因为每个订阅者都会在Broker维护一个消费游标，因此Broker会根据用户配置的过期时间到轮询检查游标，看看有哪些消息是没被消费但是已经过了TTL的并会将游标移动到其的左侧(从实现的层面相当于表示它已经被消费了)，从而达到这些过了TTL的消息允许被删除的效果，最终再将游标的信息持久化到Bookkeeper中进行保存。\n触发TTL流程 那么直接来跟踪下触发TTL的流程吧，先从Broker的启动方法start开始看。可以看到启动的时候还会开启一系列定时任务，这里只看TTL相关的，跟踪进去startMessageExpiryMonitor方法可以看到messageExpiryMonitor其实是JDK提供的线程池ScheduledExecutorService类，在这里通过scheduleAtFixedRate方法周期性的执行过期任务检测，间隔从Broker配置中进行读取的，默认是每隔5分钟一次\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public void start() throws Exception { .... this.startInactivityMonitor(); //启动定时消息过期检测任务(TTL) this.startMessageExpiryMonitor(); this.startCompactionMonitor(); this.startConsumedLedgersMonitor(); this.startBacklogQuotaChecker(); this.updateBrokerPublisherThrottlingMaxRate(); this.updateBrokerDispatchThrottlingMaxRate(); this.startCheckReplicationPolicies(); this.startDeduplicationSnapshotMonitor(); } protected void startMessageExpiryMonitor() { int interval = pulsar().getConfiguration().getMessageExpiryCheckIntervalInMinutes(); messageExpiryMonitor.scheduleAtFixedRate(this::checkMessageExpiry, interval, interval, TimeUnit.MINUTES); } TTL启动流程 通过上一节可以看到Pulsar的TTL触发就是通过JDK的定时线程池来实现的，Broker会周期性的调用checkMessageExpiry方法进行处理，因此现在就从这个方法进行跟踪，可以看到最终会调用到Topic的checkMessageExpiry方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 public void checkMessageExpiry() { //进去看看forEachTopic的实现 forEachTopic(Topic::checkMessageExpiry); } public void forEachTopic(Consumer\u0026lt;Topic\u0026gt; consumer) { //topics是Broker维护的一个Map结构，用于记录当前Broker所维护的Topic信息 //这里使用了Java8的Consumer，相当于闭包的设计，让内部的所有Topic都执行checkMessageExpiry方法 topics.forEach((n, t) -\u0026gt; { Optional\u0026lt;Topic\u0026gt; topic = extractTopic(t); topic.ifPresent(consumer::accept); }); } 由于Topic只是接口，因此我们看它最常用的实现类也就是我们熟悉的PersistentTopic类的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 public void checkMessageExpiry() { //从topic配置中获取消息的TTL配置，这个跟上面的配置是有区别的，这里代表的是消息的有效期 int messageTtlInSeconds = topicPolicies.getMessageTTLInSeconds().get(); //通过这里的逻辑可以知道如果配置成0就不会过期 if (messageTtlInSeconds != 0) { //循环调用当前Topic订阅者检测过期 subscriptions.forEach((__, sub) -\u0026gt; { if (!isCompactionSubscription(sub.getName())) { //进行具体的检测动作，从这里继续跟踪 sub.expireMessages(messageTtlInSeconds); } }); } } public boolean expireMessages(int messageTTLInSeconds) { //获取当前积压消息的条数(指的就是未被消费的消息条数) long backlog = getNumberOfEntriesInBacklog(false); //如果没有消息积压就代表所有消息都被成功消费并且游标此时已经处于最左端，因此没必要再做TTL的检测了 if (backlog == 0 || (dispatcher != null \u0026amp;\u0026amp; dispatcher.isConsumerConnected() \u0026amp;\u0026amp; backlog \u0026lt; MINIMUM_BACKLOG_FOR_EXPIRY_CHECK \u0026amp;\u0026amp; !topic.isOldestMessageExpired(cursor, messageTTLInSeconds))) { // don\u0026#39;t do anything for almost caught-up connected subscriptions return false; } this.lastExpireTimestamp = System.currentTimeMillis(); //更新过期消息的下标，从这里继续跟踪 return expiryMonitor.expireMessages(messageTTLInSeconds); } public boolean expireMessages(int messageTTLInSeconds) { .... // 这里进去进行过期检查 checkExpiryByLedgerClosureTime(cursor, messageTTLInSeconds); .... } private void checkExpiryByLedgerClosureTime(ManagedCursor cursor, int messageTTLInSeconds) { //参数校验，可是这里为什么又做了小于0的判断，而外层只判断了等于0，可否用统一的参数校验工具进行校验呢？ if (messageTTLInSeconds \u0026lt;= 0) { return; } if (cursor instanceof ManagedCursorImpl managedCursor) { ManagedLedgerImpl managedLedger = (ManagedLedgerImpl) managedCursor.getManagedLedger(); //获得游标当前标记的可删除位置 Position deletedPosition = managedCursor.getMarkDeletedPosition(); //获取当前未被成功消费的积压日志信息，按Ledger进行排序 SortedMap\u0026lt;Long, MLDataFormats.ManagedLedgerInfo.LedgerInfo\u0026gt; ledgerInfoSortedMap = managedLedger.getLedgersInfo().subMap(deletedPosition.getLedgerId(), true, managedLedger.getLedgersInfo().lastKey(), true); MLDataFormats.ManagedLedgerInfo.LedgerInfo info = null; // 查询最接近现在的第一个未过期Ledger，那么其上一个Ledger一定是过期的并且其之前的都是过期的 for (MLDataFormats.ManagedLedgerInfo.LedgerInfo ledgerInfo : ledgerInfoSortedMap.values()) { if (!ledgerInfo.hasTimestamp() || !MessageImpl.isEntryExpired(messageTTLInSeconds, ledgerInfo.getTimestamp())) { break; } info = ledgerInfo; } //如果info不为空说明一定存在已经处于过期的Ledger也就是过期的消息集合体 if (info != null \u0026amp;\u0026amp; info.getLedgerId() \u0026gt; -1) { //获取具体过期的位置 PositionImpl position = PositionImpl.get(info.getLedgerId(), info.getEntries() - 1); if (((PositionImpl) managedLedger.getLastConfirmedEntry()).compareTo(position) \u0026lt; 0) { findEntryComplete(managedLedger.getLastConfirmedEntry(), null); } else { //这里进去检查过期位置 findEntryComplete(position, null); } } } } 通过上面的代码跟踪可以看到在获取到过期的消息位置后，最终调用了PersistentMessageExpiryMonitor类的findEntryComplete方法，那么咱们接下来跟着进去看看都发生了哪些有意思的事情吧\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 public void findEntryComplete(Position position, Object ctx) { ....\t//通过方法命名可以推测是通过标记游标的删除位置到达到TTL的效果，继续跟踪进去看看 cursor.asyncMarkDelete(position, cursor.getProperties(), markDeleteCallback, cursor.getNumberOfEntriesInBacklog(false)); .... } public void asyncMarkDelete(final Position position, Map\u0026lt;String, Long\u0026gt; properties, final MarkDeleteCallback callback, final Object ctx) { .... //异步标记删除位置 internalAsyncMarkDelete(newPosition, properties, callback, ctx); } protected void internalAsyncMarkDelete(final PositionImpl newPosition, Map\u0026lt;String, Long\u0026gt; properties, final MarkDeleteCallback callback, final Object ctx) { .... synchronized (pendingMarkDeleteOps) { switch (STATE_UPDATER.get(this)) { .... case Open: if (PENDING_READ_OPS_UPDATER.get(this) \u0026gt; 0) { pendingMarkDeleteOps.add(mdEntry); } else { //进行标记删除 internalMarkDelete(mdEntry); } break; .... } } } void internalMarkDelete(final MarkDeleteEntry mdEntry) { .... //持久化游标信息到Bookkeeper persistPositionToLedger(cursorLedger, mdEntry, cb); } void persistPositionToLedger(final LedgerHandle lh, MarkDeleteEntry mdEntry, final VoidCallback callback) { PositionImpl position = mdEntry.newPosition; PositionInfo pi = PositionInfo.newBuilder().setLedgerId(position.getLedgerId()) .setEntryId(position.getEntryId()) .addAllIndividualDeletedMessages(buildIndividualDeletedMessageRanges()) .addAllBatchedEntryDeletionIndexInfo(buildBatchEntryDeletionIndexInfoList()) .addAllProperties(buildPropertiesMap(mdEntry.properties)).build(); .... requireNonNull(lh); byte[] data = pi.toByteArray(); //调用Bookkeeper客户端将游标信息写入 lh.asyncAddEntry(data, (rc, lh1, entryId, ctx) -\u0026gt; { .... }, null); } 通过上面的跟踪可以看得到最终是通过Bookkeeper的客户端对象LedgerHandle的asyncAddEntry方法将游标信息持久化到了Bookkeeper，这里就不继续跟踪下去了，因为已经到了TTL左右范围的尽头了。\n总结 以上就是Pulsar中TTL的实现源码流程，我在这个过程中尽量省略了一些非必要的逻辑，主要是跟踪了主线，像一些地方也是值得跟踪的，感兴趣的伙伴可以自行跟踪。同时在这里我们可以看到，TTL过程只移动了游标位置并不涉及到数据的删除，说明在Pulsar的设计中将两者进行了分离，这是一种很好的职责设计思路，各自负责自己的一那部分。一方面在程序维护时可以避免改动引起一些相关性不那么大的影响，另一方面对于程序执行的整体性能来说也是比较高效的。\n","date":"2024-04-02T10:34:56+08:00","image":"https://sherlock-lin.github.io/p/pulsar%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8Bttl/image-20240331111412370_hu135517140155982200.png","permalink":"https://sherlock-lin.github.io/p/pulsar%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8Bttl/","title":"Pulsar源码解析之TTL"},{"content":"引言 任何东西都有生命周期，就像沙丁鱼罐头🥫也会过期一样，咱们的消息本身也是有生命周期的，因此像Pulsar这样的流平台/消息队列也提供了Retention、Backlog和TTL机制。\n默认清理机制 任何机制的出现都是有背景的，因此我们要先了解这三个机制出现之前的情况，才能分析出它们具体分别解决的事什么问题。首先看下图，生产者往Broker不断往Broker中写入消息，这些消息在Broker中会按照顺序从左到右进行存储的，新写入的消息是不断的在左边进行新增。消费者也是从右往左进行消费的，在Broker中会维持一个游标记录消费的情况，通过此游标Broker才可以对消息进去区分，哪些消息是可清理回收的，哪些消息是目前还不能清理回收的。这个默认清理机制符合我们使用消息队列的一部分业务场景\nRetention机制 在咱们理解了默认清理机制时，我们会有个疑问🤔️，如果消息一被成功消费就被删除，那么如果Broker的下游处理有问题需要从头消费或者从指定的某个位置消费的话，目前的清理机制是完成没办法支持的。而Pulsar设计的目标是一个大一统的流平台/消息队列，肯定是不允许这种情况的出现，因此引入了Retention机制。\n通过下图可以看到消息发布订阅过程，在默认的清理机制中游标右侧的消息是允许被删除的，但是配置Retention的情况则会按照机制进行保存一段时间。而Cursor游标左边的这些消息表示还没被消费者消费，因此即便没有配置 Retention机制这些消息也不会被删除。Retention 支持数据大小维度以及时间维度两种方式进行配置，不过它目前仅支持针对Namespace级别进行生效。\n在设置Retentio机制时可以通过defaultRetentionSizeInMB和defaultRetentionTimeInMinutes同时进行配置，此时会有以下几种情况\n时间维度 文件大小为度 消息保留效果 -1 -1 永久保存 -1 \u0026gt;0 基于数据大小进行保留 \u0026gt;0 -1 基于时间进行保留 0 0 默认配置，当消息被消费后不会被保留 0 \u0026gt;0 无效配置 \u0026gt;0 0 无效配置 \u0026gt;0 \u0026gt;0 当消息已经被消费或者没有消费者订阅时，满足其中一个条件的则不被保留 Backlog 限额机制 Retention机制解决了消息“提前”删除的问题，那么可以高枕无忧了吗？让我们来想想下面这种场景，就是未被成功消费的消息是会一直保留在Pulsar中的，那么如果写入速度一直远大于消费速度，是不是就相当于一个蓄水池入水速度远大于出水速度，最终这个池子会满一样，Pulsar的磁盘也会被打满从而影响服务的稳定性。\nBacklog的原理其实不复杂，相当于在蓄水池中标记一个水位线，当蓄水池的高度到达这条水位线时则触发报警，工作人员根据这个报警来做出相对应的处理。Pulsar其实也是一样，假如我们配置Backlog限额的大小是两条消息的大小，那么如下图，此时如果已经有两条消息未被消费，再有一条新的消息进行尝试写入，就会触发Pulsar的报警策略进行处理。\n积压警报策略有以下三种\nproducer_request_hold：生产者会暂时等待一段时间，并在之后重新进行消息发送 producer_exception：向生产者抛出异常，让生产者进行处理如停止或暂停往Pulsar进行消息的写入 consumer_backlog_eviction：Broker会清理一些积压的数据 Backlog 机制是针对Namespace级别限额，同样是支持通过数据大小以及时间两种维度配置。\nTime to live (TTL) 看起来Retention和Backlog机制已经基本满足我们的使用了，那么为啥还要加一个TTL呢？是社区闲着没事干整那么多东西吗，答案显然不是的。我们再来想想生活中的某些场景，如果在我们的业务场景中消息是有时效性的，例如股票最新的价格，如果这个价格信息是通过Pulsar进行传递的，那么如果这条消息及时没有被消费，在10分钟后它的价值理论上就没有那么高了，因为还会有源源不断的最新价格信息写入Pulsar，而用户更加关心的是最新的价格。因此根据业务场景给消息配置上TTL，可以更有利于Pulsar进行消息的回收以及资源的释放。通过下图我们可以看到，每一条消息都有一个“蜡烛”标记它的生命周期\n当这条消息上面的蜡烛燃尽时，即便这条消息还没有被消费，游标依然会移动到它左边将其标记为允许被删除，因为此时对于业务来说这条消息已经属于没有价值，没有在Pulsar继续保留的必要。可以看到这种方式相比Backlog的方式更加稳妥，因为这不依赖于消费者的消费情况\n综合 对于Pulsar存储而言，Backlog和TTL机制可以防止磁盘被耗尽；而Retention机制会占用磁盘来保留未来可能还会用到的消息。 对于影响范围而言，Retention机制仅针对已经成功消费的消息，Backlog和TTL仅针对未被成功消费的消息。 整体流程就是，在过了Retention配置的时间，已被成功消费的消息就会被删除；如果Pulsar的消息超过了Backlog限额则Pulsar会停止接收来自生产者的消息直到有更多可用的空间，因此针对消息数据配置TTL是可以非常好的保护Backlog限额的。 Pulsar物理存储的大小应该满足Retention和Backlog的总和，在设计集群时应该把消息需要保留多久、允许多少积压等考虑进去。 除此之外Pulsar支持分层存储，会将冷数据迁移到更加廉价的外部系统中存储，此时配置的策略会依然有效，因此应该考虑全面。 以上就是Pulsar Retention、Backlog和TTL机制的核心，可以满足流平台/消息队列的使用场景\n参考资料 官方文档\nUnderstanding Pulsar Message TTL, Backlog, and Retention\nApache Pulsar 之 TTL 与 Retention 策略\n","date":"2024-04-01T10:34:57+08:00","image":"https://sherlock-lin.github.io/p/%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BA%86%E8%A7%A3pulsar%E7%9A%84%E6%B6%88%E6%81%AF%E4%BF%9D%E7%95%99%E7%A7%AF%E5%8E%8Bttl%E7%AD%96%E7%95%A5%E5%90%97/image-20240331085922332_hu13280254660255972346.png","permalink":"https://sherlock-lin.github.io/p/%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BA%86%E8%A7%A3pulsar%E7%9A%84%E6%B6%88%E6%81%AF%E4%BF%9D%E7%95%99%E7%A7%AF%E5%8E%8Bttl%E7%AD%96%E7%95%A5%E5%90%97/","title":"你真的了解Pulsar的消息保留、积压、TTL策略吗"},{"content":"引言 今天一起来看看Pulsar服务端消息相关最重要的一个类PersistentTopic，看看它都负责哪些事情以及是如何设计的\n正文 在Topic被创建时，Pulsar集群中会有一台Broker维护这个Topic，在实现上就是维护一个PersistentTopic对象，这个PersistentTopic对象处理针对该Topic相关的一切操作，具体负责的相关操作如下\n处理订阅以及下线订阅 新增生产者对象以及下线生产者对象 处理消息写入 进行跨集群复制 记录Topic度量状态以及做Topic限流 检查消息的TTL、积压、压缩、配置策略更新 绘成表格的形式如下图\n本篇文章不会深入讲解每一项，主要是大概过下这个类都做了哪些事情以及大致逻辑，因为服务端的代码会经常跟这个类打交道，因此专门弄清楚这个类的相关知识还是很有必要的。接下来就让我们带着以下三个疑问去看下面的内容\nPersistentTopic在什么时候会被创建？都有哪些重要的成员变量？ PersistentTopic的创建流程都会发生什么？ 上面那些相关操作大概是什么实现的？ 一、何时创建 以下列出创建的时机，基本上流程都是发起创建Topic的时候会通过一致性哈希计算出这个Topic所归属的Bundle，然后去zookeeper获取这个Bundle所归属的Broker机器，最后请求这台Broker节点创建对应的PersistentTopic对象\n管理流创建 cli管理命令行 多语言Client Http方式 写入流创建 生产者写入流 消费者写入流 接下来看看这个类的主要成员变量，重要的一些已经加上注释解释了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 public class PersistentTopic extends AbstractTopic implements Topic, AddEntryCallback { // 管理Bookkeeper的Ledger，在做消息读取或者写入时会通过该对象 protected final ManagedLedger ledger; // 存储订阅当前Topic的所有订阅对象，key是订阅名，value是订阅对象 private final ConcurrentOpenHashMap\u0026lt;String, PersistentSubscription\u0026gt; subscriptions; // 管理对端集群，负责做跨集群数据复制 private final ConcurrentOpenHashMap\u0026lt;String/*RemoteCluster*/, Replicator\u0026gt; replicators; //跟replicators类似 private final ConcurrentOpenHashMap\u0026lt;String/*ShadowTopic*/, Replicator\u0026gt; shadowReplicators; @Getter private volatile List\u0026lt;String\u0026gt; shadowTopics; private final TopicName shadowSourceTopic; //调度限流器 private Optional\u0026lt;DispatchRateLimiter\u0026gt; dispatchRateLimiter = Optional.empty(); //调度限流锁 private final Object dispatchRateLimiterLock = new Object(); //订阅限流器 private Optional\u0026lt;SubscribeRateLimiter\u0026gt; subscribeRateLimiter = Optional.empty(); //积压游标阈值条数 private final long backloggedCursorThresholdEntries; public static final int MESSAGE_RATE_BACKOFF_MS = 1000; //处理消息重复情况 protected final MessageDeduplication messageDeduplication; //处理消息压缩服务 private TopicCompactionService topicCompactionService; // 在对外开放压缩策略配置时，根据用户配置创建对应的压缩策略 private static Map\u0026lt;String, TopicCompactionStrategy\u0026gt; strategicCompactionMap = Map.of( ServiceUnitStateChannelImpl.TOPIC, new ServiceUnitStateCompactionStrategy()); //未知 private CompletableFuture\u0026lt;MessageIdImpl\u0026gt; currentOffload = CompletableFuture.completedFuture( (MessageIdImpl) MessageId.earliest); //负责跨集群复制时订阅相关事项 private volatile Optional\u0026lt;ReplicatedSubscriptionsController\u0026gt; replicatedSubscriptionsController = Optional.empty(); //记录Topic度量相关信息，如这个Topic的写入速率、消费速率等 private static final FastThreadLocal\u0026lt;TopicStatsHelper\u0026gt; threadLocalTopicStats = new FastThreadLocal\u0026lt;TopicStatsHelper\u0026gt;() { @Override protected TopicStatsHelper initialValue() { return new TopicStatsHelper(); } }; } 二、创建流程 创建流程主要分为构建和初始化两个阶段，一般是先通过构造函数创建PersistentTopic，创建好后在调用其initialize方法进行初始化\n1. 构造函数 构造函数主要做三件事：1. 更新Broker级别策略 2. 创建发布限流 3. 初始化容器。具体代码实现如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public AbstractTopic(String topic, BrokerService brokerService) { //基本都是赋值操作 this.topic = topic; this.brokerService = brokerService; this.producers = new ConcurrentHashMap\u0026lt;\u0026gt;(); this.isFenced = false; ServiceConfiguration config = brokerService.pulsar().getConfiguration(); this.replicatorPrefix = config.getReplicatorPrefix(); topicPolicies = new HierarchyTopicPolicies(); updateTopicPolicyByBrokerConfig(); this.lastActive = System.nanoTime(); this.preciseTopicPublishRateLimitingEnable = config.isPreciseTopicPublishRateLimiterEnable(); //创建发布限流 topicPublishRateLimiter = new PublishRateLimiterImpl(brokerService.getPulsar().getMonotonicSnapshotClock()); //更新限流策略 updateActiveRateLimiters(); } public PersistentTopic(String topic, ManagedLedger ledger, BrokerService brokerService) { super(topic, brokerService); //赋值操作 this.orderedExecutor = brokerService.getTopicOrderedExecutor() != null ? brokerService.getTopicOrderedExecutor().chooseThread(topic) : null; this.ledger = ledger; //初始化容器，分别是维护当前Topic的订阅情况、跨集群副本情况 this.subscriptions = ConcurrentOpenHashMap.\u0026lt;String, PersistentSubscription\u0026gt;newBuilder() .expectedItems(16) .concurrencyLevel(1) .build(); this.replicators = ConcurrentOpenHashMap.\u0026lt;String, Replicator\u0026gt;newBuilder() .expectedItems(16) .concurrencyLevel(1) .build(); this.shadowReplicators = ConcurrentOpenHashMap.\u0026lt;String, Replicator\u0026gt;newBuilder() .expectedItems(16) .concurrencyLevel(1) .build(); this.backloggedCursorThresholdEntries = brokerService.pulsar().getConfiguration().getManagedLedgerCursorBackloggedThreshold(); .... } 2. initialize方法 初始化方法的逻辑相比下要丰富写，归纳起来有以下四点\n获取压缩服务\n通过双重判断获取单例TwoPhaseCompactor进行压缩，有专门的线程池进行处理压缩动作\n遍历游标恢复订阅的状态\n当Topic重新分配后，在新的Broker中要根据游标恢复订阅、跨集群复制的状态，这样才能让客户端“无感”\n跨集群复制\n遍历这个Topic的游标，如果游标中存在跨集群复制游标则创建对应的GeoPersistentReplicator对象进行消息的复制\n更新配置\n更新Topic命名空间的配置策略 初始化调度限流DispatchRateLimiter 更新订阅/发布/资源组限流 更新Topic级别的配置 具体代码实现如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 public CompletableFuture\u0026lt;Void\u0026gt; initialize() { List\u0026lt;CompletableFuture\u0026lt;Void\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;\u0026gt;(); //获取Broker压缩对象 futures.add(brokerService.getPulsar().newTopicCompactionService(topic) .thenAccept(service -\u0026gt; { PersistentTopic.this.topicCompactionService = service; //遍历这个Topic的游标恢复订阅中的对象 this.createPersistentSubscriptions(); })); //遍历这个Topic的游标，如果游标中存在跨集群复制游标则创建对应的GeoPersistentReplicator对象进行消息的复制 for (ManagedCursor cursor : ledger.getCursors()) { if (cursor.getName().startsWith(replicatorPrefix)) { String localCluster = brokerService.pulsar().getConfiguration().getClusterName(); String remoteCluster = PersistentReplicator.getRemoteCluster(cursor.getName()); futures.add(addReplicationCluster(remoteCluster, cursor, localCluster)); } } return FutureUtil.waitForAll(futures).thenCompose(__ -\u0026gt; brokerService.pulsar().getPulsarResources().getNamespaceResources() .getPoliciesAsync(TopicName.get(topic).getNamespaceObject()) .thenAcceptAsync(optPolicies -\u0026gt; { if (!optPolicies.isPresent()) { isEncryptionRequired = false; updatePublishDispatcher(); //进行资源组级别的隔离 updateResourceGroupLimiter(new Policies()); initializeDispatchRateLimiterIfNeeded(); updateSubscribeRateLimiter(); return; } Policies policies = optPolicies.get(); //更新命名空间级别的策略 this.updateTopicPolicyByNamespacePolicy(policies); //初始化调度限流 initializeDispatchRateLimiterIfNeeded(); //更新订阅限流 updateSubscribeRateLimiter(); //更新发布限流 updatePublishDispatcher(); //更新资源组限流 updateResourceGroupLimiter(policies); this.isEncryptionRequired = policies.encryption_required; isAllowAutoUpdateSchema = policies.is_allow_auto_update_schema; }, getOrderedExecutor()) .thenCompose(ignore -\u0026gt; initTopicPolicy()) .exceptionally(ex -\u0026gt; { .... })); } 三、负责内容 1、生产者相关 新增 生产者客户端启动时会跟Topic归属的Broker建立TCP连接并请求Broker端ServerCnx的handleProducer方法进行处理，这个方法最终会调用PersistentTopic的addProducer方法进行创建，咱们来看看实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public CompletableFuture\u0026lt;Optional\u0026lt;Long\u0026gt;\u0026gt; addProducer(Producer producer, CompletableFuture\u0026lt;Void\u0026gt; producerQueuedFuture) { //进去看看父类的实现 return super.addProducer(producer, producerQueuedFuture).thenCompose(topicEpoch -\u0026gt; { messageDeduplication.producerAdded(producer.getProducerName()); // Start replication producers if not already return startReplProducers().thenApply(__ -\u0026gt; topicEpoch); }); } public CompletableFuture\u0026lt;Optional\u0026lt;Long\u0026gt;\u0026gt; addProducer(Producer producer, CompletableFuture\u0026lt;Void\u0026gt; producerQueuedFuture) { .... //继续跟踪 return internalAddProducer(producer); .... } protected CompletableFuture\u0026lt;Void\u0026gt; internalAddProducer(Producer producer) { .... //producers是ConcurrentHashMap结构，相当于会在PersistentTopic中维护服务端的生产者对象 Producer existProducer = producers.putIfAbsent(producer.getProducerName(), producer); .... return CompletableFuture.completedFuture(null); } 删除 删除的逻辑很简单，也是通过TCP接收到客户端断开连接的请求后，会调用Producer的close方法进行资源释放，同时从维护的producers中移除此对象\n2. 订阅相关 消费者客户端启动时会跟Topic归属的Broker建立TCP连接并请求Broker端，请求由ServerCnx的handleSubscribe方法进行处理，这个方法最终会调用PersistentTopic的internalSubscribe方法进行创建，咱们来看看实现\n新增 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 private CompletableFuture\u0026lt;Consumer\u0026gt; internalSubscribe(final TransportCnx cnx, String subscriptionName, long consumerId, SubType subType, int priorityLevel, String consumerName, boolean isDurable, MessageId startMessageId, Map\u0026lt;String, String\u0026gt; metadata, boolean readCompacted, InitialPosition initialPosition, long startMessageRollbackDurationSec, boolean replicatedSubscriptionStateArg, KeySharedMeta keySharedMeta, Map\u0026lt;String, String\u0026gt; subscriptionProperties, long consumerEpoch, SchemaType schemaType) { .... //创建对应的客户端对象 Consumer consumer = new Consumer(subscription, subType, topic, consumerId, priorityLevel, consumerName, isDurable, cnx, cnx.getAuthRole(), metadata, readCompacted, keySharedMeta, startMessageId, consumerEpoch, schemaType); .... //将消费者对象加到订阅里 return addConsumerToSubscription(subscription, consumer); } protected CompletableFuture\u0026lt;Void\u0026gt; addConsumerToSubscription(Subscription subscription, Consumer consumer) { .... //最终将将创建的消费者放到Dispatcher中进行管理以及加到subscriptions这个Map中进行维护 return subscription.addConsumer(consumer); } 删除 删除的逻辑也是比较简单的，就是从subscriptions中进行移除\n3. 处理消息写入 消息写入的流程相对比较复杂，后面再单独分析，暂时跳过\n4. 跨集群复制 跨集群复制这里实现逻辑其实不难，相当于在Broker上去读取Bookkeeper获取数据并通过启动生产者往其他集群进行数据写入，具体细节后面也单独写文章进行分析\n5. 消息清理 Pulsar的消息TTL、积压、压缩都是在Broker启动时往线程池中加入定时任务轮询触发的\nTTL TTL会循环扫描每个Topic过期的消息位置，并通过改变游标进行标记，而清理是由专门的线程根据游标进行处理的\n积压 消息积压也是会定期检测，分两种情况，一种是消息超过限制额度，另一种是消息时间超过额度。这两种情况都会触发积压策略的处理，具体的策略在BacklogQuota.RetentionPolicy中定义\n压缩 跟上面一样，轮询检测进行处理\n配置更新 在PersistentTopic启动的初始化initialize方法中会调用onUpdate进行策略更新，那Pulsar又是如何做的支持配置动态更新的呢？这个问题保留给大家\n四、总结 本文主要强调PersistentTopic类的重要性、聊聊它都负责哪些事情以及大概实现，具体每个细节展开都能单独写一篇文章，这个敬请期待～\n","date":"2024-03-27T10:34:55+08:00","image":"https://sherlock-lin.github.io/p/pulsar%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8Bpersistenttopic%E7%B1%BB/image-20240327210450901-6219390_hu18382412844183478919.png","permalink":"https://sherlock-lin.github.io/p/pulsar%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8Bpersistenttopic%E7%B1%BB/","title":"Pulsar源码解析之PersistentTopic类"},{"content":"失效的自律 在人生的每个阶段，我好像都有遇到那种天然就知道自己该做什么事情并且极度“自律”的人，上学那会就有同学雷打不动的学习，哪怕没人监督也照样认真学习。与之相比的我感觉就像是这个世界的NPC一样，做事三分热度，感兴趣的时候也能热血沸腾狠狠学一段时间，但是大部分时候还是想偷懒，一直以来觉得是自己自控力问题导致自己不够自律，也会是不是给自己定制计划并设置奖惩，但最后都不了了之。你是否也有同样的经历并且苦恼呢\n高级的欲望 相比想方设法去让自己自律，我们更应该做的是挖掘自己内心更深层次的高级欲望，打游戏确实可以带来短时间的多巴胺，但是提升学习技能所带来的内啡肽比多巴胺更加吸引人。高级欲望一般难度相比更大，它填满时的喜悦以及成就感远远不是低级欲望所能比拟的。而作为一个需要及时反馈的普通人来说，可以讲高级欲望的目标进行划分，每个时间段攻克其中一小块，这不仅也能带来喜悦同时也能有中升级打怪的成就感。同时也要尽可能找到可以观测到的输出方式，例如输出文章，或者说学乐器的话就是熟练练会一首曲子，学英语的话就是掌握100个单词等等。除了这些外，最好是能发现或者点燃内心对某个东西的热爱，当你在做一件真正热爱的事情时，别说要你坚持，即便很多人都不让你去做，你也会发了疯的去拼命做。最后一点最重要的就是，行动起来，说再多都比不上动作做一次～\n","date":"2024-03-21T15:09:14+08:00","image":"https://sherlock-lin.github.io/p/%E5%85%8B%E6%9C%8D%E6%AC%B2%E6%9C%9B%E7%9A%84%E6%B0%B8%E8%BF%9C%E4%B8%8D%E6%98%AF%E8%87%AA%E5%BE%8B%E8%80%8C%E6%98%AF%E6%9B%B4%E9%AB%98%E7%BA%A7%E7%9A%84%E6%AC%B2%E6%9C%9B/image-20240321191336836-6816731_hu1393761622652813113.png","permalink":"https://sherlock-lin.github.io/p/%E5%85%8B%E6%9C%8D%E6%AC%B2%E6%9C%9B%E7%9A%84%E6%B0%B8%E8%BF%9C%E4%B8%8D%E6%98%AF%E8%87%AA%E5%BE%8B%E8%80%8C%E6%98%AF%E6%9B%B4%E9%AB%98%E7%BA%A7%E7%9A%84%E6%AC%B2%E6%9C%9B/","title":"克服欲望的永远不是自律，而是更高级的欲望"},{"content":"引言 无论你是刚接触Pulsar还是使用Pulsar多年，相信你对下面这段代码都很熟悉，这就是生产者端最常写的代码没有之一，其中最核心的其实就三行代码，分别用红色数字标识出来了，其中对应的就是1、客户端对象创建 2、生产者对象创建 3、消息发送。今天就分别针对这三个步骤进行深入的探索。\n创建客户端对象 无论是写生产者还是消费者端代码，第一步都是要创建客户端对象，那么客户端对象都做了些什么事情呢？这里将客户端对象创建的步骤绘制成以下图\n客户端对象的创建以下几个东西，其中最重要的是前两个\nLookup服务 连接池 线程池 内存控制器MemoryLimitController 创建客户端计数器HashedWheelTimer Lookup服务 Lookup服务负责获取Topic的归属Broker地址以及Schema信息等，非常重要。默认有HTTP和二进制传输两种实现，如果创建客户端对象时.serviceUrl方法传入的地址是http开头则使用HTTP实现，否则就是二进制传输实现。\nLookup服务的创建如下\n1 2 3 4 5 6 7 //初始化LookupService服务 if (conf.getServiceUrl().startsWith(\u0026#34;http\u0026#34;)) { lookup = new HttpLookupService(conf, this.eventLoopGroup); } else { lookup = new BinaryProtoLookupService(this, conf.getServiceUrl(), conf.getListenerName(), conf.isUseTls(), this.scheduledExecutorProvider.getExecutor()); } 进入看看HttpLookupService的构造方法可以看到它是内部套了一个HttpClient对象来对外进行HTTP通信，在继续看HttpClient的构造函数可以它内部实际上是调用的DefaultAsyncHttpClient构造函数来创建，这个对象是外部包 async-http-client-2.12.1.jar的实现，跟了一下代码，底层也是基于Netty来进行实现的HTTP长连接通信\n1 2 3 4 5 6 7 8 9 10 11 public HttpLookupService(ClientConfigurationData conf, EventLoopGroup eventLoopGroup) throws PulsarClientException { this.httpClient = new HttpClient(conf, eventLoopGroup); this.useTls = conf.isUseTls(); this.listenerName = conf.getListenerName(); } protected HttpClient(ClientConfigurationData conf, EventLoopGroup eventLoopGroup) throws PulsarClientException { .... httpClient = new DefaultAsyncHttpClient(config); } 跟到这里就差不多了，我们知道创建客户端对象的时候会初始化Lookup服务，而Lookup服务初始化的时候会创建跟外部进行通信的异步HTTP客户端，用于在创建生产者时去查询Topic的归属Broker的IP地址，这样生产者才知道具体去跟哪台Broker创建TCP连接\n连接池ConnectionPool 连接池是池化技术在网络连接这个场景的使用，使用连接池可以避免重复创建关闭TCP连接造成资源浪费以及提升性能。在创建客户端对象的构造方法中，ConnectionPool的创建如下，可以是通过new方式进行创建，因此我们看下它的构造方法\n1 2 connectionPoolReference = connectionPool != null ? connectionPool : new ConnectionPool(conf, this.eventLoopGroup); ConnectionPool的构造方法如下，可以看到核心逻辑其实就是通过Bootstrap创建Netty客户端对象，通过 pool = new ConcurrentHashMap\u0026lt;\u0026gt;(); 这行代码也很重要，这个HashMap就是存储咱们的网络连接\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public ConnectionPool(ClientConfigurationData conf, EventLoopGroup eventLoopGroup, Supplier\u0026lt;ClientCnx\u0026gt; clientCnxSupplier, Optional\u0026lt;AddressResolver\u0026lt;InetSocketAddress\u0026gt;\u0026gt; addressResolver) throws PulsarClientException { .... //启动Netty客户端 pool = new ConcurrentHashMap\u0026lt;\u0026gt;(); bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup); bootstrap.channel(EventLoopUtil.getClientSocketChannelClass(eventLoopGroup)); //Netty相关配置 bootstrap.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, conf.getConnectionTimeoutMs()); bootstrap.option(ChannelOption.TCP_NODELAY, conf.isUseTcpNoDelay()); bootstrap.option(ChannelOption.ALLOCATOR, PulsarByteBufAllocator.DEFAULT); try { channelInitializerHandler = new PulsarChannelInitializer(conf, clientCnxSupplier); bootstrap.handler(channelInitializerHandler); } catch (Exception e) { log.error(\u0026#34;Failed to create channel initializer\u0026#34;); throw new PulsarClientException(e); } .... } 生产者对象创建 看完了客户端对象创建，再来看看生产者对象的创建，从这条语句进行切入 Producer\u0026lt;String\u0026gt; producer = pulsarClient.newProducer(...).create(); 在创建生产者对象时会进行一下几步\n指定路由策略 这个主要就是根据创建生产者对象时指定的，如果没有配置的话默认使用的轮询路由策略。setMessageRoutingMode 这个方法就是指定路由策略的，然后指定完后下面的代码可以看到，如果有配置拦截器的话在创建生产者对象时也会把它给拦截逻辑加载进去。\n1 2 3 4 5 6 7 8 9 10 11 12 public CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; createAsync() { .... try { setMessageRoutingMode(); } catch (PulsarClientException pce) { return FutureUtil.failedFuture(pce); } return interceptorList == null || interceptorList.size() == 0 ? client.createProducerAsync(conf, schema, null) : client.createProducerAsync(conf, schema, new ProducerInterceptors(interceptorList)); } setMessageRoutingMode 逻辑如下，默认用轮询路由，如果配置其他的就用其他的，其次就是做路由规则的校验，看看用户是否配置的信息有冲突的提前感知并抛出去。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 private void setMessageRoutingMode() throws PulsarClientException { if (conf.getMessageRoutingMode() == null \u0026amp;\u0026amp; conf.getCustomMessageRouter() == null) { messageRoutingMode(MessageRoutingMode.RoundRobinPartition); } else if (conf.getMessageRoutingMode() == null \u0026amp;\u0026amp; conf.getCustomMessageRouter() != null) { messageRoutingMode(MessageRoutingMode.CustomPartition); } else if (conf.getMessageRoutingMode() == MessageRoutingMode.CustomPartition \u0026amp;\u0026amp; conf.getCustomMessageRouter() == null) { throw new PulsarClientException(\u0026#34;When \u0026#39;messageRoutingMode\u0026#39; is \u0026#34; + MessageRoutingMode.CustomPartition + \u0026#34;, \u0026#39;messageRouter\u0026#39; should be set\u0026#34;); } else if (conf.getMessageRoutingMode() != MessageRoutingMode.CustomPartition \u0026amp;\u0026amp; conf.getCustomMessageRouter() != null) { throw new PulsarClientException(\u0026#34;When \u0026#39;messageRouter\u0026#39; is set, \u0026#39;messageRoutingMode\u0026#39; \u0026#34; + \u0026#34;should be set as \u0026#34; + MessageRoutingMode.CustomPartition); } } 获取Topic分区数和Schema 通过Lookup机制去Broker中查询这个Topic的Schema信息，可以看到如果服务端没有配置Schema信息的话则默认用 Schema.BYTES\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 return lookup.getSchema(TopicName.get(conf.getTopicName())) .thenCompose(schemaInfoOptional -\u0026gt; { if (schemaInfoOptional.isPresent()) { SchemaInfo schemaInfo = schemaInfoOptional.get(); if (schemaInfo.getType() == SchemaType.PROTOBUF) { autoProduceBytesSchema.setSchema(new GenericAvroSchema(schemaInfo)); } else { autoProduceBytesSchema.setSchema(Schema.getSchema(schemaInfo)); } } else { autoProduceBytesSchema.setSchema(Schema.BYTES); } return createProducerAsync(topic, conf, schema, interceptors); }); 咱们进去看看 getSchema 的实现，可以看到构造的是HTTP地址并通过GET方式请求Broker进行获取\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public CompletableFuture\u0026lt;Optional\u0026lt;SchemaInfo\u0026gt;\u0026gt; getSchema(TopicName topicName, byte[] version) { CompletableFuture\u0026lt;Optional\u0026lt;SchemaInfo\u0026gt;\u0026gt; future = new CompletableFuture\u0026lt;\u0026gt;(); String schemaName = topicName.getSchemaName(); String path = String.format(\u0026#34;admin/v2/schemas/%s/schema\u0026#34;, schemaName); if (version != null) { if (version.length == 0) { future.completeExceptionally(new SchemaSerializationException(\u0026#34;Empty schema version\u0026#34;)); return future; } path = String.format(\u0026#34;admin/v2/schemas/%s/schema/%s\u0026#34;, schemaName, ByteBuffer.wrap(version).getLong()); } httpClient.get(path, GetSchemaResponse.class).thenAccept(response -\u0026gt; { if (response.getType() == SchemaType.KEY_VALUE) { SchemaData data = SchemaData .builder() .data(SchemaUtils.convertKeyValueDataStringToSchemaInfoSchema( response.getData().getBytes(StandardCharsets.UTF_8))) .type(response.getType()) .props(response.getProperties()) .build(); future.complete(Optional.of(SchemaInfoUtil.newSchemaInfo(schemaName, data))); } else { future.complete(Optional.of(SchemaInfoUtil.newSchemaInfo(schemaName, response))); } }).exceptionally(ex -\u0026gt; { .... }); return future; } 除了读取Schema，还会读取Topic的分区信息，从下面创建的代码可以看到，如果存在分区则创建PartitionedProducerImpl对象，不存在分区则创建ProducerImpl对象。获取分区的方法是 getPartitionedTopicMetadata，咱们进去看看它的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 private \u0026lt;T\u0026gt; CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; createProducerAsync(String topic, ProducerConfigurationData conf, Schema\u0026lt;T\u0026gt; schema, ProducerInterceptors interceptors) { CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; producerCreatedFuture = new CompletableFuture\u0026lt;\u0026gt;(); getPartitionedTopicMetadata(topic).thenAccept(metadata -\u0026gt; { .... ProducerBase\u0026lt;T\u0026gt; producer; if (metadata.partitions \u0026gt; 0) { producer = newPartitionedProducerImpl(topic, conf, schema, interceptors, producerCreatedFuture, metadata); } else { producer = newProducerImpl(topic, -1, conf, schema, interceptors, producerCreatedFuture, Optional.empty()); } producers.add(producer); }).exceptionally(ex -\u0026gt; { .... }); return producerCreatedFuture; } getPartitionedTopicMetadata方法的核心逻辑如下，通过一路跟踪下去发现也是通过Lookup服务进行HTTP进行查询读取分区信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public CompletableFuture\u0026lt;PartitionedTopicMetadata\u0026gt; getPartitionedTopicMetadata(String topic) { CompletableFuture\u0026lt;PartitionedTopicMetadata\u0026gt; metadataFuture = new CompletableFuture\u0026lt;\u0026gt;(); try { TopicName topicName = TopicName.get(topic); AtomicLong opTimeoutMs = new AtomicLong(conf.getLookupTimeoutMs()); .... getPartitionedTopicMetadata(topicName, backoff, opTimeoutMs, metadataFuture, new ArrayList\u0026lt;\u0026gt;()); } catch (IllegalArgumentException e) { .... } return metadataFuture; } private void getPartitionedTopicMetadata(TopicName topicName, Backoff backoff, AtomicLong remainingTime, CompletableFuture\u0026lt;PartitionedTopicMetadata\u0026gt; future, List\u0026lt;Throwable\u0026gt; previousExceptions) { long startTime = System.nanoTime(); lookup.getPartitionedTopicMetadata(topicName).thenAccept(future::complete).exceptionally(e -\u0026gt; { remainingTime.addAndGet(-1 * TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime)); long nextDelay = Math.min(backoff.next(), remainingTime.get()); // skip retry scheduler when set lookup throttle in client or server side which will lead to // `TooManyRequestsException` boolean isLookupThrottling = !PulsarClientException.isRetriableError(e.getCause()) || e.getCause() instanceof PulsarClientException.AuthenticationException; if (nextDelay \u0026lt;= 0 || isLookupThrottling) { PulsarClientException.setPreviousExceptions(e, previousExceptions); future.completeExceptionally(e); return null; } .... }); } public CompletableFuture\u0026lt;PartitionedTopicMetadata\u0026gt; getPartitionedTopicMetadata(TopicName topicName) { String format = topicName.isV2() ? \u0026#34;admin/v2/%s/partitions\u0026#34; : \u0026#34;admin/%s/partitions\u0026#34;; return httpClient.get(String.format(format, topicName.getLookupName()) + \u0026#34;?checkAllowAutoCreation=true\u0026#34;, PartitionedTopicMetadata.class); } 创建生产者对象 在上一小结可以看到已经查到分区信息，在有分区的情况是会调用 newPartitionedProducerImpl 方法进行生产者对象的初始化，现在就从这里开始进行跟踪，可以看到这个方法只是封装了new PartitionedProducerImpl对象的操作，于是继续看PartitionedProducerImpl的构造函数的逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 protected \u0026lt;T\u0026gt; PartitionedProducerImpl\u0026lt;T\u0026gt; newPartitionedProducerImpl(String topic, ProducerConfigurationData conf, Schema\u0026lt;T\u0026gt; schema, ProducerInterceptors interceptors, CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; producerCreatedFuture, PartitionedTopicMetadata metadata) { return new PartitionedProducerImpl\u0026lt;\u0026gt;(PulsarClientImpl.this, topic, conf, metadata.partitions, producerCreatedFuture, schema, interceptors); } public PartitionedProducerImpl(PulsarClientImpl client, String topic, ProducerConfigurationData conf, int numPartitions, CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; producerCreatedFuture, Schema\u0026lt;T\u0026gt; schema, ProducerInterceptors interceptors) { super(client, topic, conf, producerCreatedFuture, schema, interceptors); this.producers = ConcurrentOpenHashMap.\u0026lt;Integer, ProducerImpl\u0026lt;T\u0026gt;\u0026gt;newBuilder().build(); this.topicMetadata = new TopicMetadataImpl(numPartitions); //配置路由策略 this.routerPolicy = getMessageRouter(); stats = client.getConfiguration().getStatsIntervalSeconds() \u0026gt; 0 ? new PartitionedTopicProducerStatsRecorderImpl() : null; //配置最大同时等待的消息数 int maxPendingMessages = Math.min(conf.getMaxPendingMessages(), conf.getMaxPendingMessagesAcrossPartitions() / numPartitions); conf.setMaxPendingMessages(maxPendingMessages); final List\u0026lt;Integer\u0026gt; indexList; if (conf.isLazyStartPartitionedProducers() \u0026amp;\u0026amp; conf.getAccessMode() == ProducerAccessMode.Shared) { // try to create producer at least one partition indexList = Collections.singletonList(routerPolicy .choosePartition(((TypedMessageBuilderImpl\u0026lt;T\u0026gt;) newMessage()).getMessage(), topicMetadata)); } else { // try to create producer for all partitions indexList = IntStream.range(0, topicMetadata.numPartitions()).boxed().collect(Collectors.toList()); } firstPartitionIndex = indexList.get(0); //这里是核心逻辑，从这里进去 start(indexList); // start track and auto subscribe partition increasement if (conf.isAutoUpdatePartitions()) { topicsPartitionChangedListener = new TopicsPartitionChangedListener(); partitionsAutoUpdateTimeout = client.timer() .newTimeout(partitionsAutoUpdateTimerTask, conf.getAutoUpdatePartitionsIntervalSeconds(), TimeUnit.SECONDS); } } private void start(List\u0026lt;Integer\u0026gt; indexList) { .... final ProducerImpl\u0026lt;T\u0026gt; firstProducer = createProducer(indexList.get(0)); firstProducer.producerCreatedFuture().handle((prod, createException) -\u0026gt; { .... }).thenApply(name -\u0026gt; { for (int i = 1; i \u0026lt; indexList.size(); i++) { //循环分区数创建与之对应的ProducerImpl对象 createProducer(indexList.get(i), name).producerCreatedFuture().handle((prod, createException) -\u0026gt; { afterCreatingProducer.accept(false, createException); return null; }); } return null; }); } 继续从 createProducer 方法进行跟踪\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 private ProducerImpl\u0026lt;T\u0026gt; createProducer(final int partitionIndex, final Optional\u0026lt;String\u0026gt; overrideProducerName) { //创建ProducerImpl后会统一放到producers这个Map中，key是分区号，value就是ProducerImpl对象 return producers.computeIfAbsent(partitionIndex, (idx) -\u0026gt; { String partitionName = TopicName.get(topic).getPartition(idx).toString(); //继续进入看看ProducerImpl创建的逻辑 return client.newProducerImpl(partitionName, idx, conf, schema, interceptors, new CompletableFuture\u0026lt;\u0026gt;(), overrideProducerName); }); } public ProducerImpl(PulsarClientImpl client, String topic, ProducerConfigurationData conf, CompletableFuture\u0026lt;Producer\u0026lt;T\u0026gt;\u0026gt; producerCreatedFuture, int partitionIndex, Schema\u0026lt;T\u0026gt; schema, ProducerInterceptors interceptors, Optional\u0026lt;String\u0026gt; overrideProducerName) { .... this.compressor = CompressionCodecProvider.getCompressionCodec(conf.getCompressionType()); .... //这里是核心逻辑，用于创建ProducerImpl对象跟对应的Broker的TCP网络连接 grabCnx(); } 创建连接 从上一小节可以看到代码逻辑跟到了grabCnx 方法，继续一路跟踪下去，可以看到最后都会调用 state.client.getConnection, 继续往里面看看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 void grabCnx() { this.connectionHandler.grabCnx(); } protected void grabCnx() { grabCnx(Optional.empty()); } protected void grabCnx(Optional\u0026lt;URI\u0026gt; hostURI) { .... cnxFuture = state.client.getConnection(address, address, randomKeyForSelectConnection); .... } public CompletableFuture\u0026lt;ClientCnx\u0026gt; getConnection(final InetSocketAddress logicalAddress, final InetSocketAddress physicalAddress, final int randomKeyForSelectConnection) { //可以看到调用连接池进行网络连接的获取，继续进去看看实现细节 return cnxPool.getConnection(logicalAddress, physicalAddress, randomKeyForSelectConnection); } public CompletableFuture\u0026lt;ClientCnx\u0026gt; getConnection(InetSocketAddress logicalAddress, InetSocketAddress physicalAddress, final int randomKey) { if (maxConnectionsPerHosts == 0) { // 如果配置没开启连接池，则每一次都重新新建一个TCP连接 return createConnection(logicalAddress, physicalAddress, -1); } final ConcurrentMap\u0026lt;Integer, CompletableFuture\u0026lt;ClientCnx\u0026gt;\u0026gt; innerPool = pool.computeIfAbsent(logicalAddress, a -\u0026gt; new ConcurrentHashMap\u0026lt;\u0026gt;()); // 新建TCP网络连接并放在连接池中以备之后的复用,继续进去看createConnection的逻辑 CompletableFuture\u0026lt;ClientCnx\u0026gt; completableFuture = innerPool .computeIfAbsent(randomKey, k -\u0026gt; createConnection(logicalAddress, physicalAddress, randomKey)); .... } private CompletableFuture\u0026lt;ClientCnx\u0026gt; createConnection(InetSocketAddress logicalAddress, InetSocketAddress physicalAddress, int connectionKey) { .... // 继续进去看createConnection的逻辑 createConnection(logicalAddress, physicalAddress).thenAccept(channel -\u0026gt; { .... }).exceptionally(exception -\u0026gt; { .... }); return cnxFuture; } private CompletableFuture\u0026lt;Channel\u0026gt; createConnection(InetSocketAddress logicalAddress, InetSocketAddress unresolvedPhysicalAddress) { CompletableFuture\u0026lt;List\u0026lt;InetSocketAddress\u0026gt;\u0026gt; resolvedAddress; try { .... return resolvedAddress.thenCompose( inetAddresses -\u0026gt; connectToResolvedAddresses( logicalAddress, unresolvedPhysicalAddress, inetAddresses.iterator(), isSniProxy ? unresolvedPhysicalAddress : null) ); } catch (URISyntaxException e) { .... } } private CompletableFuture\u0026lt;Channel\u0026gt; connectToResolvedAddresses(...) { CompletableFuture\u0026lt;Channel\u0026gt; future = new CompletableFuture\u0026lt;\u0026gt;(); // 继续往下跟踪 connectToAddress(logicalAddress, resolvedPhysicalAddress.next(), unresolvedPhysicalAddress, sniHost) .... return null; }); return future; } private CompletableFuture\u0026lt;Channel\u0026gt; connectToAddress(InetSocketAddress logicalAddress, InetSocketAddress physicalAddress, InetSocketAddress unresolvedPhysicalAddress, InetSocketAddress sniHost) { .... //终于跟踪到了，就是bootstrap.register() 这个方法，可以尝试往里面看看实现，从这里开始就是Netty的代码了 return toCompletableFuture(bootstrap.register()) .thenCompose(channelInitializerHandler::initSocks5IfConfig) .thenCompose(ch -\u0026gt; channelInitializerHandler.initializeClientCnx(ch, logicalAddress, unresolvedPhysicalAddress)) .thenCompose(channel -\u0026gt; toCompletableFuture(channel.connect(physicalAddress))); } public ChannelFuture register() { validate(); //继续往下 return initAndRegister(); } final ChannelFuture initAndRegister() { Channel channel = null; try { //新建一条网络通道到Broker channel = channelFactory.newChannel(); init(channel); } catch (Throwable t) { .... } .... return regFuture; } 从上面的代码跟踪可以看到，生产者对象在创建的时候会通过Netty客户端跟Topic所在的Broker建立TCP网络连接，方便后续的通信\n消息发送 消息发送流程大致如下图\n在选择消息发送是，生产者对象会根据路由策略来决定用目标分区所对应的ProducerImpl对象进行处理 发送前会按照顺序对数据进行拦截器链逻辑处理(如果有配置的话)，然后进行压缩最后再进行序列化操作(消息传输/存储必须序列化) 消息发送前会放到待确认队列中进行维护，每个分区都有一个对应的确认队列，在消息写入成功后会从对应的确认队列中将自己删除，否则这条消息不算写入成功。 将消息发送操作封装成一个任务交给线程池中的一个线程进行最后的发送操作 Broker将数据写入成功后向客户端返回ack，客户端通过ack中携带的消息信息到待确认队列中进行消息的删除 那么老规矩，继续一起看下代码实现吧\n发送流程前置操作 就从常见的这条语句进行切入 producer.sendAsync(\u0026quot;hello java API pulsar:\u0026quot;+i+\u0026quot;, 当前时间为：\u0026quot;+new Date()); 。通过代码中可以看到sendAsync 方法是从其父类ProducerBase中继承的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public CompletableFuture\u0026lt;MessageId\u0026gt; sendAsync(Message\u0026lt;?\u0026gt; message) { //继续跟踪进去 return internalSendAsync(message); } //这是一个抽象方法，有分区生产者和非分区生产者两种实现，跟踪分区生产者的实现逻辑 abstract CompletableFuture\u0026lt;MessageId\u0026gt; internalSendAsync(Message\u0026lt;?\u0026gt; message); CompletableFuture\u0026lt;MessageId\u0026gt; internalSendAsync(Message\u0026lt;?\u0026gt; message) { //继续往里面跟踪 return internalSendWithTxnAsync(message, null); } CompletableFuture\u0026lt;MessageId\u0026gt; internalSendWithTxnAsync(Message\u0026lt;?\u0026gt; message, Transaction txn) { .... //还有印象吗，在生产者创建时会维护一个以分区号为key，ProducerImpl为value的Map，现在从里面获取相对应的对象进行处理 return producers.get(partition).internalSendWithTxnAsync(message, txn); } 消息处理以及包装 又回到ProducerImpl对象的逻辑了，相当于分区生产者对象只是个壳，无论分区还是非分区最终都是调用的ProducerImpl进行消息发送的真正逻辑，不废话继续往下看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 CompletableFuture\u0026lt;MessageId\u0026gt; internalSendWithTxnAsync(Message\u0026lt;?\u0026gt; message, Transaction txn) { .... return internalSendAsync(message); } CompletableFuture\u0026lt;MessageId\u0026gt; internalSendAsync(Message\u0026lt;?\u0026gt; message) { .... //拦截器的逻辑就是在这里生效 MessageImpl\u0026lt;?\u0026gt; interceptorMessage = (MessageImpl) beforeSend(message); .... //核心逻辑，继续切入 sendAsync(interceptorMessage, new SendCallback() { .... }); return future; } public void sendAsync(Message\u0026lt;?\u0026gt; message, SendCallback callback) { checkArgument(message instanceof MessageImpl); .... //核心逻辑，从名字可以看到就是对消息进行序列化并进行发送逻辑，继续跟进去 serializeAndSendMessage(msg, payload, sequenceId, uuid, chunkId, totalChunks, readStartIndex, payloadChunkSize, compressedPayload, compressed, compressedPayload.readableBytes(), callback, chunkedMessageCtx, messageId); } catch (PulsarClientException e) { .... } } private void serializeAndSendMessage(....) throws IOException { //核心逻辑，op是OpSendMsg对象，封装了要发送的消息内容，继续往下跟 processOpSendMsg(op); } } 消息发送 数据已经处理包装得差不多了，接下来就是发送的逻辑，咱们顺着 processOpSendMsg 方法继续往下看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 protected void processOpSendMsg(OpSendMsg op) { .... //将消息加到OpSendMsgQueue队列中，这就是“等待确认队列” pendingMessages.add(op); .... //ClientCnx对象维护着Netty实现跟Broker的TCP连接 final ClientCnx cnx = getCnxIfReady(); if (cnx != null) { .... //WriteInEventLoopCallback方法的run方法执行会将数据发送出去，然后队列中维护消息的状态 cnx.ctx().channel().eventLoop().execute(WriteInEventLoopCallback.create(this, cnx, op)); stats.updateNumMsgsSent(op.numMessagesInBatch, op.batchSizeByte); } else { .... } } catch (Throwable t) { .... } } //WriteInEventLoopCallback是一个线程类，被放到线程池里面执行，因此直接看它的run方法 private static final class WriteInEventLoopCallback implements Runnable { public void run() { .... try { //熟悉Netty的朋友相信对writeAndFlush方法不默认，就是通过之间建立好的TCP连接将数据发送到Broker去 cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise()); op.updateSentTimestamp(); } finally { recycle(); } } } 跟踪到这里基本就结束了，对Netty感兴趣的朋友可以再继续往下跟，这里可以简单说一下，其实它内部是对JDK的NIO做了包装和优化，最底层也是通过Java的Socket连接网络端口进行的数据发送。不知道有没有小伙伴发现，咦，怎么没有对返回结果进行处理的逻辑呢？这就是所谓的异步设计，Netty不就是一个异步通信框架吗，客户端发送的逻辑到这里就是彻底结束了，而消息的处理结束就是要等服务端Broker向客户端发起消息ack请求了，想知道Pulsar怎么实现的吗？那就跟着我一起瞅瞅吧～\n消息确认 消息确认流程是由Broker端发起的，那么生产者对象肯定是通过Netty客户端接收的，所以直接看Pulsar实现的ChannelInboundHandlerAdapter类的channelRead的逻辑即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public abstract class PulsarDecoder extends ChannelInboundHandlerAdapter { public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { .... switch (cmd.getType()) { .... //可以看得到消息有写成功的后续处理动作，那就从这里看看 case PRODUCER_SUCCESS: checkArgument(cmd.hasProducerSuccess()); handleProducerSuccess(cmd.getProducerSuccess()); break; case UNSUBSCRIBE: checkArgument(cmd.hasUnsubscribe()); safeInterceptCommand(cmd); handleUnsubscribe(cmd.getUnsubscribe()); break; } } } handleProducerSuccess这个方法的是由ClientCnx对象进行实现的，那就跟进来看看吧\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 protected void handleProducerSuccess(CommandProducerSuccess success) { checkArgument(state == State.Ready); if (log.isDebugEnabled()) { log.debug(\u0026#34;{} Received producer success response from server: {} - producer-name: {}\u0026#34;, ctx.channel(), success.getRequestId(), success.getProducerName()); } long requestId = success.getRequestId(); if (!success.isProducerReady()) { //还记得pendingRequests 这个“待确认队列”吗，现在会从里面查询对应的消息 TimedCompletableFuture\u0026lt;?\u0026gt; requestFuture = pendingRequests.get(requestId); if (requestFuture != null) { //日志进行打印 log.info(\u0026#34;{} Producer {} has been queued up at broker. request: {}\u0026#34;, ctx.channel(), success.getProducerName(), requestId); //标记为成功 requestFuture.markAsResponded(); } return; } //客户端处理的主要逻辑就是从队列中移除此消息 CompletableFuture\u0026lt;ProducerResponse\u0026gt; requestFuture = (CompletableFuture\u0026lt;ProducerResponse\u0026gt;) pendingRequests.remove(requestId); .... } 总结 生产者写数据的流程到这里基本就结束了，怎么样，是不是没想象中那么可怕？也许你对1、客户端对象创建 2、生产者对象创建 3、消息发送 这三步之间的关系还有点迷迷糊糊，那就请允许我给你举个例子，1、客户端对象创建相当于一座新城市的创建，打好城市的地基，2、生产者对象创建 相当于在这个地基的基础上建起了城市，发电厂等等，最重要的是修建其通往其他各个城市的交通要道，最后的3、消息发送 相当于这个新城市的居民们乘坐高铁去其他的城市。这么说相信你一定已经明白了～如果还有其他疑问欢迎在下面的评论区一起讨论\n","date":"2024-03-21T10:34:57+08:00","image":"https://sherlock-lin.github.io/p/%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82producer%E7%AB%AF%E6%B5%81%E7%A8%8B%E4%BB%A5%E5%8F%8A%E5%8E%9F%E7%90%86/image-20240321153410330_hu2501804792718174333.png","permalink":"https://sherlock-lin.github.io/p/%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82producer%E7%AB%AF%E6%B5%81%E7%A8%8B%E4%BB%A5%E5%8F%8A%E5%8E%9F%E7%90%86/","title":"一文彻底搞懂Producer端流程以及原理"},{"content":"机会其实不多 最近一口气看了《飞驰人生》以及《飞驰人生2》，过去是以看喜剧的心态去看沈腾的电影，当如今二刷时发现这不就是生活吗，只不过用喜剧的外壳做了层包装。两部电影给我影响最深的就是最后的那段对白，“张弛，要不咱们放弃吧，只要以后努力还有机会”，张弛回答：“我努力过无数次，可是机会只出现在其中一两次”。相信这段对白也触动了很多人，特别是步入社会后的朋友们相信会更加有自己的共鸣。社会不像学校哪会，只要你努力就会在下次考试中看到效果；而工作后，有时候你发现自己即便做出十倍、百倍的努力，而工作还是一团遭，如此多次可能也想摆烂算了，在社会的这套复杂的评定体系里，有时候仿佛你的努力是失效的，所以这个时候再看到张弛为了比赛胜利甚至不惜冒着生命危险，仿佛能够理解了，因为有些东西真的不想算了，有些东西真的比生命更加可贵，有些东西它错过了真的就错过了，甚至这辈子都不会再有了。这就是我对《飞驰人生》系列的观后感。那么，你是否也有那么一个时刻，让你愿意选择抛弃全部，来选择穿越回到那时拼尽全力的去做的事情吗？\n只要准备好，机会就会出现 如果你也曾因为过去的某个重要时刻没有把握住机会而浑浑噩噩，想摆烂过完余生，那么我想跟你分享一句话，“只要准备好，机会就会出现”。如今随着互联网的发展，每个人都多了很多曝光自己的机会以及认识更多志同道合的朋友，所以只要你足够优秀就会逐渐被推到台前，是金子就一定会发光，前提是你还足不足够优秀。因此咱们需要做的就是不断打磨自己的专业技能、软技能等等，而在机会出现时务必要紧紧抓住并拼尽全力，把握住机会后再继续静下心来沉淀自己如此反复，从而将自己内核修炼得越来强悍。因此，我们应该学会享受沉淀、修炼的过程，就像是在玩一款很长很长的养成系游戏一般，以“十年磨一剑”的匠心精神慢慢积累，而在机会出现时果断的举起“剑”挥向它，同时高喊一句，“去你X的”。\n总结 我们在每一刻都会面临无数个选择，我们在过去无数个选择中的选定绘制出了如今的生活，而站在未来十年、二十年的角度，选择的自己也是一个起点，从现在开始的每一个决定都会不断的改善未来的自己。简单来说就是“种一棵树最好的时间是十年前，其次是现在”，因此从现在这一刻开始，让咱们为了自己感兴趣的事情，疯狂一次吧\n","date":"2024-03-16T15:09:17+08:00","image":"https://sherlock-lin.github.io/p/%E6%80%BB%E8%A6%81%E6%9C%89%E4%B8%80%E6%AC%A1%E4%B8%BA%E8%87%AA%E5%B7%B1%E7%96%AF%E7%8B%82/image-20240316113459701_hu11518649223452192192.png","permalink":"https://sherlock-lin.github.io/p/%E6%80%BB%E8%A6%81%E6%9C%89%E4%B8%80%E6%AC%A1%E4%B8%BA%E8%87%AA%E5%B7%B1%E7%96%AF%E7%8B%82/","title":"总要有一次，为自己疯狂"},{"content":"一、引言 系统学习Pulsar的大纲\n二、正文 下图是我绘制的Pulsar大纲 (由于时间缘故花的比较粗糙，这张图会不定期更新)\n三、学习大纲 一、Pulsar Client 二、生产者 Pulsar消息路由深入剖析 三、消费者 四、Topic pulsar原来是这样操作topic的 五、Function Pulsar3.2 Function的介绍与使用 Pulsar IO实战 Worker调度管理器原理解析 六、Schema Registry Pulsar Schema使用原理介绍 七、存储管理 详解bookkeeper AutoRecovery机制 八、综合 九、高可用 四、学习资料 官方文档\nPulsar三本书籍\n《Mastering Apache Pulsar》：个人认为是Pulsar系统资料最好的，喜欢Pulsar的伙伴务必阅读此经典\n《深入解析Apace Pulsar》：林琳大佬的作品，兼备使用、调优以及原理的介绍\n《Apache Pulsar in Action》：目录布局不太好，但针对个别知识点讲得比较精细，可作为补充读物\nPulsar官方整理资料大全：收录了大量Pulsar使用、原理、业务场景等精彩的文章资料\n五、想对本系列文章读者说的话 坦白了说，现如今的网络环境不像过去那么友好(这个观点不做任何讨论，如果你觉得不对，那么你是对的)，如今还能坚持在网络上输出高质量的作者都是值得尊敬的。我之所以写这系列文章的目的有以下三点：1. 接触技术这些年，受到不少大佬文章的熏陶，技术和思维都有了不少的提升，因此也想做些回馈于技术社区的事情 2. 我知道一定有不少对技术充满热情的小白，我希望能够以Pulsar为切入点给你带来技术的乐趣 3. 通过输出文章来倒推自己持续阅读、提升自己提炼抽象能力。\n我能保证的是以下几点\n这个系列的文章永不收费(降低大家阅读成本) 输出的内容都是经过思考的，拒绝复制张贴以及低价值的东西 尽可能以图、精简的话来协助大家伙对某个知识点的理解 不做模凌两可的解释，宁可偏激的给个错误的答案，我相信有一定依据支撑的错误答案价值大于模糊不清的概念 除此之外，由于本人的知识量以及认知有限，如果有某个知识表述不清楚或者表达有误的地方，恳请指出，大家一起学习共同进步～\n","date":"2024-03-16T10:34:56+08:00","image":"https://sherlock-lin.github.io/p/pulsar%E4%BB%8E%E5%85%A5%E8%BF%B7%E5%88%B0%E5%85%A5%E9%AD%94%E4%B9%8B%E8%B7%AF/image-20240316103554735_hu8487334652089443369.png","permalink":"https://sherlock-lin.github.io/p/pulsar%E4%BB%8E%E5%85%A5%E8%BF%B7%E5%88%B0%E5%85%A5%E9%AD%94%E4%B9%8B%E8%B7%AF/","title":"Pulsar从入迷到入魔之路"},{"content":"一、概述 大数据背景下，分区应该是所有组件必备的基本条件，否则面对海量数据时无论是计算还是存储都容易遇到瓶颈。跟其他消息系统一样，Pulsar通过Topic将消息数据进行业务层面划分管理，同时也支持Topic分区，通过将多个分区分布在多台Broker/机器上从而带来性能上的巨大提升以及无限的横向拓展能力。而一旦有了分区之后就会面临一个问题，但一条数据请求时应该将其发往哪个分区？目前Pulsar跟其他消息系统一样支持以下三种路由模式。\n轮询路由 生产者会按将消息按批为单位轮询发送到不同的分区，这是一种常见的路由策略，具有简单的优势，由于它不需要过多的配置以及考虑但却可以表现不错的性能。如果消息带有key的话会根据key进行哈希运算后再对分区进行取模来决定消息投放的目标分区。 单分区路由 单分区路由提供一种更简单的机制，它会将所有消息路由到同一个分区。这种模式类似非分区Topic，如果消息提供key的话将恢复到轮询哈希路由方式 自定义分区路由 自定义分区路由支持你通过实现MessageRouter接口来自定义路由逻辑，例如将特定key的消息发到指定的分区等 二、实战 消息路由发生在生产者端，在创建生产者是通过 .messageRoutingMode() 进行指定，下面就分别实战对比下这三种的路由效果\n1. 轮询路由 先试试轮询路由的策略，这是最常见也是默认的路由策略，通过 .messageRoutingMode(MessageRoutingMode.RoundRobinPartition) 进行指定，然后往里面通过同步方式往分区Topic里面写入数据\n1 2 3 4 5 6 7 8 9 10 11 12 String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); Producer\u0026lt;String\u0026gt; producer = pulsarClient.newProducer(Schema.STRING) .topic(\u0026#34;sherlock-api-tenant-1/sherlock-namespace-1/partition_partition_topic_2\u0026#34;) .messageRoutingMode(MessageRoutingMode.RoundRobinPartition) //.messageRoutingMode(MessageRoutingMode.SinglePartition) .create(); for (int i = 0; i \u0026lt; 20000; i++) { producer.send(\u0026#34;hello java API pulsar:\u0026#34;+i+\u0026#34;, 当前时间为：\u0026#34;+new Date()); } 通过管理页面可以看到数据基本均匀的落在各个分区，从这个结果是能够反向验证数据是符合轮询发送后的效果\n2. 单分区路由 现在试试单分区路由的策略，通过 .messageRoutingMode(MessageRoutingMode.SinglePartition) 进行指定，并往分区Topic里面写入一批数据\n1 2 3 4 5 6 7 8 9 10 11 String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); Producer\u0026lt;String\u0026gt; producer = pulsarClient.newProducer(Schema.STRING) .topic(\u0026#34;sherlock-api-tenant-1/sherlock-namespace-1/partition_partition_topic_2\u0026#34;) .messageRoutingMode(MessageRoutingMode.SinglePartition) .create(); for (int i = 0; i \u0026lt; 20000; i++) { producer.send(\u0026#34;hello java API pulsar:\u0026#34;+i+\u0026#34;, 当前时间为：\u0026#34;+new Date()); } 通过管理页面可以看到数据都落在第一个分区，说明这也符合官网中对单分区路由的描述。同时经过反复试验多次发现，生产者会随机选择一个分区并将所有数据发送到这个分区。\n3. 自定义路由 在有些业务场景，我们需要将自己的业务逻辑“融入”路由策略，因此像Pulsar、Kafka等消息中间件都是支持用户进行路由规则的自定义的。这里为了好玩，咱们尝试将数据按照 1:2:3:4 等比例分别落在四个分区如何？说干就干，自定义路由也是比较简单的，只需要实现Pulsar MessageRouter接口的choosePartition方法即可，实现逻辑如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class SherlockRouter implements MessageRouter { Long count = 0L; public int choosePartition(Message\u0026lt;?\u0026gt; msg, TopicMetadata metadata) { count++; count = count % 10; if (count == 0) return 0; if (count \u0026lt; 3) return 1; if (count \u0026lt; 6) return 2; return 3; } } 通过上面代码可以看到，参数msg就是生产者中国呢发送的消息对象，metadata是这条消息的元数据如租户、命名空间等等，而返回值其实就是这个Topic分区的下标，这里需要注意的是不要超过Topic的分区数，同时一些比较复杂的数据处理逻辑代码尽量不要写在这里影响消息发送性能以及不规范。\n写完后通过 .messageRouter() 方法进行指定即可使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public static void customRoundSchemaProducer() throws Exception { String serverUrl = \u0026#34;http://localhost:8080\u0026#34;; PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(serverUrl).build(); Producer\u0026lt;String\u0026gt; producer = pulsarClient.newProducer(Schema.STRING) .topic(\u0026#34;sherlock-api-tenant-1/sherlock-namespace-1/partition_partition_topic_3\u0026#34;) .messageRouter(new SherlockRouter()) .create(); for (int i = 0; i \u0026lt; 20000; i++) { producer.send(\u0026#34;hello java API pulsar:\u0026#34;+i+\u0026#34;, 当前时间为：\u0026#34;+new Date()); } producer.close(); pulsarClient.close(); } 在管理页面可以看到，数据是按照咱们预期的逻辑 1:2:3:4等比落在分区里面，嘿嘿～\n三、源码分析 1. 接口以及父类 Pulsar中所有路由规则都是基于MessageRouter接口进行实现的，这个接口主要提供了choosePartition方法，只要重写这个方法即可自定义任意自己预期的逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @InterfaceAudience.Public @InterfaceStability.Stable public interface MessageRouter extends Serializable { /** * * @param msg * Message object * @return The index of the partition to use for the message * @deprecated since 1.22.0. Please use {@link #choosePartition(Message, TopicMetadata)} instead. */ @Deprecated default int choosePartition(Message\u0026lt;?\u0026gt; msg) { throw new UnsupportedOperationException(\u0026#34;Use #choosePartition(Message, TopicMetadata) instead\u0026#34;); } /** * Choose a partition based on msg and the topic metadata. * * @param msg message to route * @param metadata topic metadata * @return the partition to route the message. * @since 1.22.0 */ default int choosePartition(Message\u0026lt;?\u0026gt; msg, TopicMetadata metadata) { return choosePartition(msg); } } MessageRouterBase是路由策略的抽象类，主要定义了消息有key时的哈希算法，像上面提的轮询路由和单分区路由继承了这个抽象类。JavaStringHash和Murmur3Hash32两个都是Pulsar提供的哈希算法的实现类，两者的差异后面再单独进行分析\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public abstract class MessageRouterBase implements MessageRouter { private static final long serialVersionUID = 1L; protected final Hash hash; MessageRouterBase(HashingScheme hashingScheme) { switch (hashingScheme) { case JavaStringHash: this.hash = JavaStringHash.getInstance(); break; case Murmur3_32Hash: default: this.hash = Murmur3Hash32.getInstance(); } } } 2. 轮询路由的实现 主要看choosePartition 方法的逻辑，首先如果消息带有key则针对key进行哈希然后取模，这样可以保证相同key的消息落在同一个分区。然后就是判断消息是否按批次进行发送的，如果是单条消息发送的话则通过一个累加计数器进行轮询分区，即可达到消息按照分区顺序逐个发送的效果；如果是按批次发送的话，则是根据时间戳进行取模，这样达到的效果就是每批数据都会随机发送到某一个分区\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class RoundRobinPartitionMessageRouterImpl extends MessageRouterBase { @SuppressWarnings(\u0026#34;unused\u0026#34;) private volatile int partitionIndex = 0; private final int startPtnIdx; private final boolean isBatchingEnabled; private final long partitionSwitchMs; .... @Override public int choosePartition(Message\u0026lt;?\u0026gt; msg, TopicMetadata topicMetadata) { // If the message has a key, it supersedes the round robin routing policy if (msg.hasKey()) { return signSafeMod(hash.makeHash(msg.getKey()), topicMetadata.numPartitions()); } if (isBatchingEnabled) { // if batching is enabled, choose partition on `partitionSwitchMs` boundary. long currentMs = clock.millis(); return signSafeMod(currentMs / partitionSwitchMs + startPtnIdx, topicMetadata.numPartitions()); } else { return signSafeMod(PARTITION_INDEX_UPDATER.getAndIncrement(this), topicMetadata.numPartitions()); } } } 3. 单分区路由 可以看到单分区的逻辑是比较简单且清晰的，如果有key就进行哈希取模，否则就发送到partitionIndex这个成员变量指定的分区去，那么这个partitionIndex指定的是哪个分区呢？通过代码能看到是从构造函数里面传进来的，因此跟踪下代码看看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class SinglePartitionMessageRouterImpl extends MessageRouterBase { private final int partitionIndex; public SinglePartitionMessageRouterImpl(int partitionIndex, HashingScheme hashingScheme) { super(hashingScheme); this.partitionIndex = partitionIndex; } @Override public int choosePartition(Message\u0026lt;?\u0026gt; msg, TopicMetadata metadata) { // If the message has a key, it supersedes the single partition routing policy if (msg.hasKey()) { return signSafeMod(hash.makeHash(msg.getKey()), metadata.numPartitions()); } return partitionIndex; } } 通过跟踪可以看到是在PartitionedProducerImpl类的getMessageRouter方法中进行SinglePartitionMessageRouterImpl类的初始化，同时是通过ThreadLocalRandom.current().nextInt(topicMetadata.numPartitions()) 来生成一个小于分区数的随机数，因此单分区路由的分区是随机指定的一个，这个结果跟咱们实战中测试的效果是吻合的。除此之外，咱们还看到 getMessageRouter方法中会根据咱们在创建生产者时 .messageRoutingMode 方法指定的路由模式来创建对应的路由实现类，在这里可以明确的看到没有指定的话默认就是采用的轮询路由规则\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 private MessageRouter getMessageRouter() { MessageRouter messageRouter; MessageRoutingMode messageRouteMode = conf.getMessageRoutingMode(); switch (messageRouteMode) { case CustomPartition: messageRouter = Objects.requireNonNull(conf.getCustomMessageRouter()); break; case SinglePartition: messageRouter = new SinglePartitionMessageRouterImpl( ThreadLocalRandom.current().nextInt(topicMetadata.numPartitions()), conf.getHashingScheme()); break; case RoundRobinPartition: default: messageRouter = new RoundRobinPartitionMessageRouterImpl( conf.getHashingScheme(), ThreadLocalRandom.current().nextInt(topicMetadata.numPartitions()), conf.isBatchingEnabled(), TimeUnit.MICROSECONDS.toMillis(conf.batchingPartitionSwitchFrequencyIntervalMicros())); } return messageRouter; } 四、总结 通过以上内容相信你对Pulsar的路由规则有一定的了解了，如果想进一步了解可以尝试按照自己喜好实现下路由规则并观测是否按照预期运行，同时也可以跟踪Pulsar的源码看看实现是否符合预期。如果想彻底掌握Pulsar，最好自己跟踪下Pulsar的一些核心逻辑，这样不仅了解其底层是如何运作的，也能加深你对一些设计/特性的印象。\n","date":"2024-03-13T10:34:56+08:00","image":"https://sherlock-lin.github.io/p/pulsar%E6%B6%88%E6%81%AF%E8%B7%AF%E7%94%B1%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90/image-20240306152645225_hu5442259153227018439.png","permalink":"https://sherlock-lin.github.io/p/pulsar%E6%B6%88%E6%81%AF%E8%B7%AF%E7%94%B1%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90/","title":"Pulsar消息路由深入剖析"},{"content":"一、引言 今天跟着 官方文档 基于docker玩一把Pulsar IO吧\n二、概要 在用户能够轻松的将消息队列跟其他系统(数据库、其他消息系统)一起使用时，消息队列的作用才是最强大的。而Pulsar IO connectors可以让你很轻松的创建、部署以及管理这些跟外部系统的连接，例如mysql、kafka、cassandra等。\nPulsar connector分为Source和Sink两种，Source connector会将数据从外部系统喂给Pulsar，而Sink connector负责将数据从Pulsar喂给外部系统。\nPulsar connector是一种特殊的Function，只不过这个Function持有其他系统的客户端作为pulsar与其他系统的桥梁，它在处理保证上跟Function是一致的，分别是最多一次、至少一次、精准一次。处理保证不仅依靠Pulsar，还跟外部系统相关以及实现逻辑相关。\n最多一次：发给connector的消息最多处理一次或者不做处理 至少一次：发给connector的消息处理一次或者多次 精准一次：发给connector的消息只处理一次 三、实战 1.安装connector 在 这里 下载对应的connector，先选择对应的版本，在点进 connectors 目录选择对应的source或者sink\n将下载的nar文件放到pulsar安装地址的connectors 目录下(没有需要创建)\n启动Pulsar\n通过指令查看服务connector信息，先输出下面这样的信息就说明connector已经注册到Pulsar上面了\n1 curl -s http://localhost:8080/admin/v2/functions/connectors 2. 安装Cassandra 基于 brew install --cask --appdir=/Applications docker 安装docker(仅针对mac环境)\n基于docker运行 cassandra，成功运行后通过 docker ps可以看到Cassandra服务已经起来了\n1 docker run -d --rm --name=cassandra -p 9042:9042 cassandra:3.11 通过 docker exec -ti cassandra cqlsh localhost 进入Cassandra服务的容器，并通过以下指令进行库表的初始化\n1 2 3 4 5 CREATE KEYSPACE pulsar_test_keyspace WITH replication = {\u0026#39;class\u0026#39;:\u0026#39;SimpleStrategy\u0026#39;, \u0026#39;replication_factor\u0026#39;:1}; USE pulsar_test_keyspace; CREATE TABLE pulsar_test_table (key text PRIMARY KEY, col text); 先查询该表确保没有数据 select * from pulsar_test_table;\n3. 功能验证 写配置文件cassandra-sink.yml\n1 2 3 4 5 6 configs: roots: \u0026#34;localhost:9042\u0026#34; keyspace: \u0026#34;pulsar_test_keyspace\u0026#34; columnFamily: \u0026#34;pulsar_test_table\u0026#34; keyname: \u0026#34;key\u0026#34; columnName: \u0026#34;col\u0026#34; 启动写Cassandra的sink，启动后通过指令查看显示sink已经正常启动\n1 2 3 4 5 6 7 pulsar-admin sinks create \\ --tenant public \\ --namespace default \\ --name cassandra-test-sink \\ --sink-type cassandra \\ --sink-config-file examples/cassandra-sink.yml \\ --inputs test_cassandra 执行命令批量往pulsar中写入数据，看是否会正常输出到Cassandra中\n1 for i in {0..9}; do pulsar-client produce -m \u0026#34;key-$i\u0026#34; -n 1 test_cassandra; done 由于上面的操作是有延迟的，所以不断的查询Cassandra的表是可以看到数据在逐步的增加，并最终写满十条数据\n四、总结 纸上得来终觉浅，绝知此事要躬行。 学习不能仅仅停留在纸面上或者理论，脱离使用去探讨设计或者源码都是不切实际的。因此今天一起体验了一把Pulsar IO，除此之外Pulsar还提供了非常丰富的跟其他系统交互的Connector，详细可以看上面发的下载地址并尝试使用自己感兴趣的Connector感受下实操的快乐～\n","date":"2024-03-13T10:34:55+08:00","image":"https://sherlock-lin.github.io/p/pulsario%E5%AE%9E%E6%88%98/image-20240313191618099_hu9489298534787853151.png","permalink":"https://sherlock-lin.github.io/p/pulsario%E5%AE%9E%E6%88%98/","title":"PulsarIO实战"},{"content":"引言 为何要模块化，这里的主体是人，客体是事物。当事物很小时，人可以很轻松的解决；但是当事物远大于人能处理的范围时，我们就可以考虑对它进行模块化分解。模块化是一种解决复杂问题的方式，放之四海而皆可用，以下就举几个例子聊聊模块化\n分封制 商朝之前，统治者一个人管理硕大的疆域，整个疆域大大小小事都要自己操心亲力亲为，像商朝不就是最后被偷家了，手动狗头。因此周朝的统治者采用分封制进行管理，庞大的帝国不好打理那就划分成多块领域也就是将大的东西分解成不那么大的东西分别进行管理，而随后春秋战国直到秦朝后，开始实行郡县制，本质上就是将模块分解更加精细化，这样打理整个庞大的帝国就方便很多，并且非常大幅提高了整体的效率，这不在短短几十年修长城、统一度量衡、文字等等。这些事情要是放在秦朝前那几乎是难以想象的，但因为模块化了，相当于每个县都是一个独立的单元具备自我管理的功能，而统治者到县之间的这些层级本质上都是在做政令的传达以及结果反馈。这种设计如下图，模块化的符号化其实就是一颗多叉树，原本要一个人管理的国家分成了6个县，原本一个人要打理的事情分成了6个人处理并且这是可以无限扩展的。每一层各司其职，从而整体达到最大的效率。\n大数据 大数据时代迎来的数据的爆炸式增长，庞大的数据在存储和计算上都成了很大的难题，因此大佬们通过设计最终采用了目前下面这种方案，将数据进行拆解，各个小数据集合再落在具体的某台Linux机器上进行存储或者计算\n总结 上面就是模块化的好处，原本看似不可能完成的东西通过模块化分解后都是可以完成的。因此在这里想表达的是，虽然学海无涯，但是对于咱们热爱的事情，可以利用好这个方式，将要做的大任务或者要学习的大的方向进行分解，然后在逐个攻克一个个小单元，因此不用害怕任何事情，大胆折腾起来\n","date":"2024-03-05T15:09:15+08:00","image":"https://sherlock-lin.github.io/p/%E4%B8%87%E7%89%A9%E7%9A%86%E5%8F%AF%E6%A8%A1%E5%9D%97%E5%8C%96%E5%88%86%E8%A7%A3/image-20240920152044106_hu17856311937218138140.png","permalink":"https://sherlock-lin.github.io/p/%E4%B8%87%E7%89%A9%E7%9A%86%E5%8F%AF%E6%A8%A1%E5%9D%97%E5%8C%96%E5%88%86%E8%A7%A3/","title":"万物皆可模块化分解"},{"content":"引言 Pulsar Function中最重要的角色是Worker，而Worker中最核心的类就是调度管理器SchedulerManager，本篇博客就专门对它进行剖析\n一、正文 SchedulerManager职责有以下两点\n任务调度 重平衡 任务调度是SchedulerManager最重要的逻辑，咱们通过 pulsar-admin functions create xxx 启动一个function实例时，Pulsar 如何决定在哪台worker所在节点启动这个function实例，这就是任务调度要做的事情，除此之外任务调度还包含function更新、删除以及任务的生命周期管理。而重平衡是稳定性相关的，当咱们的function实例分布不均衡时，可能会导致涝的涝死，旱的旱死，因此需要咱们做function实例的重新分配，这也是SchedulerManager要做的事情\n二、任务调度 在开始讲解任务调度之前，咱们先看看下面这张图\n图中的上下方分别是两个worker进程实例，在咱们通过 bin/pulsar functions-worker 启动worker进程时服务内部会启动consumer并以failover方式来在Broker进行消息订阅消费，failover机制保证同一时间内只有一个Consumer能进行订阅，因此Worker通过这个机制来进行选主，成功订阅的worker晋升为leader负责任务的派发，未成功订阅的worker变为follwer并通过Reader监听Broker中的任务。其中Leader和Follwer的主要逻辑分别如下\nworker-leader 通过Consumer-failver机制成为leader后，会立马启动一个Producer负责往Broker中发送任务消息，每当有新建启动function请求进来，就会往Broker中写入一条对应的任务消息。除此之外Leader还会通过Consumer消费Broker中保存的元数据，并以Map数据结构存在内存中作为Leader的元数据管理的数据来源，这里的数据有Function信息、Instance信息等，在接受到我不请求是也会同步更新这里，同时也会定期的根据元数据检查来排查出异常的Function、Instance等。\nworker-follwer 在worker成为follower后，会启动Reader监听Broker中的任务，当监听到有新任务时会调用任务管理器进行处理，例如在有新增启动Function时，如果是配置的线程级别则以线程方式启动Instance，如果是配置的进程级别则会拉起一个独立的Instance进程进行Function任务的执行。\n源码解析 调度逻辑的主要入口在SchedulerManager的invokeScheduler方法\n获取所有Function 以及Instance 删除所有不存在的Function/Instance的分配器，同时更新分配器的信息 如果元数据管理器中存有Function，但是这个Function对应的InstanceID不存在于Runtime管理器的Runtime列表 则从Master元数据中删除，并通过内部Topic发送一条清除这个Instance给Worker 通过元数据比较获取需要新增的Instance并包装成Assignment，通过内部Topic发送这条新增Instance给Worker 获取还未启动的Instance实例，并通过RoundRobinScheduler的schedule方法派发到对应的Worker节点进行启动 循环通过FunctionRuntimeManager.processAssignment启动Instance 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 void invokeScheduler() { long startTime = System.nanoTime(); //获取当前worker集群中可用的worker节点信息 Set\u0026lt;String\u0026gt; availableWorkers = getCurrentAvailableWorkers(); //获取所有Function List\u0026lt;FunctionMetaData\u0026gt; allFunctions = functionMetaDataManager.getAllFunctionMetaData(); //获取所有Instance Map\u0026lt;String, Function.Instance\u0026gt; allInstances = computeAllInstances(allFunctions, functionRuntimeManager.getRuntimeFactory().externallyManaged()); //获取当前每个 workerId-\u0026gt;(InstanceId—\u0026gt;任务) Map\u0026lt;String, Map\u0026lt;String, Assignment\u0026gt;\u0026gt; workerIdToAssignments = functionRuntimeManager .getCurrentAssignments(); // 初始化调度状态记录器 SchedulerStats schedulerStats = new SchedulerStats(workerIdToAssignments, availableWorkers); //delete assignments of functions and instances that don\u0026#39;t exist anymore Iterator\u0026lt;Map.Entry\u0026lt;String, Map\u0026lt;String, Assignment\u0026gt;\u0026gt;\u0026gt; it = workerIdToAssignments.entrySet().iterator(); while (it.hasNext()) { Map.Entry\u0026lt;String, Map\u0026lt;String, Assignment\u0026gt;\u0026gt; workerIdToAssignmentEntry = it.next(); Map\u0026lt;String, Assignment\u0026gt; functionMap = workerIdToAssignmentEntry.getValue(); // remove instances that don\u0026#39;t exist anymore functionMap.entrySet().removeIf(entry -\u0026gt; { String fullyQualifiedInstanceId = entry.getKey(); boolean deleted = !allInstances.containsKey(fullyQualifiedInstanceId); if (deleted) { Assignment assignment = entry.getValue(); MessageId messageId = publishNewAssignment(assignment.toBuilder().build(), true); // Directly update in memory assignment cache since I am leader log.info(\u0026#34;Deleting assignment: {}\u0026#34;, assignment); functionRuntimeManager.deleteAssignment(fullyQualifiedInstanceId); // update message id associated with current view of assignments map lastMessageProduced = messageId; // 更新状态 schedulerStats.removedAssignment(assignment); } return deleted; }); // update assignment instances in case attributes of a function gets updated for (Map.Entry\u0026lt;String, Assignment\u0026gt; entry : functionMap.entrySet()) { String fullyQualifiedInstanceId = entry.getKey(); Assignment assignment = entry.getValue(); Function.Instance instance = allInstances.get(fullyQualifiedInstanceId); if (!assignment.getInstance().equals(instance)) { functionMap.put(fullyQualifiedInstanceId, assignment.toBuilder().setInstance(instance).build()); Assignment newAssignment = assignment.toBuilder().setInstance(instance).build().toBuilder().build(); MessageId messageId = publishNewAssignment(newAssignment, false); // Directly update in memory assignment cache since I am leader log.info(\u0026#34;Updating assignment: {}\u0026#34;, newAssignment); functionRuntimeManager.processAssignment(newAssignment); // update message id associated with current view of assignments map lastMessageProduced = messageId; //update stats schedulerStats.updatedAssignment(newAssignment); } if (functionMap.isEmpty()) { it.remove(); } } } List\u0026lt;Assignment\u0026gt; currentAssignments = workerIdToAssignments .entrySet() .stream() .filter(workerIdToAssignmentEntry -\u0026gt; { String workerId = workerIdToAssignmentEntry.getKey(); // remove assignments to workers that don\u0026#39;t exist / died for now. // wait for failure detector to unassign them in the future for re-scheduling return availableWorkers.contains(workerId); }) .flatMap(stringMapEntry -\u0026gt; stringMapEntry.getValue().values().stream()) .collect(Collectors.toList()); //获取未分配的Function任务 Pair\u0026lt;List\u0026lt;Function.Instance\u0026gt;, List\u0026lt;Assignment\u0026gt;\u0026gt; unassignedInstances = getUnassignedFunctionInstances(workerIdToAssignments, allInstances); workerStatsManager.scheduleStrategyExecTimeStartStart(); //触发任务真正调度派发的入口 List\u0026lt;Assignment\u0026gt; assignments = scheduler.schedule(unassignedInstances.getLeft(), currentAssignments, availableWorkers); workerStatsManager.scheduleStrategyExecTimeStartEnd(); assignments.addAll(unassignedInstances.getRight()); if (log.isDebugEnabled()) { log.debug(\u0026#34;New assignments computed: {}\u0026#34;, assignments); } isCompactionNeeded.set(!assignments.isEmpty()); //更新到Leader内存中的元数据 for (Assignment assignment : assignments) { MessageId messageId = publishNewAssignment(assignment, false); // Directly update in memory assignment cache since I am leader log.info(\u0026#34;Adding assignment: {}\u0026#34;, assignment); functionRuntimeManager.processAssignment(assignment); // update message id associated with current view of assignments map lastMessageProduced = messageId; // update stats schedulerStats.newAssignment(assignment); } log.info(\u0026#34;Schedule summary - execution time: {} sec | total unassigned: {} | stats: {}\\n{}\u0026#34;, (System.nanoTime() - startTime) / Math.pow(10, 9), unassignedInstances.getLeft().size(), schedulerStats.getSummary(), schedulerStats); } 三、总结 以上就是Pulsar中Worker的调度过程，这里主要是以Worker独立部署的方式进行讲解的，基于Broker启动的Worker感兴趣的朋友可以自行跟踪下代码。\n","date":"2024-03-05T10:34:57+08:00","image":"https://sherlock-lin.github.io/p/worker%E8%B0%83%E5%BA%A6%E7%AE%A1%E7%90%86%E5%99%A8%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/image-20240305140605827-9618768_hu15216224640484705908.png","permalink":"https://sherlock-lin.github.io/p/worker%E8%B0%83%E5%BA%A6%E7%AE%A1%E7%90%86%E5%99%A8%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/","title":"Worker调度管理器原理解析"},{"content":"引言 《皮囊》里告诉我们，每个人都是由一副皮囊和一个灵魂组成，皮囊就像一辆汽车，灵魂就像这辆汽车的驾驶员，从母亲的羊水中离开那一刻就启动汽车，而终点就是我们离开这个世界的那一刻。但这个生命周期是这副皮囊的，那么灵魂呢？围绕这个问题几千年来的智者们已经给出很多结论，以及根据一些理论创办对应自洽的的宗教信仰，这篇文章并不是要讨论是否有来世的问题(以我目前的知识量也没法想到什么有用的结论)，但这篇文章想表达的是，在汽车行驶的这段路程，咱们作为驾驶员有哪些值得我们思考的。\n皮囊-灵魂依赖反转 人开车，理想情况下应该是开往人想去的地方，而不是任由车“自动驾驶”，或者是参考车是什么颜色，开了多少里程数了来决定自己想去的地方。那么，为什么要用年龄、环境等东西来捆绑住自己的“皮囊”呢，例如以下问题\n我今年已经三十一了，喜欢编程想学编程是不是有些晚了 要是三年前就XXX就好了 我热爱并且想做A，但是我的工作内容却一直是B，好苦恼 \u0026hellip;. 更多的例子就不一一例举了，本质上都是用皮囊束缚住了灵魂，如果你想透彻了你会发现这件事情没那么复杂，喜欢去做就完了，就这 么简单，如下图所示，灵魂不该给皮囊服务或让步，应该折腾好皮囊，利用它服务好我们的灵魂\n使命感 \u0026ldquo;人活着是为了什么？\u0026quot;，对于这个问题，我听过无数个答案，听过一个比较认同的就是，“每个人来到这个世界上都有自己的一个使命，每个灵魂要做的就是发现这个使命，并为它奉上自己的一切”。这就是我在这里想提的使命感，如今的生活是个物质充裕但精神匮乏的世界，虽然不少朋友已经解决温饱过上所谓的“小资”生活，但成天闷闷不乐，甚至有个别患上精神疾病如抑郁症。针对精神问题我也曾经饱受困扰，现如今逐渐醒悟过来也希望能够帮到你，我的方式就是找到自己热爱的东西也就是自己的使命，然后彻底贯彻它，但你将全部的精力集中在这个点时，分散在其他不快乐的精力就会少很多很多，同时由于你在做一件你热爱的事情时，你不会容易觉得累甚至会觉得有无穷的精力。\n我的使命 在大学接触编程时，也曾幻想用代码改变世界，同时也在钻研沉淀自己的专业技能。但是在工作后发现公司是个盈利的机构，有时候它所追求的东西会限制住你的发挥，甚至会有很多你不喜欢的东西充斥着你的生活，开不完的会、干不完的活以及很多消耗你精气神的事情，经过这些东西消磨后你发现自己对技术的热情不再，但是当你真的一段时间不接触技术后你陷入了更大的痛苦，仿佛丢了罗盘的航海船一般浑浑噩噩。\n最终经过分析发现，其实是违背了自己的使命以及给自己的不努力找借口，当你真的热爱一个东西的时候，即便是神明都无法阻挡你去追求它。如今在技术层面我不会再去思考这个东西会不会给自己带来收益，只要感兴趣的那就学以及深挖；在形式上，我不在局限于给开源社区贡献代码，像输出技术文章，输出心得体会也是一种创造价值的方式，只要能够多影响到一个就够了，这是我的初衷，至于结果会是什么交给未来吧，只要坚持做自己热爱的事情就够了。说了这么多，我的使命是什么呢，简单的说就是创造，写软件改变世界也是创造，输出文章影响读者也是一种创造，这就是我热爱的事情并不断在这个过程中提升自己的思维，用皮囊服务于灵魂。\n总结 最后与各位读者分享一句话：人有两次生命的诞生，一次是你肉体出生，一次是你灵魂觉醒。\n","date":"2024-02-28T15:09:16+08:00","image":"https://sherlock-lin.github.io/p/%E4%B8%80%E5%89%AF%E7%9A%AE%E5%9B%8A%E7%9A%84%E4%BD%BF%E5%91%BD/image-20240228143652107_hu11282021279702529150.png","permalink":"https://sherlock-lin.github.io/p/%E4%B8%80%E5%89%AF%E7%9A%AE%E5%9B%8A%E7%9A%84%E4%BD%BF%E5%91%BD/","title":"一副皮囊的使命"},{"content":"引言 随着生活水平的提高，不少人的目标从原先的解决温饱转变为追求内心充实，但由于现在的时间过得越来越快以及其他外部因素，我们 对很多东西的获取越来越没耐心，例如书店经常会看到《7天精通Java》、《3天掌握XXX》等等之类的书籍，然后大致翻阅后以及经过短暂的实操后，多巴胺充斥着身体，在获得享受后又贪婪的将目光转向下一个目标～我们总在忙，总在不断的学，但是最后大概率会被社会的棒子打回原型，我们其实什么都不会。在获得这样的答案后，我们会变的更贪婪，觉得是自己不够努力，于是更加的拼命学，周而复始直到精疲力竭，最后悲愤高呼“世道如此，悲夫XXX”，因此在这篇文章想表达的是，“欲速则不达，慢就是快”\n技术迷张三的悲哀 张三是个对技术充满热情的程序员，在大学时期先接触的Java编程语言，于是照着《7天精通Java》敲完上面的例子后，感觉已经掌握了Java。于是看着安卓风吐火如荼时，也跟着下载个AndroidStudio开发一些小的APP，开发出一些小case后感觉安卓也差不多掌握了，但是如果再继续精进的话就要付出更多的精力，于是在全栈流行的时候，又跟着学习前端Web知识，自己搭建一个完整的Web服务等等。在毕业时，当他信心满满的去面试时，被面试官狠狠的按在地上摩擦～于是他只能选择一个不上不下的公司先干着，这个时候大数据风头来了，于是他趁着风头转了大数据行业，由于之前面试的经验告诉它，学技术一定要深挖，于是呼在简单学习一些基础知识后，就立马吭哧吭哧的啃起了大数据组件的源码，味涩难懂没关系，看不懂就看别人讲解甚至尝试去背，他觉得只要把这些热门的组件的代码都“搞懂”那自己就是香饽饽了，最终他工作上还是四处碰壁，他不服气，觉得是自己懂得不够多，于是乎啃完Hadoop、啃HBase、Kafka、RocksDB、ClickHouse等等，甚至编程语言还去学Python、Rust、Go等等，他觉得自己已经还可以了，但是最终在社会的毒打中，身心疲惫的转行做其他的了\n悲从何来 张三很忙，也很努力，但是悲哀的是，他在每一个方向都只学了最简单的知识，并错误的认为自己以为掌握了，实则只是冰上一角。 因此虽然他很努力，但是悲剧是必然的。张三只是宇宙中的一粒沙子，他的理想伴随着宇宙规律堙灭无人知晓，但如果我们在他身上看到了自己的影子，那么我们可能需要注意下，避免这种逃避困难的盲目的努力，这本质上也是一种“奶头乐”。用张一鸣的话来说，“他们为了避开思考，愿意付出一切努力”\n解法 静，勿燥 这跟 有点矛盾，一句话说清两者的关系“战略上要静，战术上要快”。指导员在抗战时期提出的“论持久战”就是战略上的静，我们知道目的地在那里，但也要承认这段路是比较漫长的，只靠冲刺是永远到达不了的。因此在长远目标定下来后，心要静下来，然后针对眼前的一个个要做的事情，莽起来，大胆去做，因为即便一两件事搞崩了也远不会影响你的最终目标。\n规划性 在有目标后，要定一个大纲来进行指导，每一个阶段的小方向是什么，再到小方向上要做的事，最后再逐个攻克。在攻克的过程中识别到新的信息后，可以反过来调整计划。\n跟外界保持联系 要承认的一件事，我们很难独立于这个世界，我们需要得到这个世界的认可从而获得收益例如金钱、权力、名誉等等，因此我们不能闭门造车。要跟世界保持联系，例如学某个技术不要自己埋头硬啃，也要关注一下别的公司业务是如何用的，遇到了哪些问题，一定要记住一件事，你学一个东西一定是要用来解决某个“问题的，因此你要了解这个“问题”。如果只是埋头硬啃除了可能会脱离业务，还可能会钻入一些牛角尖的地方徒徒耗费时间等，因此务必要跟外界保持联系\n总结 在最后，跟大家分享一句很喜欢的话，“如果有一天，你不再寻找爱情，只是去爱;你不再渴望成功，只是去做;你不再追求空泛的成长，只是开始修养自己的性情;你的人生一切，才真正开始”\n","date":"2024-02-20T15:09:17+08:00","image":"https://sherlock-lin.github.io/p/%E6%AC%B2%E9%80%9F%E5%88%99%E4%B8%8D%E8%BE%BE%E6%85%A2%E5%B0%B1%E6%98%AF%E5%BF%AB/image-20240920152413904_hu15743919184586671853.png","permalink":"https://sherlock-lin.github.io/p/%E6%AC%B2%E9%80%9F%E5%88%99%E4%B8%8D%E8%BE%BE%E6%85%A2%E5%B0%B1%E6%98%AF%E5%BF%AB/","title":"欲速则不达，慢就是快！"},{"content":"引言 随着知识量的增加，有时会减低执行力。小时候很多东西不知道，但是就很莽，大胆的撬开电风扇，哪怕组装回来多了几个零件也很自豪；小时候好奇海的那边有什么，跟着小伙伴们沿着海岸线跑一下午都不觉得累。但是随着对这个世界的了解的增加，我们逐渐变得“理智”，喜欢的人还没开始去追就内心觉得反正也成功不了就放弃了，有些工作还没开始就觉得这个设计方案行不通甚至开发好的代码迟迟不上线，因为不发布就不会有问题等等呢个。为了避免失败，于是乎放弃所有开始，但是今天我想说的是，莽，就完事拉~\n一、知行合一 第一次听到“知行合一”这个词，是从王阳明《传习录》里看到的，但开始理解是从董宇辉的直播上，而在近期真正实战中有了进一步的领悟，因此把它排在第一。我是一个喜欢思考的人，在内心中觉得几乎所有事情都可以在心中的沙盘进行推演然后得出最优解，最后再将最优解进行落地。这在上学时期没问题，但工作后如果你也跟我一样的话，在工作中会很容易吃瘪，因为很多时候但一项工作派给你时，很多信息是不确定的，你无法根据这些信息获得所有的“最优解”，例如要开发一个新功能，你如果先花大量时间去基于技术实现的角度来思考哪个方案更好，那么在实现时大概率会受阻。比如这个方案在真正落地时很有可能遇到以下阻力：① 依赖外部服务，但目前外部还不支持这种功能 ② 你设计的是回调方式同步数据，但等你设计好落地时发现由于安全问题网络知识单向的 ③ 这个方案在实现时复杂度比原来想的要高的多得多。除了上诉的几个场景，相信你可能还遇到其他的，有想过为什么吗？\n上诉最大的问题就是，花了过多的时间在方案设计上，除非一些特别特别核心的点，大部分情况下拿到活了直接开干，代码能跑就行，先实现起来调试，因为“行”就是“知”，或者说只有当你真正的行动起来，你才能获取更多相关的信息，视野才能更加的开阔起来。单纯靠想是永远都想不明白，与其花大量时间纠结走哪一条路，不如先挑一条走起来，也许你走个几分钟就发现这条路走不下去折返去另一条路呢，这不比你花几个小时在哪里纠结强吗？这个时候的“走错路”难道是真的错吗？不见得吧。因此当你真的内心有想法时，大胆去尝试；当觉得某个方案有问题时，大胆的提出来；不要被所谓的“犯错”限制住了自己，哪怕你想法是错误的，你也只有尝试了，提出来了才能获取到这个结论不是吗，“行”就是“知”。所以如果有喜欢的东西，趁着热情还没消散，莽一点，相信你会有不一样的体验~\n二、你遇见的所有人，都是你自己 “你遇见的所有人，都是不同平行世界里的自己。” 这句话送给内向型敏感性格的朋友，不用害怕他们，他们其实都是“你”。这里的意思是，这个世界上所有你看到的人都是由“你”组成的，这是属于你的世界。所以不用在意“自己”的看法，大胆去去做你想做的事情，可能会有人说三道四，但是记住，这是另一个世界的你对当前的这个你的看法。就如同是现在的你批评过去某个阶段的自己一样，没什么差别。为什么这么我要在这里提一下呢，因为内向型敏感性格的人，有自己的优缺点。如果过多去关注外界的看法会大量消耗自己的精气神，但是精气神这玩意是固定的，少了之后就会降低你做其他事情的动力。内向型敏感人格有自己的优点，从产出最大化的角度来看，应该将更多的精力专注于自己感兴趣的事情上，记住，是感兴趣的事情上而不是自己身上。例如应该关注的是自己的表达水平是否提升而不是关注有人说你不近人情，应该关注想学的东西例如英语今天背了多少词汇量而不是关注自己的衣服脏了一点之类的，大致意思相信你能明白\n三、热爱，可克服一切阻碍 除了上诉两点，最后我想说的是，保持你热爱的东西，这是你动力的源泉，如果不能保持，那就尽量去“爱上”你在做的事情。很多东西做一两天容易，但是长期坚持的话，如果不是发自内心的热爱，那就是一件很折磨人的事情。并且特别是在坚持件事的前两年，由于不熟悉你会遇到各种各样的阻碍，这是劝退大部分人的时期，但是如果你坚持下来了，收获一般相对也比较丰富，同时你内心也会变强。这样再去做其他有难度的事情时，你能比别人更皮实。例如李笑来大佬小时候被逼着抄新华词典，等真的抄完后，之后他感觉遇到的所有事仿佛都没那么难熬了。因此保持热爱，去坚持做的想做的事情~\n四、总结 以上就是我想说的，最后，还是用标题来结尾，哥们，莽就完事了，开干吧~\n","date":"2024-02-04T15:09:14+08:00","image":"https://sherlock-lin.github.io/p/%E8%8E%BD%E5%B0%B1%E5%AE%8C%E4%BA%8B%E5%95%A6/the-creative-exchange-d2zvqp3fpro-unsplash_hu5876398126655421130.jpg","permalink":"https://sherlock-lin.github.io/p/%E8%8E%BD%E5%B0%B1%E5%AE%8C%E4%BA%8B%E5%95%A6/","title":"莽，就完事啦"},{"content":"引言 在谈绩效后，我收获了一些心得，在此梳理出来，加深印象并且共勉\n基本信息 在步入职场后，你可能跟我一样虽然技术水平有在上升，但是在处理一些事情上可能偶尔没能获得预期的成果。我在通过绩效沟通以及自我反思后得出以下几点，如果你也有类似的情况可能需要加强些\n沟通方式 工作中完整的沟通链路 何时沟通 风险汇报 心态方面 皮实 客观 师傅领进门 人无远虑，必有近忧 沟通方式 沟通链路\n在国内大部分互联网公司不会需要你有非常强悍的专业技能，但如果想把事情做好那必不可少的就是沟通能力，沟通技能不像编码那样有明确的测量指标，但这并不代表没有沟通模板。下面这是工作中通用的沟通链路模板，分别由主体、客体以及相关方构成，在工作中我们常常扮演其中的一个角色\n主体：事件的发起者，工作中常见的例如：你的直接上级给你派活、某些专项的事情需要你支持、产品/PM等\n客体：主体命令的执行者，工作中常见的例如：你、你派发任务的那个人等\n相关方：所有事件推进过程中需要配合的人员，例如：事件变更会影响到的人员、事件推进中需要配合你们的人员等\n理清这三个角色后，接下来让我们看看正常一个事件的完整流程，事件假设为：你们的大数据集群下个月需要扩容\n你的上级将这个任务派发给你，指定下个月要进行完成 收到信息跟上级确认细节以及相关事项，同时给上级承诺完成 梳理出本次变更中会影响到的下游使用方、运维同学等等，并同步要变更的信息，同时要明确每个相关方都收到通知 在相关方响应后，要跟他们确定需要他们做操作的事件，例如需要运维同学在两周后提前扩好机器备用等并推进 在跟相关方都梳理清楚后跟你的上级进行同步，如果梳理的时间比较长可以每隔一段时间进行同步 你的上级在确认好后，如果本次事件的影响是比较大的话。应该跟相关方或者相关方的上级在check下 相关方对这件事情做二次确认，例如邮件、群消息或者文档跟进 以上基本就是一个事件发生的完整链路，不复杂但是工作中往往会忘记，浓缩成一句心得就是，“事事有着落，件件有着落”\n何时汇报\n大致分为以下三种情况\n某一方信息有变动时\n当你知道的任何一方包括你自己存在信息变动时，可以考虑进行汇报。例如你下个月突然有事要请假，那么你应该第一时间跟你的上级沟通，看看这个事情能够前置或者后置，或者能够换个人来接替这件事情等\n定期汇报\n例如在周会、日例会上进行定期进展同步，如果这件事比较重要可以单独拉个专项，针对这个专项定期进行开会对进展\n存在风险时\n当你识别到可能存在风险时，例如要运维扩机器，但是跟第三方的商务合约还没谈拢导致无法按期分配机器，那么这样的风险就应该第一时间同步给你的上级以及相关方\n风险汇报\n风险汇报务必要做到快、准、客观。快就是第一时间要立马同步，准是要先快速确认下信息的准确性，客观就是风险跟你相关或者由你引起的时候，不要担心担责或者被责备，应该保持客观的心态去汇报这个事情。一定要谨记一件心得，就是鼓足干劲把事件做好才是最重要的，其他的都是其次。\n心态方面 皮实\n简单来说遇到困难、责备、复盘的时候，要耐C。无论生活工作把你摁在地上摩擦成什么样，你站起来继续做你该做的事情。你要明确自己来这里的目的是什么，为钱、为成长、为实现自我价值等，你要牢记这一点，工作只是辅助工具，辅助你实现你的目的。因此即便工作一时做不好或者被责备，不要觉得天塌了，其实真的没有那么严重，你但凡把自己人生的时间线拉长一些你都会发现，过去某个时间段你觉得非常重要的事情在现在看到是不是基本都是风轻云淡了？例如期末考试考砸了、打游戏被父母抓到、失恋、足球比赛失误等等等等，哪一件不是当时觉得非常重要甚至世界崩了，但是回首都轻的像是一片羽毛，像是别人的故事一般，就像苏东坡的那句“回首向来萧瑟处，也无风雨也无晴”。因此牢记自己的初心，你一定可以越来越耐C～\n不皮实可能可能会给你带来的缺点\n由于害怕责备，重要的事情一拖再拖，遇到风险迟迟不敢汇报 由于害怕别人指出自己的缺点，会议上迟迟不敢发表自己的想法 工作复盘几次后，自己觉得世界塌了，工作干脆开始摆烂 情绪变的暴躁，会觉得是全世界的错，看谁都不爽，路边的狗都想上去扇两个耳光～ 除了以上种种还有很多，就像那句话说的一样 “勇敢的人先享受世界～”，你不妨大胆些去试试，换句话说，这个世界其实没有太多人关注你，你为啥不follwer自己的内心，做自己想做的事情呢\n客观\n这个词可能不是很准确的表达，大致意思就是我们在看待很多跟自己相关的事情的时候要尽量客观，例如自己的项目搞砸了，自己可能存在的那部分就是做得不好，没有什么好狡辩的，这里指的狡辩不是对任何人，而是对你自己，你自己心里要清楚自己不足的地方以及积极改进，否则每次事情做不好都怨这怨那的最终自己没有得到任何的提升\n师傅领进门\n这个也可以理解为独立做事能力，很多事情不要过多依赖别人，例如排查到一个跟数据库相关的问题，不要直接丢给dba，要自己检查下SQL写的是否有问题，连接mysql的参数是否有误等等，如果遇到事情就要依赖别人，不仅自己得不到成长，还会退化，最后任何事情都要别人手把手指导，这恐怕也不是你想成为的那个人吧？如果遇到事情自己积极主动处理，会让你不断的扩充自己的知识，提升自己的做事能力，形成一个良性循环\n人无远虑，必有近忧\n我们工作中经常会遇到各种各样的问题，因此我们应该透过现象看本质，知道本质的问题是什么后尽可能的从本质上处理了。例如你负责的A项目的某个模块经常出问题，你排查后发现代码设计一塌糊涂，那么与其不停的话时间不断的修bug，那为啥不直接抽时间梳理清楚逻辑然后重构下呢？头疼医头脚疼医脚永远不会健康，很多时候做事情眼光也要放长远些\n写在最后 本篇写给自己以及所有可能跟我一样，有时候过多专注于编码，忽略了一些软技能导致工作没有达成预期的朋友，同时也感谢一路上给我提供技术指导、做事指导的朋友们\n","date":"2024-01-25T15:09:13+08:00","image":"https://sherlock-lin.github.io/p/%E5%B7%A5%E4%BD%9C%E8%BD%AF%E6%8A%80%E8%83%BD%E7%AC%AC%E4%B8%80%E5%BC%B9%E5%85%B3%E4%BA%8E%E8%81%8C%E5%9C%BA%E6%B2%9F%E9%80%9A%E6%88%90%E9%95%BF%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/image-20240920151741705_hu3661236691741607602.png","permalink":"https://sherlock-lin.github.io/p/%E5%B7%A5%E4%BD%9C%E8%BD%AF%E6%8A%80%E8%83%BD%E7%AC%AC%E4%B8%80%E5%BC%B9%E5%85%B3%E4%BA%8E%E8%81%8C%E5%9C%BA%E6%B2%9F%E9%80%9A%E6%88%90%E9%95%BF%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/","title":"工作软技能第一弹，关于职场沟通、成长的那些事"},{"content":"在各种武侠文化的渲染下，我从小萌生了一种奇怪的想法，就是弄任何事都要偷偷摸摸的钻研，最后惊艳所有人；因此无论是大学还是毕业工作中，很多事情都希望做到“完美”再同步给“外界”，如以下几个例子\n学习SpringMVC，想说等学透了再输出文章博客 做某项任务，想说等拿到自己觉得合格的成果再同步给上级 做技术分享，由于想做得好一些，既要..又要..还要..等等，结果导致分享无限 \u0026hellip; 但是以上种种最终都没有达到很好的效果，如何算学透？你永远都不会彻底准备好的，就像董宇辉说的，给你三年你准备不好高考，就算给你三十年也准备不好的，最好的方式是边学边输出博客，通过输出来反思自己所学的内容；拿到任务要定期汇报给上级，我们所生活的世界是一个错综复杂的体系，也许过了几天这个任务已经变得“不重要”了，你如果早点与上级汇报与沟通就会早点把更多精力投入到更有用的任务上，或者说在得到上级的帮助，你可以更加快速的攻克这个任务，再不济你也要让上级知道这些事情的进展等。以上种种思考的模式是一种单向的方式，个人认为是不太健康的，理想的情况下应该是一个螺旋环状的结构，如下图 通过上图可以看到，从开始到结束那么一长条线都是一条孤独的路，如果只是自己埋头从头到尾去做一件事很有可能是枯燥、痛苦的事，这会导致很多人中途放弃，这也是上面几个例子失败的最主要根因；因此再来看第二种方式，在有目标之后的第一件事是先将其拆分为独立的一个个小任务，每攻克一个小点时，我们都可以适当做下输出，无论是输出技术博客、还是技术分享或者是其他方式，在接受到“鲜花与掌声”后我们会拥有更多的动力对下一个“堡垒”发起进攻，在接受“鲜花与掌声”的同时，我们也能听到更多的反馈，例如可能会评论说你对IOC的某个理解是错误的、领导觉得你的这个方案一可能存在某个缺陷等等，那么在这个基础下，你在开启下一个环是有个更多的“注意事项”，这能让你更有条不紊的朝着最终目标前行。\n除了大目标要进行拆分，我们也要重视外界反馈的“作用”，曾经我觉得别人的看法不重要，等自己把大目标做好了大家对你的看法自然而然的就会变好。这些也没错但是大部分人都是普通人，都是“俗人”，被人表扬会开心，收到点赞会兴奋，因此我们要合理的应用自己的“人性”的这个利器。不用害怕暴露自己，收到正向反馈就把它当作是“燃料”继续驱动自己朝着目标方向飞行，收到负面反馈就适当反思有没有需要调整的，如果不是就不用太过在意。下面是我绘制的“个体”与“外界”的关系图\n封闭世界指的是我们每个人的内心世界，而无限宇宙指的是除了自身以外的一切事物。 封闭世界 优点\n这个世界的任何东西只要你想可以随便改动 当进入心流状态时，你大脑会运转得飞快，一些困难点可以快速攻克以及快速弄明白很多知识点 缺点\n孤独 偏执 无限宇宙 优点\n反馈 缺点\n嘈杂 过多无法改变的事物 通过简单比较并不是想表达哪个更优秀，而是我们个体应该跟这个世界“链接”起来，借用“无限宇宙”中强大的反馈能力驱动“封闭世界”，消除由于孤独带来的执行力低下，修正由于个体视角所带来的偏执，同时再利用好“封闭世界”的优点。可以让我们就像驱使一辆无限燃料的飞船，有条不紊的朝着我们梦想的星球飞去～\n","date":"2024-01-10T15:09:16+08:00","image":"https://sherlock-lin.github.io/p/%E4%BB%B0%E6%9C%9B%E6%98%9F%E7%A9%BA%E4%B9%9F%E8%A6%81%E9%B2%9C%E8%8A%B1%E4%B8%8E%E6%8E%8C%E5%A3%B0/image-20240109182221111-4795743_hu1133924793650014166.png","permalink":"https://sherlock-lin.github.io/p/%E4%BB%B0%E6%9C%9B%E6%98%9F%E7%A9%BA%E4%B9%9F%E8%A6%81%E9%B2%9C%E8%8A%B1%E4%B8%8E%E6%8E%8C%E5%A3%B0/","title":"仰望星空，也要鲜花与掌声"},{"content":"概述 这几年在迷茫中看了不少资料，有觉得写得很棒的，也有写的很糟糕的。所以一直想写这块的总结来进行归纳，同时也希望能给其他处于迷茫中的朋友提供一份高质量的资料列表(也许一个读者也没有)，以下清单个人觉得值得反复看以及思考\n关于学习这件事 博主觉得自己对学习的热情最高的时候恰恰是在小学二三年级左右，入学的第一天，大家都坐在座位上，眼巴巴的看着隔壁班的同学领着书过去，迫不及待的等着老师发新课本。在听到老师点到自己名字时会兴奋的跑到讲台，然后激动的抱着属于自己的一垒书📚在其他人的目光下像个凯旋的大将军，回到座位上后像猎豹贪婪的吸着自己的猎物一般闻着新书的味道，然后一页页翻开新书，看着上面讲阅的新的故事，以及有趣好玩的插画，仿佛自己也置身其中，等回过神来已经是下课铃了。但随着年纪的增长以及应试教育的背景下，学习逐渐成为了一件功利心很强的事情，学习—\u0026gt; 分数—\u0026gt; 学府—\u0026gt; good 公司—\u0026gt; money。这条链路很直观也很现实，特别是对一些家境不太好的人来说是一条“必须”走的路。步入社会后，通过几年逐步熟悉工作内容后，慢慢的进入了所谓的舒适圈。每天日复一日做着重复的工作，当然也赚到了一些钱，就认为这条链路已经到达尽头了这辈子都不需要学习了，就像一个工具感觉用不到了就直接丢弃。博主写这篇博客目的并不是劝学，仅仅单纯从自己的视角做些分析，孰对孰错不重要，重要的是在分析或者讨论后对咱们自身的思维想法有什么作用不是吗？\n关于如何学习这件事 在刚开始学习时，本人以为学习是有捷径的，但在经过投机取巧被现实按在地上摩擦后并被告知学习是没有捷径的，唯一的捷径就是努力。之后就各种无脑卷，死记硬背，各种压榨时间投入到里面。在经过多年后，现在博主想说，学习，tmd是真的有捷径的！\n上面这张图就是我总结的四步，且构成循环\n提升效率 效率这块分为工作和学习两方面；如果你已经在工作了，务必先提升工作这方面的效率，这样在完成工作后你才能腾出足够多的时间精力来提升学习方面的效率\n工作效率的提升\n在聊工作效率之前你要想明白工作的本质是什么，无他，就是要解决你上级的问题(包括你上级自己可能都没意识到的)，各行各业皆是如此包括你上级，他一样也要给他的上级解决问题。那么问题来了，如果你帮你上级解决了重要的问题，那么如果有升职加薪的机会他会不会优先考虑你呢。方向对了之后，下一步呢，如果你是一个产品的开发，那么你就应该对这个产品足够了解以及了解业内的玩法。这样在产品提出一些耗时并且不合理的设计时，你是不是就能合理的拒绝或裁剪呢；如果一定要做，那么是否可以反馈这个成本并且加入自己的一些想法让产品做trade off呢；其次，在具体的日常工作时，咱们是不是可以利用好自己程序员的身份，将一些繁琐的工作进行自动化/半自动化呢。最后要强调的一点也就是很多程序员容易忽略的，就是务必要搞好人际关系，这对工作的顺利展开的帮助是非常大的也能避免一些无效内耗。随着现在经济这个情况，各个公司都在强调降本增效，其实博主觉得，最应该降本增效的是咱们开发，这里博主推荐的是《程序员修炼之道》以及极客时间的《10x程序员工作法》\n学习效率的提升\n学习效率这块可以参考下面“关于卡bug的这件事”的内容，这里就不详细展开\n培养好习惯 好习惯这块我觉得《认知觉醒》中就总结得很好，在微信读书就能看，博主在这里就不板门弄斧了。博主就分享两个自己常用的两点，第一个是“只做一个”，比如要坚持做俯卧撑，那么每天只坚持做一个就算完成目标，如果要多做就当附赠的；另一点就是“心理暗示”，对于要培养的习惯可以适当的心理暗示，比如要坚持练小提琴，可以心理暗示自己“我比谁都热爱小提琴”、“我是小提琴专业选手”等等，这样频繁暗示之后等再去做的时候就觉得这一切都是理所应当的\n开阔眼界、提升思维 这一点应该是最让博主感慨并且后怕的，在这些年的职业生涯中接触过很多同事，有优秀到让博主想献上膝盖的技术大佬如于某前辈，也有不了解技术但是思维很清晰，分析问题能入目三分的产品前辈；但其中也有不少的同事的眼界和思维让博主感到有些惊讶。有个工作将近十年的测试前辈，经常一个小问题要反复跟你掰扯二三十分钟ta才明白，思维处于一种混沌的状态。也有一些同事一件事情给你描述半天你都无法知道ta表达什么；更有个别同事工作多年不知道倒排索引、分布式等知识。博主提这些并不是要指责任何人，在生活中他们都是很好的人并且相处得也很愉快。但是博主在这里提出来主要是想表达 “有道无术，术可求；有术无道止于术” 这个观点，如果做技术知识混口饭吃那无所谓，但如果你是一个对技术有追求的热血青年，到老了忙碌一辈子以为是技术的东西原来只是皮毛，此时醒悟会不会有些悲凉。这也是博主自己后怕的点，具体的解法可以看下陈老师的 别让自己“墙”了自己\n成事，并构成循环 成事简单来说就是将一件事情做好，哪怕是一件小事。这点是博主四个里面做的最烂的，这也直接导致了博主颠簸的职业生涯。无论上级给你交代什么事情，务必要事事有着落，事事有回响，哪怕是做不了也要第一时间同步。在职场中，你的绩效不会跟你的技术挂钩，只会跟你的成事呈正相关。借用易经的话“天行健，君子以自强不息；地势坤，君子以厚德载物”，无论你技术再牛，如果上级给你派的活你总是做得很糟糕让他不省心，那想必他以后也不敢再派重要的任务给你并且也不会给你太好看的绩效。因此在职场中德行是非常重要的，这里面就包括上级对你的信任。通过不断成事来增强上级对你的信心、依赖，你会获得更多丰厚的资源(除了工资还包括能让你提升打磨技术的任务等)。在不断积累这些经验后，距离下一个跃迁也是很快的一件事。在这里推荐《冯唐成事心法》以及《跃迁: 成为高手的技术》\n关于卡bug的这件事 如果你要问我这个世界能不能卡bug，我会毫不犹豫的告诉你，能。大致举几点\nps：博主对卡bug的定义是，如果别人学习一个东西要十天，你通过这个方式只要五天那就是；如果别人成为专业的要8年，你通过这个方式只要5年甚至更少，那就是。\n增强回路 这个词是在《认知觉醒》中接触到的，简单来说就是人体本身是存在一定的机制，在你不断的刻意训练某项能力，它会不停的增强，甚至有时候增强的幅度是跃迁级别的。那如果咱们将这个机制用在学习某些专业能力很强的技能点上，是不是可以获得意向不到的结果？\n也许有读者要开喷了，这不是废话吗，我不断的付出肯定是不断的有收获啊~\n但请注意，博主这里想强调的是增长的幅度，可能不是平时大家所想的线性增长，它有时候可能是呈现爆炸式的跳跃增长。以前有看过故事，就一个打铁匠日复一日的打铁过去了好多年，突然有一天他悟了然后就有了绝世神功(不知道编剧是怎么想的哈哈哈)。不过博主有比较深的体会，博主刚毕业那会坚持阅读源码，一开始晦涩难懂，虽然中途也断过几次，但幸运的是一直都坚持过来了。就在毕业的第三年那样突然就悟了，对源码不再恐惧。哪怕是一个全新的从没看过的大数据新组件，也能很快的通过看源码理清其内部原理。后来跳槽的时候大概很快上手了一个稍微复杂的项目，上级略为惊讶，殊不知这纯纯的降维打击。\n自己也仔细在这方面做过总结，并不是什么玄学。其实在我们不停的学某个领域的新东西时，咱们自身会对其进行抽象归纳。在咱们吸收这个抽象模型后，再去学这个领域的新东西时，会自动的用上这个抽象模型，那速度相比新学一个东西肯定是要快上很多。\n举个简单的例子，如果现在再让博主去学一个新的组件。博主会分三步，第一步阅读官方文档/博客，主要看都有哪些功能以及机制；第二步自己搭建起来玩一下各个功能顺带验证巩固第一步的知识；第三步就是翻看源码看看功能、机制是怎么实现的，都有哪些优缺点等等。这三板斧下去不敢说精通但至少说熟练还是没什么大问题的。\n借用周总理的话，不会咱们可以学嘛，即便再难借用好增强回路机制一定也能攻克\n复利 这个词是投资里面经常提到的词，比如每年投资赚10%，如果想要资产翻倍并不需要10年，而是八年。这就是复利的作用\n那在学习生涯中是否也可以利用复利的能力呢，仔细去推算复利增长的核心就会知道，除了本金更重要的就是时间，时间可以放大很多东西，除了咱们的资产，还可以放大咱们得学识。并且更重要的就是要坚持，在复利中如果断断续续的投资效果会大打折扣，学习也是如此。更何况还要考虑到《跃迁: 成为高手的技术》中所说的资源倾斜问题，那收益就会损失得更多。因此学习最重要的就是要坚持，越到后期效果会越加显著，相信到时候的收益一定不会让你失望\n元认知 这个词也是在《认知觉醒》中接触到的，形象一点说就是分裂出一个自己像蜘蛛侠一样粘在天花板上俯视一切，这个分裂出来的自己只做一件事情，就是观测下面发生的所有事情，包括宿主的一举一动，一言一行以及思考的内容。你的灵魂在这两幅躯壳中来回进行切换，你依然像平时一样改干嘛干嘛。只不过每隔十多分钟左右都要有意的切换到\u0026quot;蜘蛛侠\u0026quot;上进行观测。这样做的目的是啥嘞，其实就是为了自我纠正，自我修复。比如说你虽然坐在书桌前拿着本书，但是可能你的思绪已经故国神游了，在你切换灵魂后就能看到宿主躯壳这幅傻模样并且切换回去后专注回来继续看书；比如说你地铁上遇到素质差的人让你情绪暴躁想冲上去跟他打一架，在你切换灵魂后就可以清晰冷静的分析 双方的体型差距、是否有摄像头、除了动手是否还有其他更优解等等；比如说在给大家讲东西的时候，适当的切换灵魂看看宿主现在讲话语速是否过快，是否简单的知识复杂化等等来进行自我调整。\n简单来说就是调整自身的状态提高做事情的效率以及获得更好的结果。当然以上只是博主对这个概念的见解，感兴趣的读者可以阅读原著\n读书飞轮 两年前在学习“学习方法”时刷到这个： 书魔的学习方法-1:读书的飞轮 ，当时的第一个感觉就是相见恨晚，即便是现在再看也一样会很激动。这对博主这种具有严重的拖延症简直就是一剂强心剂，博主学习做事经常会受困于想太多，这个东西学了会不会以后永不上，这本书和那本书应该看哪一本，钻研这个事情还是留到某个长假再学等等。但这篇博客指导你，别怕，大胆去学，不仅要学还要飞快的学。时间会自动过滤掉用不上的，你最重要的是要学起来，保持学习的劲头(是不是对应上回路增强和复利了)。但你保持学习的劲头后，你会发现东西越学越快，同样的时间你能看完更多的书，弄懂更多知识。\n心流 这个词是在《心流》书籍里接触的，其实就是进入某种状态，在这个状态中你全身心的投入的当前的这个事情，此时的效率是最高的。\n相信很多人都有过这样的感觉，博主印象最深的就是高中做数学题的时候，戴上耳机摒弃外界一切干扰。刷题刷着刷着仿佛进入了一个空白的世界，在这个世界中你可以通过意念绘制立体图形，然后再通过意念补足辅助线，再在空气中列出公式求导得出值，ok，清空世界再开始下一题。此时我感觉不到你我他以及外部一切，大脑就像一台高速运转的cpu一样，导入题后快速预设好的逻辑对数据进行加工处理然后输入，如果处理不来就查阅外部存储(书籍)进行分析并自我完善。等反应过来已经是天黑了，虽然觉得时间过得很快，但同时也觉得自己弄懂了不少东西。\n在工作中遇到一些难题时，我也常常使用这种方式，找个安静的会议室或者回家路上，进入这个自我世界，清空一切杂念，然后输入已知信息，并不断地快速推导可行的解决方案，这个方式替我解决了不少问题。如果繁杂的工作环境下没法得出答案，可以试试这个方式。\n当然这个方式更多的可以应用在学习上，尽量避免过多的干扰物。可以考虑去图书馆或者一些自习室沉浸式的学习，当你进入这个状态时学习的速度和深度往往会远超平时的状态。\n话又说回来，你说为啥古时候或者武侠小说里动不动就去山洞里修炼，要我说很大程度上就是要进入心流状态来达到高效的结果。王守仁在龙场悟道我相信也是在心流的基础上，也许他所进入的那个世界真的有老子、孔夫子、朱熹等等跟他聚在一块探讨世界的奥秘。不过这些就扯远了，但对于咱们普通人来说，合理利用心流一定是学习路上的一大杀器。\n注意事项 切记陷入自我满足的学习，如果你重读书轻技能、重输入轻输出的话很有可能你的学习是不被这个世界认可并无法获得对应的“酬劳” 切记不要闭门造车，很有可能你闷头做了几年的东西再业内已经有了很好的产品或者说方向有可能是夕阳方向，相信我这不值得，你的热血值得挥洒在于你而言更有价值的东西并且你的努力理应获得更多的回报。可以试试加一些技术交流群、拥抱开源社区、以及看一些高质量的技术网站如：medium.com、InfoQ等，且尽量用google来进行知识的探索 切记学东西浅尝辄止，学任何东西都不要仅仅停留在皮毛，那样只会浪费你的大好时光以及消磨你的技术热情。学任何东西都分 道术器三个层次，对于你热爱的东西理应不断打磨，不断地探索下一个层次。要时不时将灵魂跳出肉身，俯视当前的这个人思维所处的环境是那个级别，是否过于死扣细节而忽略原理等。相信你跟我一样，对于大部分粗糙看的东西都忘得差不多了，但你一定清晰得记得，在你苦思冥想分析的那个bug的根因是什么，在你挑灯夜读所探索某个技术的原理是什么，这些哪怕到了退休都会清楚的记得。因为这是你在脑海里反复推敲过的东西，这些东西才是真正属于你的。而外面熙熙攘攘的那些所谓看了很多的知识其实并不属于你，它们与你而言只是匆匆赶路时的一抹景色，并不是你心中的东西。因此学习务必要有深度 切勿拖延，完美主义是成事的天敌。像博主之前每件事都想做到极致，每个功能都想彻底开发好再上线，每个优化都想优化到极致再上线等，这些在职场上都是致命的，要学会拥抱瑕疵。要知道对于公司什么最重要，功能可否迭代发布，先上线用户急迫需要的那部分开放出去，在慢慢开发剩下的？优化是否可以优化提升最显著的那部分，剩下的在慢慢搞？你学习可以没有输出或者晚点输出，但是公司不行，归根结底公司是个营利组织，是以结果为导向的。想起大气帝国崛起中嬴驷对嬴华说的 “何为战之本？曰，为国取利益”；那么何为 工作之本？曰，为公司取利。即便你的设计、代码不完美，只要能解决公司的问题那么就可以先上线，进一步优化的事对公司来说至少没那么紧急重要。先解决问题，先成事才是头等大事。 对于未来我想说的 对于未来，我想说持续保持热爱，不忘初心，就像二三年级时候拿到课本那般热情去学习新的知识。在这里安利下此专访，每当我偶尔迷茫时都会翻来看，时刻提醒自己，只要这是你热爱的东西就去做，当做一辈子的事情那样去做 专访“MySQL 之父”：我曾创造 MySQL，也将颠覆 MySQL 。至于路怎么走继续参考陈皓老师的 如何超过大多数人 以及技术人员的发展之路。\n总结 看完的读者会发现，博主通篇没有给任何东西定义对错。应试教育、功利心强、毕业了赚到钱不学习、投机取巧走捷径、只读书不转化为技能、不看完这篇博客或者否定这篇博客中所有的观点，可能都是“对”的。但所谓的对错真的重要吗？人生是一场求仁得仁的路程，你追求的是什么并且最终得到相信你的内心一定是富足的(前提是你以为你要的真的是你内心真正的追求)。有人追求金钱、有人追求名望、也有人心怀天下等等都没错，写这篇博客只是想给赶路的你我整理一篇“章法”。这个世界是符合一定规律的，你我置身其中岂能外乎？因此一定是有某个子规律，在符合它时能放大你努力的收益，这里所说的“章法”就是这个子规律。在“章法”这块其实已经有很多优秀的资料了，博主写得算不上好，但即便如此博主还是要写，借用一句诗来表达所想，“他强任他强，清风拂山岗”。最后，祝你我在人生的最终阶段，都能不留遗憾。爱你所爱，行你所行，听从你心，无问西东！\n参考博客/书籍 书魔的学习方法-1:读书的飞轮\n别让自己“墙”了自己\n程序员如何把控自己的职业\n如何超过大多数人\n技术人员的发展之路\n专访“MySQL 之父”：我曾创造 MySQL，也将颠覆 MySQL\n《认知觉醒》\n《认知驱动》\n《冯唐成事心法》\n《曾国藩家书》\n《跃迁: 成为高手的技术》\n","date":"2024-01-05T15:09:13+08:00","image":"https://sherlock-lin.github.io/p/%E5%AD%A6%E4%B9%A0%E5%BD%95/the-creative-exchange-d2zvqp3fpro-unsplash_hu5876398126655421130.jpg","permalink":"https://sherlock-lin.github.io/p/%E5%AD%A6%E4%B9%A0%E5%BD%95/","title":"学习录"},{"content":"引言小故事 张三在一家小型互联网公司上班，由于公司实行的996，因此经常有同事“不辞而别”，为了工作的正常推进，团队内达成了某种默契，这种默契就是通过某个规则来选出一个同事，这个同事除了工作之余还有额外看看每天是否有同事“不辞而别”，当发现有同事李四离职时，就会去把李四负责的工作的内容进行拆分给其他的同事进行处理。整个过程大致如下图\n由上图可以看到这个公司通过一个签到本和工作进度表来完成整个流程，每个同事上班时都要在签到本上进行签到，每天下班前要在工作进度表上同步今天的工作进展；例如今天李四“不辞而别”溜了，张三在签到本上看到李四没有签到记录，就判定这家伙不干了同时在工作进度表中把李四的任务进行拆分给大狗和二狗来做\u0026hellip;\n通过上面的故事会发现有几个问题\n张三是通过什么规则被选成“监督者”的？ 如果张三也不辞而别呢？ 为啥要通过签到本的方式，而不是张三直接去挨个挨个看？ \u0026hellip;. 咱们可以带着这些种种心里的疑惑看下面的文章，这个故事其实是一个分布式存储组件的雏形，刚刚所讨论的那些问题也是这些组件所会遇到的且大部分都是有解法的，所以咱们接下来就来看看bookkeeper这个分布式存储组件是如何解决上述问题的\nbookkeeper基础 “硬件无法保证不故障”，在这个大前提下，所有运行在硬件上的存储组件都一定会做一件很重要的事情，这件事就是数据恢复，要么是在组件内部来做，要么是在组件外部来做。\nbk是一个具有容错的分布式存储组件，同一份数据会有多个副本，分别存在多个bookie中来提供容错保证，那么当一台bookie不可用时，其上面保存的数据都少了一个副本，如果不进行数据恢复/复制的话再有其他的bookie不可用就很容易造成数据的丢失。因此bk自身内部提供了数据恢复的机制，今天通篇大论都是围绕bk的这个机制进行展开的\n数据恢复一般分为手动和自动，bk同时支持这两种方式，接下来就看看具体怎么操作的\n手动恢复\n1 2 bin/bookkeeper shell recover 192.168.1.10:3181 指定bookie机器来恢复 bin/bookkeeper shell recover 192.168.1.10:3181 --ledger ledgerID 指定bookie机器上的某个ledgerId进行恢复 在执行手动恢复时，会发生以下四个步骤\n客户端从zookeeper读取Ledger信息 根据Ledger信息确定需要做数据复制的Ledger(根据Ledger中存有被哪些bookie存储的元信息来确定) 在客户端启动一个做数据恢复的进程，针对需要做数据复制的Ledger进行数据恢复 一旦所有Ledger被标记为全副本了，则恢复动作完成 自动恢复\n1 2 3 bin/bookkeeper autorecovery bookie 集群开启自动恢复机制 bin/bookkeeper shell autorecovery -disable 关闭自动恢复机制 bin/bookkeeper shell autorecovery -enable 关闭恢复后再重新开启 除了通过指令的方式启动，bk还支持配置的方式，只需要在bookie节点配置autoRecoveryDaemonEnabled为false，这个bookie节点在启动的时候也同样会启动autorecovery服务\nautorecovery机制 上一章节讲了怎么使用，本章节主要讲明autorecovery这个机制\n自动恢复机制中有两个角色Auditor和replication worker，在启动自动恢复机制后，会在每个bookie实例中启动这两个角色\nAuditor\nbk集群中的Auditor们会通过zookeeper选举产生一位leader，这个leader负责监听 zookeeper /ledgers/available 节点变化情况来判定是否要做数据恢复动作，因为所有节点启动都会注册在上面，如果有服务不可用由于zookeeper的临时目录机制，会自动删除在此目录下自己节点的信息，因此leader通过watch机制可以轻松感知到有节点不可用，当Auditor leader感知到有节点不可用时，会将此bookie所负责的所有Ledger加在zookeeper /ledgers/underreplicated 路径下，通过这种方式通知replication worker做数据恢复过程\nreplication worker\n每个replication worker都会监听 /ledgers/underreplicated 地址，在监听到有数据恢复任务时，会在 /ledgers/underreplication/locks下添加锁从而避免并发问题；如果在开始恢复前发下当前Ledger的Fragment还处于写入中的状态，replication worker会先尝试等待它写完再做数据恢复动作，但如果等了一段时间还没写完会通过Fence机制处理再做复制，同时开启一个新的Fragment给客户端做数据的继续写入\n启动工作流程\n参照上图，在服务器节点上执行bin/bookkeeper autorecovery bookie后会发生以下步骤\n通过exec shell指令调用操作系统拉起AutoRecoveryMain 这个Java进程 AutoRecoveryMain进程启动时会同时启动Auditor线程和ReplicationWorker线程，由于环境中可能会启动多个AutoRecoveryMain进程来做HA高可用，因此多个Auditor线程会通过zookeeper选举来产生一个Auditor Leader 由于bookie集群用zookeeper来做集群感知，因此Auditor Leader只需要通过watch监听zookeeper上 bookie所注册的地址就能感知到是否有bookie节点不可用；当bookie节点不可用时一般就不会上报心跳给zookeeper，zookeeper就会将该节点创建的临时目录进行删除并告知添加watch的Auditor Leader Auditor Leader收到通知后会去zookeeper查询该不可用bookie所负责的Ledger列表，理论上这些Ledger都是需要做数据恢复的，因此会将它们放在zookeeper的/ledgers/underreplicated 目录下来通知ReplicationWorker ReplicationWorker通过watch监听到此目录有需要做数据恢复的Ledger后，会先在zk加锁再进行数据恢复逻辑；通过将Ledger划分为多个Fragment来轮训进行数据恢复，通过读取其他正常bookie上该Ledger的数据并写到其他没有该数据的bookie的节点上从而保证每份数据都有多个副本，直到将/ledgers/underreplicated 下的所有Ledger进行复制完，本次 autorecovery就算完成了。而Auditor线程和ReplicationWorker线程会不停的监听zookeeper直到下一个bookie节点不可用 通过此机制给bookkeeper提高了稳定性以及高可用能力，在有个别节点挂掉的时候依然能自动做到数据完备不丢，这种设计是一个成熟的组件该具备的能力\nautorecovery启动源码 源码主要分 启动流程以及工作流程进行讲解，同时在这里给需要阅读的朋友提供一个可能会用上的“词典”\n1 2 3 4 5 6 7 8 9 10 AutoRecoveryMain核心类, 主要负责启动AutoRecovery服务 AutoRecoveryService核心类，主要负责AutoRecovery相关的服务 LedgerManager 对外提供一个管理ledger的api，对内负责如何将ledger的元数据存储在kv存储上。提供增删、读写、注册/注销六个核心接口 AbstractZkLedgerManager 抽象类 LedgerIdGenerator：基于zk实现全局唯一递增的ledgerId ZkLedgerUnderreplicationManager：管理未完成复制的Ledger ZkLedgerAuditorManager：管理Auditor ReplicationWorker：负责从ZkLedgerUnderreplicationManager中获取未完成复制的Ledger并进行复制，每隔rwRereplicateBackoffMs触发一次 LedgerFragment：组成Ledger的单元，也是恢复复制的单元 EmbeddedServer：启动bk实例的节点 从现在开始跟踪启动的源码，在客户端执行 bin/bookkeeper autorecovery bookie 后会走到 bookkeeper/bin/bookkeeper 这个脚本下面的这行逻辑\n1 2 if [ ${COMMAND} == \u0026#34;autorecovery\u0026#34; ]; then exec \u0026#34;${JAVA}\u0026#34; ${OPTS} ${JMX_ARGS} org.apache.bookkeeper.replication.AutoRecoveryMain --conf ${BOOKIE_CONF} $@ 逻辑非常清晰，其实就是通过shell启动AutoRecovery 这样一个独立的Java进程，专门负责做故障数据恢复。JVM会从启动类的main方法进行引导执行，因此咱们接下来从AutoRecoveryMain的main方法作为入口来看看后面会发生哪些事情\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public static void main(String[] args) { //调用真正执行的方法，开源项目中真正执行某个操作会以do前缀来进行修饰 int retCode = doMain(args); .... } static int doMain(String[] args) { ServerConfiguration conf; try { //根据shell启动命令中指定的配置地址加载成配置对象 conf = parseArgs(args); } catch (IllegalArgumentException iae) { .... } LifecycleComponent server; try { //构建AutoRecoveryServer对象，比较重要的方法 server = buildAutoRecoveryServer(new BookieConfiguration(conf)); } catch (Exception e) { .... } try { //启动AutoRecoveryServer对象 ComponentStarter.startComponent(server).get(); } catch (InterruptedException ie) { .... } return ExitCode.OK; } 通过这里可以发现AutoRecoveryMain的main方法只是做一个引导的动作，最终启动的是AutoRecoveryServer对象。因此让我们深入看看这个服务的构造以及启动的流程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public static LifecycleComponentStack buildAutoRecoveryServer(BookieConfiguration conf) throws Exception { LifecycleComponentStack.Builder serverBuilder = LifecycleComponentStack.newBuilder() .withName(\u0026#34;autorecovery-server\u0026#34;); // 1. 创建StatsProviderService对象，主要用来记录AutoRecovery服务的各项指标状态 StatsProviderService statsProviderService = new StatsProviderService(conf); .... // 2. 通过构造函数的方式创建AutoRecoveryService对象，这是核心的代码 AutoRecoveryService autoRecoveryService = new AutoRecoveryService(conf, rootStatsLogger); .... // 3. 创建BKHttpServiceProvider对象，主要用来对外提供http服务，支持通过http方式读取内部状态信息等 if (conf.getServerConf().isHttpServerEnabled()) { BKHttpServiceProvider provider = new BKHttpServiceProvider.Builder() .setAutoRecovery(autoRecoveryService.getAutoRecoveryServer()) .setServerConfiguration(conf.getServerConf()) .setStatsProvider(statsProviderService.getStatsProvider()).build(); HttpService httpService = new HttpService(provider, conf, rootStatsLogger); .... } return serverBuilder.build(); } 再看AutoRecoveryService的构造函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public AutoRecoveryService(BookieConfiguration conf, StatsLogger statsLogger) throws Exception { super(NAME, conf, statsLogger); //通过构造函数创建AutoRecoveryMain，AutoRecoveryMain是AutoRecoveryService的成员变量 //进入看看它的实现 this.main = new AutoRecoveryMain( conf.getServerConf(), statsLogger); } public AutoRecoveryMain(ServerConfiguration conf, StatsLogger statsLogger) throws IOException, InterruptedException, KeeperException, UnavailableException, CompatibilityException { .... //创建AuditorElector对象，负责选举产生Auditor Leader auditorElector = new AuditorElector( BookieImpl.getBookieId(conf).toString(), conf, bkc, statsLogger.scope(AUDITOR_SCOPE), false); //创建ReplicationWorker对象，负责做数据的拷贝工作 replicationWorker = new ReplicationWorker( conf, bkc, false, statsLogger.scope(REPLICATION_WORKER_SCOPE)); deathWatcher = new AutoRecoveryDeathWatcher(this); } 服务构造的逻辑差不多就跟到这了，我们知道最终是为了创建AuditorElector和ReplicationWorker这两个对象就够了。服务启动这块从上面的 ComponentStarter.startComponent(server).get(); 进行跟踪\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public static CompletableFuture\u0026lt;Void\u0026gt; startComponent(LifecycleComponent component) { .... //调用start方法，这里涉及上采用了模版方法设计模式以及闭包，本质上就是就是调用创建的 //StatsProviderService、\tAutoRecoveryService、HttpService这三个服务的doStart方法 component.start(); .... } protected void doStart() { //还是调的AutoRecoveryMain方法的start方法 this.main.start(); } public void start() { //启动auditorElector服务 auditorElector.start(); //启动replicationWorker服务 replicationWorker.start(); .... deathWatcher.start(); } 结合上面的可以发现AutoRecovery的启动本质上就是启动AuditorElector和ReplicationWorker这两个服务，因此接下来咱们就来看看这两个服务的start过程，先来看看AuditorElector\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public Future\u0026lt;?\u0026gt; start() { running.set(true); //提交选举任务 return submitElectionTask(); } Future\u0026lt;?\u0026gt; submitElectionTask() { Runnable r = new Runnable() { @Override public void run() { .... //创建一个Auditor对象并进行启动 auditor = new Auditor(bookieId, conf, bkc, false, statsLogger); auditor.start(); } }; try { //异步执行以上逻辑 return executor.submit(r); } catch (RejectedExecutionException e) { .... } } 在这里其实就是对Auditor对象进行初始化以及启动，再进一步跟踪\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public Auditor(final String bookieIdentifier, ServerConfiguration conf, BookKeeper bkc, boolean ownBkc, BookKeeperAdmin admin, boolean ownAdmin, StatsLogger statsLogger) throws UnavailableException { .... //调用初始化Auditor对象逻辑 initialize(conf, bkc); .... } private void initialize(ServerConfiguration conf, BookKeeper bkc) throws UnavailableException { try { LedgerManagerFactory ledgerManagerFactory = bkc.getLedgerManagerFactory(); ledgerManager = ledgerManagerFactory.newLedgerManager(); this.bookieLedgerIndexer = new BookieLedgerIndexer(ledgerManager); this.ledgerUnderreplicationManager = ledgerManagerFactory .newLedgerUnderreplicationManager(); .... lostBookieRecoveryDelayBeforeChange = this.ledgerUnderreplicationManager.getLostBookieRecoveryDelay(); } catch (CompatibilityException ce) { .... } } 看完了初始化逻辑，再继续看下Auditor的启动逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public void start() { LOG.info(\u0026#34;I\u0026#39;m starting as Auditor Bookie. ID: {}\u0026#34;, bookieIdentifier); synchronized (this) { .... try { //1. 监听bookie变更事件，本质上就是在zk /ledgers/available 目录下增加watch监听节点的变动 //这里还会监听 只读bookie 节点的变动 watchBookieChanges(); //从zk获取处于可用的bk节点列表 knownBookies = getAvailableBookies(); } catch (BKException bke) { .... } try { //1. 在感知到有bookie节点不可用时回调LostBookieRecoveryDelayChangedCb进行逻辑处理 this.ledgerUnderreplicationManager .notifyLostBookieRecoveryDelayChanged(new LostBookieRecoveryDelayChangedCb()); } catch (UnavailableException ue) { .... } try { //1. 感知到有Ledger的副本少时触发，跟上面一样也是通过回调方式进行处理 this.ledgerUnderreplicationManager.notifyUnderReplicationLedgerChanged( new UnderReplicatedLedgersChangedCb()); } catch (UnavailableException ue) { .... } scheduleBookieCheckTask(); //启动一个线程检查Ledger的状态 scheduleCheckAllLedgersTask(); schedulePlacementPolicyCheckTask(); scheduleReplicasCheckTask(); } } 这些就是Auditor启动的逻辑，接下来再看看ReplicationWorker的启动逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public void start() { //workerThread实际上就是一个BookieThread对象 this.workerThread.start(); } public void run() { workerRunning = true; while (workerRunning) { try { //核心逻辑就是循环调用rereplicate方法 if (!rereplicate()) { LOG.warn(\u0026#34;failed while replicating fragments\u0026#34;); waitBackOffTime(rwRereplicateBackoffMs); } } catch (InterruptedException e) { .... } } LOG.info(\u0026#34;ReplicationWorker exited loop!\u0026#34;); } private boolean rereplicate() throws InterruptedException, BKException, UnavailableException { //获取需要做数据恢复的Ledger long ledgerIdToReplicate = underreplicationManager .getLedgerToRereplicate(); Stopwatch stopwatch = Stopwatch.createStarted(); boolean success = false; try { //进行数据恢复 success = rereplicate(ledgerIdToReplicate); } finally { .... } return success; } autorecovery工作源码 这块由于逻辑相对较多，因此针对autorecovery工作流程单独开一章。经过上面我们可以清晰的知道在经过启动后都发生了哪些事情，接下来咱们看看autorecovery真正工作的逻辑。在Auditor start的时候，会通过监听zookeeper来感知数据的动态变化\n1 2 3 4 5 6 7 8 public void start() { //感知bookie节点下线，将这些bookie上管理的Ledger标记为需要备份放到zookeeper上 this.ledgerUnderreplicationManager .notifyLostBookieRecoveryDelayChanged(new LostBookieRecoveryDelayChangedCb()); //感知Ledger副本变动，统计到指标里 this.ledgerUnderreplicationManager.notifyUnderReplicationLedgerChanged( new UnderReplicatedLedgersChangedCb()); } 上述两个唤醒方法主要是通过watch感知zookeeper事件，所以咱们主要看回调类里面的处理逻辑，先看下LostBookieRecoveryDelayChangedCb类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 private class LostBookieRecoveryDelayChangedCb implements GenericCallback\u0026lt;Void\u0026gt; { @Override public void operationComplete(int rc, Void result) { .... Auditor.this.ledgerUnderreplicationManager .notifyLostBookieRecoveryDelayChanged(LostBookieRecoveryDelayChangedCb.this); .... //提交事件变动处理任务，进去看看 Auditor.this.submitLostBookieRecoveryDelayChangedEvent(); } } synchronized Future\u0026lt;?\u0026gt; submitLostBookieRecoveryDelayChangedEvent() { return executor.submit(() -\u0026gt; { int lostBookieRecoveryDelay = -1; try { waitIfLedgerReplicationDisabled(); lostBookieRecoveryDelay = Auditor.this.ledgerUnderreplicationManager .getLostBookieRecoveryDelay(); .... //核心逻辑,进去看看都做了些什么 auditorBookieCheckTask.startAudit(false); } else if (auditTask != null) { LOG.info(\u0026#34;lostBookieRecoveryDelay has been set to {}, so rescheduling AuditTask accordingly\u0026#34;, lostBookieRecoveryDelay); auditTask = executor.schedule(() -\u0026gt; { auditorBookieCheckTask.startAudit(false); auditTask = null; bookiesToBeAudited.clear(); }, lostBookieRecoveryDelay, TimeUnit.SECONDS); auditorStats.getNumBookieAuditsDelayed().inc(); } } catch (InterruptedException ie) { .... } finally { if (lostBookieRecoveryDelay != -1) { lostBookieRecoveryDelayBeforeChange = lostBookieRecoveryDelay; } } }); } void startAudit(boolean shutDownTask) { try { //看起来是开始做Auditor的主要任务了，继续往下 auditBookies(); shutDownTask = false; } catch (BKException bke) { .... } } void auditBookies() throws ReplicationException.BKAuditException, InterruptedException, BKException { .... List\u0026lt;String\u0026gt; availableBookies = getAvailableBookies(); // find lost bookies Set\u0026lt;String\u0026gt; knownBookies = ledgerDetails.keySet(); //通过之前内存中存的bookie集合减去 zk当前bookie集合即可得出都有哪些bookie节点不可用了 Collection\u0026lt;String\u0026gt; lostBookies = CollectionUtils.subtract(knownBookies, availableBookies); .... //如果本次变动涉及到bookie节点不可用，则调用handleLostBookiesAsync方法处理不可用的节点 if (lostBookies.size() \u0026gt; 0) { try { FutureUtils.result( handleLostBookiesAsync(lostBookies, ledgerDetails), ReplicationException.EXCEPTION_HANDLER); } catch (ReplicationException e) { .... } .... } .... } private CompletableFuture\u0026lt;?\u0026gt; handleLostBookiesAsync(Collection\u0026lt;String\u0026gt; lostBookies, Map\u0026lt;String, Set\u0026lt;Long\u0026gt;\u0026gt; ledgerDetails) { LOG.info(\u0026#34;Following are the failed bookies: {},\u0026#34; + \u0026#34; and searching its ledgers for re-replication\u0026#34;, lostBookies); return FutureUtils.processList( Lists.newArrayList(lostBookies), //看方法名大概能猜得出来计算这些bookie上的Ledger，并针对这些Ledger进行数据恢复 //由于之前有存节点跟Ledger的映射关系，因此直接通过ledgerDetails映射表来获取这些不可用节点所负责的Ledger bookieIP -\u0026gt; publishSuspectedLedgersAsync( Lists.newArrayList(bookieIP), ledgerDetails.get(bookieIP)), null ); } protected CompletableFuture\u0026lt;?\u0026gt; publishSuspectedLedgersAsync(Collection\u0026lt;String\u0026gt; missingBookies, Set\u0026lt;Long\u0026gt; ledgers) { .... LongAdder underReplicatedSize = new LongAdder(); FutureUtils.processList( Lists.newArrayList(ledgers), ledgerId -\u0026gt; //通过读取这些Ledger的元数据，方便后续的数据恢复动作 ledgerManager.readLedgerMetadata(ledgerId).whenComplete((metadata, exception) -\u0026gt; { if (exception == null) { underReplicatedSize.add(metadata.getValue().getLength()); } }), null).whenComplete((res, e) -\u0026gt; { .... }); return FutureUtils.processList( Lists.newArrayList(ledgers), //主流程，继续往下 ledgerId -\u0026gt; ledgerUnderreplicationManager.markLedgerUnderreplicatedAsync(ledgerId, missingBookies), null ); } public CompletableFuture\u0026lt;Void\u0026gt; markLedgerUnderreplicatedAsync(long ledgerId, Collection\u0026lt;String\u0026gt; missingReplicas) { .... final String znode = getUrLedgerZnode(ledgerId); //标记需要做备份的Ledger tryMarkLedgerUnderreplicatedAsync(znode, missingReplicas, zkAcls, createFuture); return createFuture; } private void tryMarkLedgerUnderreplicatedAsync(final String znode, final Collection\u0026lt;String\u0026gt; missingReplicas, final List\u0026lt;ACL\u0026gt; zkAcls, final CompletableFuture\u0026lt;Void\u0026gt; finalFuture) { .... //将需要做数据恢复的副本进行进行proto编码 missingReplicas.forEach(builder::addReplica); .... ZkUtils.asyncCreateFullPathOptimistic( zkc, znode, urLedgerData, zkAcls, CreateMode.PERSISTENT, (rc, path, ctx, name) -\u0026gt; { if (Code.OK.intValue() == rc) { FutureUtils.complete(finalFuture, null); } else if (Code.NODEEXISTS.intValue() == rc) { //要在zookeeper将这些Ledger标记为需要做数据恢复 handleLedgerUnderreplicatedAlreadyMarked(znode, missingReplicas, zkAcls, finalFuture); } else { FutureUtils.completeExceptionally(finalFuture, KeeperException.create(Code.get(rc))); } }, null); } private void handleLedgerUnderreplicatedAlreadyMarked(final String znode, final Collection\u0026lt;String\u0026gt; missingReplicas, final List\u0026lt;ACL\u0026gt; zkAcls, final CompletableFuture\u0026lt;Void\u0026gt; finalFuture) { // get the existing underreplicated ledger data zkc.getData(znode, false, (getRc, getPath, getCtx, existingUrLedgerData, getStat) -\u0026gt; { if (Code.OK.intValue() == getRc) { // deserialize existing underreplicated ledger data final UnderreplicatedLedgerFormat.Builder builder = UnderreplicatedLedgerFormat.newBuilder(); try { TextFormat.merge(new String(existingUrLedgerData, UTF_8), builder); } catch (ParseException e) { .... } UnderreplicatedLedgerFormat existingUrLedgerFormat = builder.build(); boolean replicaAdded = false; for (String missingReplica : missingReplicas) { if (existingUrLedgerFormat.getReplicaList().contains(missingReplica)) { continue; } else { builder.addReplica(missingReplica); replicaAdded = true; } } .... //盲猜这里在zk将Ledger标志为需要做数据同步 zkc.setData(znode, newUrLedgerData, getStat.getVersion(), (setRc, setPath, setCtx, setStat) -\u0026gt; { if (Code.OK.intValue() == setRc) { FutureUtils.complete(finalFuture, null); } else if (Code.NONODE.intValue() == setRc) { tryMarkLedgerUnderreplicatedAsync(znode, missingReplicas, zkAcls, finalFuture); } else if (Code.BADVERSION.intValue() == setRc) { handleLedgerUnderreplicatedAlreadyMarked(znode, missingReplicas, zkAcls, finalFuture); } else { FutureUtils.completeExceptionally(finalFuture, KeeperException.create(Code.get(setRc))); } }, null); } else if (Code.NONODE.intValue() == getRc) { tryMarkLedgerUnderreplicatedAsync(znode, missingReplicas, zkAcls, finalFuture); } else { FutureUtils.completeExceptionally(finalFuture, KeeperException.create(Code.get(getRc))); } }, null); } 从ReplicationWorker的rereplicate方法开始就是真正做数据恢复的过程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 private boolean rereplicate(long ledgerIdToReplicate) throws InterruptedException, BKException, UnavailableException { .... //获取需要做数据恢复的Ledger的处理对象LedgerHandle try (LedgerHandle lh = admin.openLedgerNoRecovery(ledgerIdToReplicate)) { //通过对Ledger进行分解成更小数据恢复单位LedgerFragment，后续分别对LedgerFragment进行数据恢复 Set\u0026lt;LedgerFragment\u0026gt; fragments = getUnderreplicatedFragments(lh, conf.getAuditorLedgerVerificationPercentage()); .... for (LedgerFragment ledgerFragment : fragments) { .... try { //对LedgerFragment进行数据恢复 admin.replicateLedgerFragment(lh, ledgerFragment, onReadEntryFailureCallback); numFragsReplicated++; if (ledgerFragment.getReplicateType() == LedgerFragment .ReplicateType.DATA_NOT_ADHERING_PLACEMENT) { numNotAdheringPlacementFragsReplicated++; } } catch (BKException.BKBookieHandleNotAvailableException e) { .... } } .... fragments = getUnderreplicatedFragments(lh, conf.getAuditorLedgerVerificationPercentage()); .... } catch (BKNoSuchLedgerExistsOnMetadataServerException e) { .... } finally { .... } } 继续进一步看admin.replicateLedgerFragment的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 public void replicateLedgerFragment(LedgerHandle lh, final LedgerFragment ledgerFragment, final BiConsumer\u0026lt;Long, Long\u0026gt; onReadEntryFailureCallback) throws InterruptedException, BKException { .... //继续往下跟踪 replicateLedgerFragment(lh, ledgerFragment, targetBookieAddresses, onReadEntryFailureCallback); } private void replicateLedgerFragment(LedgerHandle lh, final LedgerFragment ledgerFragment, final Map\u0026lt;Integer, BookieId\u0026gt; targetBookieAddresses, final BiConsumer\u0026lt;Long, Long\u0026gt; onReadEntryFailureCallback) throws InterruptedException, BKException { .... //在这里看到这个恢复其实是异步处理的过程，继续往下 asyncRecoverLedgerFragment(lh, ledgerFragment, cb, targetBookieSet, onReadEntryFailureCallback); .... } private void asyncRecoverLedgerFragment(final LedgerHandle lh, final LedgerFragment ledgerFragment, final AsyncCallback.VoidCallback ledgerFragmentMcb, final Set\u0026lt;BookieId\u0026gt; newBookies, final BiConsumer\u0026lt;Long, Long\u0026gt; onReadEntryFailureCallback) throws InterruptedException { //发现会调用LedgerFragmentReplicator对象进行数据恢复，继续往下 lfr.replicate(lh, ledgerFragment, ledgerFragmentMcb, newBookies, onReadEntryFailureCallback); } void replicate(final LedgerHandle lh, final LedgerFragment lf, final AsyncCallback.VoidCallback ledgerFragmentMcb, final Set\u0026lt;BookieId\u0026gt; targetBookieAddresses, final BiConsumer\u0026lt;Long, Long\u0026gt; onReadEntryFailureCallback) throws InterruptedException { Set\u0026lt;LedgerFragment\u0026gt; partionedFragments = splitIntoSubFragments(lh, lf, bkc.getConf().getRereplicationEntryBatchSize()); .... //继续往下看实现 replicateNextBatch(lh, partionedFragments.iterator(), ledgerFragmentMcb, targetBookieAddresses, onReadEntryFailureCallback); } private void replicateNextBatch(final LedgerHandle lh, final Iterator\u0026lt;LedgerFragment\u0026gt; fragments, final AsyncCallback.VoidCallback ledgerFragmentMcb, final Set\u0026lt;BookieId\u0026gt; targetBookieAddresses, final BiConsumer\u0026lt;Long, Long\u0026gt; onReadEntryFailureCallback) { if (fragments.hasNext()) { try { //来了，一般有Internal的地方都会有实现的干货，继续进去 replicateFragmentInternal(lh, fragments.next(), new AsyncCallback.VoidCallback() { @Override public void processResult(int rc, String v, Object ctx) { if (rc != BKException.Code.OK) { ledgerFragmentMcb.processResult(rc, null, null); } else { replicateNextBatch(lh, fragments, ledgerFragmentMcb, targetBookieAddresses, onReadEntryFailureCallback); } } }, targetBookieAddresses, onReadEntryFailureCallback); } catch (InterruptedException e) { ..... } } else { ledgerFragmentMcb.processResult(BKException.Code.OK, null, null); } } private void replicateFragmentInternal(final LedgerHandle lh, final LedgerFragment lf, final AsyncCallback.VoidCallback ledgerFragmentMcb, final Set\u0026lt;BookieId\u0026gt; newBookies, final BiConsumer\u0026lt;Long, Long\u0026gt; onReadEntryFailureCallback) throws InterruptedException { .... //针对每个Entry对象循环做数据恢复，Entry是BK里最小的数据单元 for (final Long entryId : entriesToReplicate) { recoverLedgerFragmentEntry(entryId, lh, ledgerFragmentEntryMcb, newBookies, onReadEntryFailureCallback); } } private void recoverLedgerFragmentEntry(final Long entryId, final LedgerHandle lh, final AsyncCallback.VoidCallback ledgerFragmentEntryMcb, final Set\u0026lt;BookieId\u0026gt; newBookies, final BiConsumer\u0026lt;Long, Long\u0026gt; onReadEntryFailureCallback) throws InterruptedException { .... long startReadEntryTime = MathUtils.nowInNano(); /* * Read the ledger entry using the LedgerHandle. This will allow us to * read the entry from one of the other replicated bookies other than * the dead one. */ //到了真正读取Entry的逻辑，继续往下 lh.asyncReadEntries(entryId, entryId, new ReadCallback() { .... } }, null); } public void asyncReadEntries(long firstEntry, long lastEntry, ReadCallback cb, Object ctx) { .... //调用异步读取逻辑 asyncReadEntriesInternal(firstEntry, lastEntry, cb, ctx, false); } void asyncReadEntriesInternal(long firstEntry, long lastEntry, ReadCallback cb, Object ctx, boolean isRecoveryRead) { if (!clientCtx.isClientClosed()) { //继续往下跟踪 readEntriesInternalAsync(firstEntry, lastEntry, isRecoveryRead) .whenCompleteAsync(new FutureEventListener\u0026lt;LedgerEntries\u0026gt;() { .... }, clientCtx.getMainWorkerPool().chooseThread(ledgerId)); } else { cb.readComplete(Code.ClientClosedException, LedgerHandle.this, null, ctx); } } CompletableFuture\u0026lt;LedgerEntries\u0026gt; readEntriesInternalAsync(long firstEntry, long lastEntry, boolean isRecoveryRead) { //构造读数据的对象 PendingReadOp op = new PendingReadOp(this, clientCtx, firstEntry, lastEntry, isRecoveryRead); //运行起来，跟进去瞅瞅 op.run(); return op.future(); } public void run() { //无他，继续往下 initiate(); } void initiate() { .... do { //决定是串行读取数据还是并行读取数据 if (parallelRead) { entry = new ParallelReadRequest(ensemble, lh.ledgerId, i); } else { entry = new SequenceReadRequest(ensemble, lh.ledgerId, i); } seq.add(entry); i++; } while (i \u0026lt;= endEntryId); // read the entries. for (LedgerEntryRequest entry : seq) { //核心逻辑，这里进行数据读取操作 entry.read(); } } void read() { //继续往下看 sendNextRead(); } synchronized BookieId sendNextRead() { .... try { BookieId to = ensemble.get(bookieIndex); //发送读取请求的操作 sendReadTo(bookieIndex, to, this); .... } catch (InterruptedException ie) { .... } } void sendReadTo(int bookieIndex, BookieId to, LedgerEntryRequest entry) throws InterruptedException if (isRecoveryRead) { .... } else { //调用BK客户端进行数据的读取 clientCtx.getBookieClient().readEntry(to, lh.ledgerId, entry.eId, this, new ReadContext(bookieIndex, to, entry), BookieProtocol.FLAG_NONE); } } default void readEntry(BookieId address, long ledgerId, long entryId, ReadEntryCallback cb, Object ctx, int flags) { //继续往下 readEntry(address, ledgerId, entryId, cb, ctx, flags, null); } default void readEntry(BookieId address, long ledgerId, long entryId, ReadEntryCallback cb, Object ctx, int flags, byte[] masterKey) { //继续往下 readEntry(address, ledgerId, entryId, cb, ctx, flags, masterKey, false); } public void readEntry(final BookieId addr, final long ledgerId, final long entryId, final ReadEntryCallback cb, final Object ctx, int flags, byte[] masterKey, final boolean allowFastFail) { //获取要访问的客户端对象 final PerChannelBookieClientPool client = lookupClient(addr); .... client.obtain((rc, pcbc) -\u0026gt; { if (rc != BKException.Code.OK) { completeRead(rc, ledgerId, entryId, null, cb, ctx); } else { //调用读取逻辑 pcbc.readEntry(ledgerId, entryId, cb, ctx, flags, masterKey, allowFastFail); } }, ledgerId); } public void readEntry(final long ledgerId, final long entryId, ReadEntryCallback cb, Object ctx, int flags, byte[] masterKey, boolean allowFastFail) { //看到Internal就知道要有东西了，继续往下 readEntryInternal(ledgerId, entryId, null, null, false, cb, ctx, (short) flags, masterKey, allowFastFail); } private void readEntryInternal(final long ledgerId, final long entryId, final Long previousLAC, final Long timeOutInMillis, final boolean piggyBackEntry, final ReadEntryCallback cb, final Object ctx, int flags, byte[] masterKey, boolean allowFastFail) { .... //构造请求对象 ReadRequest.Builder readBuilder = ReadRequest.newBuilder() .setLedgerId(ledgerId) .setEntryId(entryId); .... request = withRequestContext(Request.newBuilder()) .setHeader(headerBuilder) .setReadRequest(readBuilder) .build(); .... //继续往下 writeAndFlush(channel, completionKey, request, allowFastFail); } private void writeAndFlush(final Channel channel, final CompletionKey key, final Object request, final boolean allowFastFail) { .... try { .... //跟到这里就知道最终调用了Netty的客户端来发起请求 channel.writeAndFlush(request, promise); } catch (Throwable e) { .... } } 到这里数据就发出去了，我们也能知道AutoRecovery进程是通过Netty向BK的服务端进行数据读取，那么服务端在接收到请求后又是怎么处理的呢，这里咱们从服务端接收请求的逻辑开始跟，由于BK本身也是通过Netty实例进行网络请求处理的，因此可以轻松找到BookieRequestHandler的channelRead方法监听外部网络请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { .... //职责分离做得很好，BookieRequestHandler只负责接收请求，逻辑处理相关的全权交给requestProcessor对象 requestProcessor.processRequest(msg, this); } public void processRequest(Object msg, BookieRequestHandler requestHandler) { Channel channel = requestHandler.ctx().channel(); if (msg instanceof BookkeeperProtocol.Request) { BookkeeperProtocol.Request r = (BookkeeperProtocol.Request) msg; restoreMdcContextFromRequest(r); try { BookkeeperProtocol.BKPacketHeader header = r.getHeader(); //非常好的一种设计，kafka的KafkaApis类里也是这样设计，服务端支持的操作在这里就能很清晰的看到 switch (header.getOperation()) { case ADD_ENTRY: processAddRequestV3(r, requestHandler); break; case READ_ENTRY: //在这里可以处理的读取请求，从这里进去看看 processReadRequestV3(r, requestHandler); break; case FORCE_LEDGER: processForceLedgerRequestV3(r, requestHandler); break; .... case WRITE_LAC: processWriteLacRequestV3(r, requestHandler); break; case READ_LAC: processReadLacRequestV3(r, requestHandler); break; case GET_BOOKIE_INFO: processGetBookieInfoRequestV3(r, requestHandler); break; case START_TLS: processStartTLSRequestV3(r, requestHandler); break; case GET_LIST_OF_ENTRIES_OF_LEDGER: processGetListOfEntriesOfLedgerProcessorV3(r, requestHandler); break; default: .... break; } } finally { MDC.clear(); } } else { .... } } private void processReadRequestV3(final BookkeeperProtocol.Request r, final BookieRequestHandler requestHandler) { //能看到BK也同时支持长轮询的方式读取数据 if (RequestUtils.isLongPollReadRequest(r.getReadRequest())) { .... read = new LongPollReadEntryProcessorV3(r, requestHandler, this, fenceThread, lpThread, requestTimer); } else { read = new ReadEntryProcessorV3(r, requestHandler, this, fenceThread); .... } if (null == threadPool) { //跟进去看看实现 read.run(); } else { .... } } public void run() { .... //执行读取操作 executeOp(); } protected void executeOp() { //这里感觉设计得不是很清晰，应该先读取数据出来再构造返回对象的，你们觉得呢？ ReadResponse readResponse = getReadResponse(); if (null != readResponse) { sendResponse(readResponse); } } protected ReadResponse getReadResponse() { // 读取Entry数据的地方，在此处深入探索下 return readEntry(readResponse, entryId, startTimeSw); } catch (Bookie.NoLedgerException e) { .... } } protected ReadResponse readEntry(ReadResponse.Builder readResponseBuilder, long entryId, Stopwatch startTimeSw) throws IOException, BookieException { //继续深入 return readEntry(readResponseBuilder, entryId, false, startTimeSw); } protected ReadResponse readEntry(ReadResponse.Builder readResponseBuilder, long entryId, boolean readLACPiggyBack, Stopwatch startTimeSw) throws IOException, BookieException { //调用Bookie的readEntry来读取数据 ByteBuf entryBody = requestProcessor.getBookie().readEntry(ledgerId, entryId); .... } public ByteBuf readEntry(long ledgerId, long entryId) throws IOException, NoLedgerException, BookieException { .... try { LedgerDescriptor handle = handles.getReadOnlyHandle(ledgerId); .... //调用真正读数据的逻辑，因为在这里能看到获取的值entry也是对外返回的 //这里调用的是LedgerDescriptor类的readEntry方法 ByteBuf entry = handle.readEntry(entryId); .... return entry; } finally { .... } } ByteBuf readEntry(long entryId) throws IOException, BookieException { //调用LedgerStorage接口，SingleDirectoryDbLedgerStorage实现类来读取Entry return ledgerStorage.getEntry(ledgerId, entryId); } public ByteBuf getEntry(long ledgerId, long entryId) throws IOException, BookieException { long startTime = MathUtils.nowInNano(); try { //继续往下跟踪 ByteBuf entry = doGetEntry(ledgerId, entryId); recordSuccessfulEvent(dbLedgerStorageStats.getReadEntryStats(), startTime); return entry; } catch (IOException e) { .... } } private ByteBuf doGetEntry(long ledgerId, long entryId) throws IOException, BookieException { .... //尝试从BK本地缓存中读取数据 ByteBuf entry = localWriteCache.get(ledgerId, entryId); //尝试从本地缓存flush中进行数据命中数据 entry = localWriteCacheBeingFlushed.get(ledgerId, entryId); // 尝试从读缓存中进行数据读取 entry = readCache.get(ledgerId, entryId); //从磁盘文件中进行数据读取, 调用的是EntryLogger接口，DefaultEntryLogger对象的readEntry方法 entry = entryLogger.readEntry(ledgerId, entryId, entryLocation); //写到读缓存中 readCache.put(ledgerId, entryId, entry); .... return entry; } public ByteBuf readEntry(long ledgerId, long entryId, long entryLocation) throws IOException, Bookie.NoEntryException { //再进一步探索 return internalReadEntry(ledgerId, entryId, entryLocation, true /* validateEntry */); } private ByteBuf internalReadEntry(long ledgerId, long entryId, long location, boolean validateEntry) throws IOException, Bookie.NoEntryException { //获取entry所在的LogId long entryLogId = logIdForOffset(location); long pos = posForOffset(location); BufferedReadChannel fc = null; int entrySize = -1; try { fc = getFCForEntryInternal(ledgerId, entryId, entryLogId, pos); ByteBuf sizeBuff = readEntrySize(ledgerId, entryId, entryLogId, pos, fc); entrySize = sizeBuff.getInt(0); if (validateEntry) { validateEntry(ledgerId, entryId, entryLogId, pos, sizeBuff); } } catch (EntryLookupException e) { .... } ByteBuf data = allocator.buffer(entrySize, entrySize); //进行数据读取 int rc = readFromLogChannel(entryLogId, fc, data, pos); .... data.writerIndex(entrySize); return data; } private int readFromLogChannel(long entryLogId, BufferedReadChannel channel, ByteBuf buff, long pos) throws IOException { BufferedLogChannel bc = entryLogManager.getCurrentLogIfPresent(entryLogId); .... //继续往下 return channel.read(buff, pos); } public int read(ByteBuf dest, long pos) throws IOException { //继续往下 return read(dest, pos, dest.writableBytes()); } public synchronized int read(ByteBuf dest, long pos, int length) throws IOException { .... while (length \u0026gt; 0) { // Check if the data is in the buffer, if so, copy it. if (readBufferStartPosition \u0026lt;= currentPosition \u0026amp;\u0026amp; currentPosition \u0026lt; readBufferStartPosition + readBuffer.readableBytes()) { int posInBuffer = (int) (currentPosition - readBufferStartPosition); int bytesToCopy = Math.min(length, readBuffer.readableBytes() - posInBuffer); dest.writeBytes(readBuffer, posInBuffer, bytesToCopy); currentPosition += bytesToCopy; length -= bytesToCopy; cacheHitCount++; } else { // We don\u0026#39;t have it in the buffer, so put necessary data in the buffer readBufferStartPosition = currentPosition; int readBytes = 0; //从磁盘读取数据到readBuffer中，再将readBuffer的数据写到 dest中作为返回值 //这里调用的是Java NIO FileChannel类的read方法来从磁盘进行数据的读取 if ((readBytes = validateAndGetFileChannel().read(readBuffer.internalNioBuffer(0, readCapacity), currentPosition)) \u0026lt;= 0) { throw new IOException(\u0026#34;Reading from filechannel returned a non-positive value. Short read.\u0026#34;); } readBuffer.writerIndex(readBytes); } } return (int) (currentPosition - pos); } 总结 在这里解答下引言小故事\n张三是通过什么规则被选成“监督者”的？\n张三是通过zookeeper的Paxos算法选举产生的\n如果张三也不辞而别呢？\n大狗和二狗也会通过zookeeper监听张三的状态，如果张三不辞而别的话，大狗二狗会通过zookeeper选举成为新的“监督者”\n为啥要通过签到本的方式，而不是张三直接去挨个挨个看？\n通过签到本的方式比较节约张三的时间，否则当员工比较多的时候并且对感知时间比较快的时候，张三就要每隔几分钟就要跑去挨个挨个看，这样没多久张三也要“不辞而别”了。通过签到本如果某个同事不签到了张三就能很轻松感知到并做相对应的处理了\n参考资料 https://bookkeeper.apache.org/docs/admin/autorecovery/ bk项目 site3/website/docs/admin/* 指令使用说明 ","date":"2024-01-04T12:00:10+08:00","image":"https://sherlock-lin.github.io/p/%E8%AF%A6%E8%A7%A3bookkeeper%E4%B9%8Bautorecovery%E6%9C%BA%E5%88%B6/image-20231215102118251_hu13366877165211677337.png","permalink":"https://sherlock-lin.github.io/p/%E8%AF%A6%E8%A7%A3bookkeeper%E4%B9%8Bautorecovery%E6%9C%BA%E5%88%B6/","title":"详解bookkeeper之AutoRecovery机制"},{"content":"不知不觉一年又快结束了，今天写了不少文章，那就专门写一份给自己的信\n工作 2023年整体过得还算平稳，先说说工作上的事，岗位上顺利升职，有个比较大的感慨，就是写好PPT是真的很有必要的，看了一些大佬们的晋升PPT发现人家对产品的剖析非常清晰并且很多结果都是有数据指标来支撑的，通过PPT就能明显感觉到大佬对产品的理解是很透彻的。因此自己也给自己定了个任务，就是每年都要给自己写当年的答辩PPT以及简历，通过写这些东西能够帮你思考提炼这个年度的收获以及指导未来的方向。除此之外还有三个觉得比较值得写得点\n对业务务必要深入了解 对业务理解这个好处有3点，第一就是当你对业务有足够的了解时，无论发生任何事情你都心里有底，即便有故障如果你能清晰的知道没有影响到线上流量那就不用太担心， 第二就是当对业务足够了解时，在设计程序以及跟产品battle时能够更好的抓主要矛盾，有的放矢，从而设计出更适合业务的软件。 第三就是当你对业务足够了解时，有些工作(非产品)上你可以大胆的跟各种大佬们极限拉扯，拉扯赢了有些非必要并且耗费精力的事情就可以不做或者慢慢做 先紧后驰 这点是我需要改进的点，在接到任务时我喜欢慢慢展开，喜欢花更多前期的时间去熟悉任务以及放松一下，这有时会影响任务的推进。因此在接手一些重要的任务时， 应该尽快的进行任务的展开，不用可以追求完美，先做了再说，不对再在做的过程中做调整，行就是知，知就是行，两者本就是一体的，有些东西不去做是永远也想不明白的 定期reset 这是听了郭宇大佬的专访后得出的体会，如果每天都日复一日的工作，会发现时间过得很快并且心情也容易烦躁，应该定期的给自己重置下，例如花两三天去一个陌生 城市放空自己，忘记自己的工作与生活，就跟自己跟世界对话，然后像看其他人的人生一样看自己这段时间的经历，客观的思考哪些是自己追求的，哪些是自己不需要的 等等。每年都要如此几次，通过这样来调整自己的节奏，让自己整体有条不絮的往自己的终极目标前进 学习 说完工作，再聊聊学习上的事情，今年比较大的收获是坚持了半年的背单词，每天保持背50～70个单词，不追求每个都背下来，更多的是背一个感觉，就是看到这个单词能猜到一个大概，这是从“学习飞轮”那片文章上得到的灵感，就是有些东西一定要快起来，背单词也是一样的，与其追求完美导致止步不前，不如先保持背的习惯以及对大部分单词有个认识，后续要用到的单词也会频繁的出现在自己面前加深自己的印象。除了背单词之外还有比较好的点是终于重新拾起写博客的习惯，相比于前两年的犹豫不决，今年的自己算是从迷茫逐渐走向坚定，虽然自己现在还没想明白自己的使命，但是可以确定的事就是，我希望能够继续深挖技术能力，不设边界，任何编程语言，任何领域知识只要感兴趣都可以学习以及深挖，这个过程中主要看的是这个领域的大佬是如何设计解决方案来解决对应场景的问题的。因此在这个背景下希望自己能够多输出高质量的文章，不仅能够倒逼自己学习、思考提炼，还能够通过这种方式影响更多的人，让读者能够爱上编程、爱上大数据、爱上设计、爱上生活\u0026hellip;. 除了这些以外还发现了一个拦路虎，就是写文章喜欢拖延，很多东西想一下子写到最后，然后反复推敲某个点，或者希望能够等绘制出更详细的图辅助说明等等导致无限期拖延，今年就有十多篇文章因为这个导致无限延期，因此明年希望自己在这方面能够快速闭环，有合适的想法的时候写得差不多就发出来，先闭环，等后续有新的见解可以再更新或者输出新的文章等，简单来说还是要知行合一，有时候不发出来你也会永远不知道差在哪里\n开心与遗憾 在这里罗列三件开心和遗憾的事，先说说开心的事，第一件是终于想清楚要认真学习以及输出文章这件事了，相比前两年犹豫要不要放弃编程，也许设计代码这件事情更符合自己内心的追求，认真学技术以及输出文章也算是 follower 自己的内心了。第二件就是改用VSCode来写文章，这个真的太爽了，不用再纠结markdown的语法，不用纠结于文件不好管理维护等等，就沉浸于码字，用字将自己的思绪串联起来然后通过手指敲动以字节流的方式持久化到设备上，有时能进入心流的状态，这种感觉可能只有懂得才懂。第三件就是要去湖南浏阳跨年了，也就是后天，在漫天的烟花中送走2023年，并迎来新的一年的自己，对于多年没看到烟花以及自己放烟花的自己来说这是 莫大值得激动的事情～ 说了开心的事，再说说遗憾的事吧，第一件是自己今年始终没有勇敢的迈出那一步，大学室友勇敢的去自己创业开奶茶店，同事豪哥也去尝试自己喜欢生意，而我还是选择了相对稳定工作，希望明年我也能勇敢的去尝试更多自己喜欢的事情。第二件就是在国庆时候跟家人去香港澳门游玩，由于自己没有提前做好攻略，感觉有些地方有些遗憾，毕竟家人很少离开小岛。第三件事就是改补的牙由于忙导致一直拖着，现在的牙洞逐渐扩展，内心开始有些紧张了，还是穿了又要做根管治疗了～\n展望 然后也希望明天的这个时候，能够在更多自己喜欢的领域深耕并输出更多优质的文章，然后最后想给大家分享的是，大胆去做你想做的那个人吧，把你的想法写出来然后 去实现，不用在乎别人的看法说法，首先真的没有那么多的人去关注我们，其次，在我们的世界我们才是主角，做让自己开心的事就好了。走正确的路， 就是做自己真正热爱的事，哪条是正确的路？只有自己能定义。路不止一条，坚持做你在乎的事，走出自己在乎的路，给出你对这个世界独有的回答！\n再见2023，你好2024！\n","date":"2023-12-25T15:09:16+08:00","image":"https://sherlock-lin.github.io/p/%E4%B8%80%E5%B0%81%E5%86%99%E7%BB%99%E5%B9%B4%E6%9C%AB%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BF%A1/matt-le-SJSpo9hQf7s-unsplash_hu10664154974910995856.jpg","permalink":"https://sherlock-lin.github.io/p/%E4%B8%80%E5%B0%81%E5%86%99%E7%BB%99%E5%B9%B4%E6%9C%AB%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BF%A1/","title":"一封写给年末自己的信"},{"content":"引言 距离第一次写博客已经过去将近10年时间了，今年就专门以问答形式写写为什么要写下这些玩意\n正文 为什么要写这些玩意\n作者是一个什么事情都喜欢思考有没有意义的功利性的人，但本次写作的源头却事出反常，就单纯觉得把弄懂的东西以某种媒介记录下来，在未来的某个时间点回过头来看以时间轴将这些思想穿起来的这样一部“电影”一定很有意思，如果诸君感兴趣也可一同观看\n打算写哪些方向的文章\n这块没有给自己设限，目前个人知识方向主要是 编程、大数据、操作系统、历史、以及读书心得这几个方向，正如一千个读者有一千个哈姆雷特，作者也是一样，即便是现在已经有很多现成的文章了，但通过不同作者的视角下看到的东西可能也不太一样。本人擅长抽象以及提炼，对不少东西都有自己的一番见解，因此有信心将一些普罗大众觉得复杂的东西 提炼成简单的图或者故事来给自己以及读者解惑。不要求文章多，但一定是要经过自己大脑思考、咀嚼消化过后的东西，流水账的东西尽量不写或少些。一言以蔽之，就是写值得写的东西\n使命感\n最近在跟朋友聊天有聊到这个，他希望自己能找到自己来到这个世界的使命，本人其实也一样在寻找，写文章不是使命感驱动的，更多的是作为找到使命前的“历练”，如果要功利点算的话，那就是通过写作来磨练自己的思维框架这把利剑，并将它送给未来找到使命的自己，也许写着写着就找到了也说不定呢\n会不会觉得浪费时间\n说实话，曾经有段时间觉得挺浪费时间的，写了自己也不怎么会看，也不会有什么读者去看，那写这些东西的意义何在呢？所以最终放弃了一段时间，但后来发现不写文章的时间要么也是刷短视频、打游戏、发呆等等，那好像更没啥意义，对于那些日复一日年复一年没任何积累的东西，写作反而可爱得像个养成游戏，每天陪伴它一会，它就会茁壮成长，长成一颗苍天大树，供自己安放那颗躁动的心以及给行人遮阴凉\n孤独吗\n有句话说，每个作者都是孤独的。本人也不例外，但很幸运的是可以通过文字这种工具来跨时空地域跟很多人聊天，像远在贵阳龙场的王阳明，在岳阳楼上写下“博，一介书生，三尺微命”的那个少年，“也无风雨也无晴”的东坡先生，甚至有那么一刻，我是我，也是他们，也懂了他们的孤独、惆怅、无奈，如今经历得越多那份情绪就更加浓郁几分。现如今，我也想通过文字跟不同时空的自己沟通，以及另一个时空的你，因为我，就是你啊\n小结 好像写着写着有些跑题了，主要是结合近期思考的知识回答下一些自己心中的疑问，同时也提醒自己勿忘初心并保持写作思考的节奏\n","date":"2023-12-12T15:09:15+08:00","image":"https://sherlock-lin.github.io/p/%E4%B8%BA%E5%95%A5%E8%A6%81%E5%86%99%E8%BF%99%E4%BA%9B%E7%8E%A9%E6%84%8F/the-creative-exchange-d2zvqp3fpro-unsplash_hu5876398126655421130.jpg","permalink":"https://sherlock-lin.github.io/p/%E4%B8%BA%E5%95%A5%E8%A6%81%E5%86%99%E8%BF%99%E4%BA%9B%E7%8E%A9%E6%84%8F/","title":"为啥要写这些玩意"},{"content":"写在前面 过去的十多年，随着国内互联网的蓬勃发展，信息呈现爆炸式增长；一方面，咱们接受信息的渠道变得多样化如搜索引擎、博客、朋友圈、短视频等等，另一方面，投入制造这些内容的人也多了，效率也更高了，因此我们每天接受的信息数不胜数。有些 制造者 为了自己的内容能够在众多内容中脱颖而出，因此诞生了不少 标题党、贩卖焦虑的制造者。这些内容会在用户刷手机时，仅通过0.5秒的时间就能抓住用户的眼球或者击中用户的心理，从而创造流量进而从中获利。久而久之就成了这批人在用户的大脑内圈地跑马，往用户大脑内注入自己大量的信息以及暗示，最最重要的是他们注入的都是经过他们进行“消化”过的N手知识，用户如果长期习惯于这种“被投喂”的方式，逐渐会丧失独立思考能力，从而彻底依赖于他们。借用《肖申克的救赎》里的一句话，“一开始，你痛恨周围的高墙，满满地，你习惯了生活在其中，最终你会发现自己不得不依靠它而生活”。\n经历 说说自己的经历吧，几年前在房价腾飞的时候，当时很流行一套方案，“借钱付首付，然后房租抵月供，然后每个月的工资用来还借的首付，过几年卖了房子相当于白赚几十万”，通过这种空手套白狼的方式来达到快速赚钱。当时人云亦云，相信不少朋友那个时候周围或多或少都有这样的声音，博主当时也是深信不疑，一方面是大家都这么说久而久之大脑内部也深度相信这个理论，另一方面是随着房价xiuxiuxiu往上涨自己也说服自己，这不是现实验证理论吗，但随后几年就给大众啪啪啪打脸了，甚至也不少人血本无亏。现在反思这个事情，大家都能清楚的知道，这套方案的成立是有大前提的，“经济要一直蓬勃发展”，没有什么稳赚不赔的买卖。但当时没有看清的最主要原因就是，没有什么独立批判的能力，别人说什么，只要说的频繁以及说的人多，自己就全信，这样的人出了社会往往就成了所谓的“韭菜”。在现如今，这样的群里依然不在少数，人云亦云，你只要稍微多问几个问题他就答不上来，或者说的全是“标准答案”。如果说每个人都是一辆行驶的汽车，那这样做无疑是将方向盘毫无疑问的交给一个未知的人，你希望这样吗？\n思考 前两段主要描述的是我们遇到的情况，这一段主要是聊聊如何去应对。首先最重要的是，一定要保持充电也就是知识的学习，方式不重要，其中包括但不仅限于 书籍、视频、与人探讨等等，最主要的是要自己搭建属于自己的一套“知识系统”并且不断自我完善。在有新的知识或者新的风口跳出来时，你可以基于自己的“知识系统”对其进行批判性的学习以及了解，不要人云亦云，今天追逐短视频、明天追逐gpt，这样除了了解新东西的皮毛，最终只剩下一颗焦虑的心，因为你会发现虽然不断的学新东西，不停的追逐新事物，但属于你手中，脑中的东西会越来越少，与日俱增的只有无穷的空虚以及焦虑。\n保持充电，构建自己的“知识系统” 切忌盲目追逐新事物，新东西有新东西的好，老东西有老东西的好，毕竟经典的东西都是经过时间洗礼的，减少试错成本 保持批判能力，任务事物一定一定一定有两面性，就像 道家的阴阳鱼一样，有阳光的地方就会有阴影。别人越是大肆宣扬什么，我们越是要谨慎思考他没说的那部分，要系统性全面的去思考某个观点，而不是放弃思考完全跟着别人走 避免过多的沉溺于“多巴胺陷阱”，比如花过多的时间在短视频、游戏等等上面 定期锻炼，保持愉悦积极的心态 总结 最后，虽然本篇博客提出了一个问题，已经提出了自认为的“应对方法”，但也不是每个人都必须这么去做的。首先第一点，随波逐流和独立思考也有各自的两面性，有些人选择随波逐流一样可以过得好好，这就看个人选择。第二点，选择独立思考的背景下，应对博客提出的问题其实也有很多解法，建议读者也批判性的看待这篇博客，如果觉得这篇博客也是“标题党”或者“制造焦虑”也正常，重要的是，保持独立思考，特别是深度思考，在沉浸其中时，你会忘了时间、忘了一切，仅仅沉浸于你的世界，去构造属于你自己的系统，也就是你自己。最后，祝大家都能成为自己想成为的那种人。\n","date":"2023-08-07T15:09:15+08:00","image":"https://sherlock-lin.github.io/p/%E9%9A%8F%E6%B3%A2%E9%80%90%E6%B5%81or%E7%8B%AC%E7%AB%8B%E6%80%9D%E8%80%83/matt-le-SJSpo9hQf7s-unsplash_hu10664154974910995856.jpg","permalink":"https://sherlock-lin.github.io/p/%E9%9A%8F%E6%B3%A2%E9%80%90%E6%B5%81or%E7%8B%AC%E7%AB%8B%E6%80%9D%E8%80%83/","title":"随波逐流or独立思考"}]